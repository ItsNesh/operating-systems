SPEAKER 0
Oh cool, we actually have started. Alright. Sorry, there was a thing in front of the screen saying that the microphone was muted rather than saying the lecture should have started. Hi everyone, um, week 7, I think, right? Um. There is a quiz today. If you were a diligent student and did it early, you may have noticed that in one of the questions, it was missing an important piece of information. Um, I have emailed the students in question if they got an answer that I think could be right. Um. Uh, basically, in question nine, I somehow didn't write down which algorithm you should use for a pay replacement algorithm, which was pretty dumb. Um, but the the correct answer is LRU, so, um, or not correct answer, but you know, um, correct question. Um, if you did it early this morning and prove you can do it early this morning and you still think your answer is correct based on an assumption that you've made, um, you can always send me an email and I will check whether that makes sense to me, um. Cool, um, what else is there? Assignment to groups, that was fun. Hopefully everyone now is in a group. I only noticed on Tuesday or something, Monday or Tuesday, that there's an extra set of groups that students can create themselves and lots of students have created their own groups. That was delightful. Um, I think broadly, everyone should be in a sensible group now, I think. And if you're not, again, just email me, I've already received. Probably 50 emails on this topic, maybe, maybe more. Um, but hopefully that's all sorted, um. I, I was joking with my colleagues that I should give you guys marks for putting yourself into groups, right, like as in there should just be like one mark. Can you put yourself in a group? And then people would actually do it before the deadline, and it would be great. Alright, uh, what are we doing today? So we're doing um. I own hard drives, right, so today and I I and solid state drives. So today we're, we're not talking about like the abstraction so much today, we're talking about more sort of some well there is still some abstraction, but we're talking about some implementation stuff about how stuff actually works. Um, it's a, it's a good question how relevant this will be going forward, right, um, it's still, it's still relevant, but. Let's, let's begin. Um, so today we're gonna be talking about the canonical device, direct memory access, hard drives, and solar state drives, yep, that sounds right. Um. And then last week we're looking at 74s. OK. So, so far, right? We've, we've looked at, you know, scheduling, and we've looked at memory, and we've looked at all these other things. And then we've talked about IO. You know, like when we were doing scheduling, we're like, oh what if they need, you know, the, the, the system needs to use IO? What does that actually mean? Like what does it mean for a system to actually use IO, right? Like as in like, how do, how, how do you do that, right? Um. I mean, this should be obvious, right, like why, why do we use IO cause like. Alright, so let's talk about like original computers for a moment and, and sort of see where this comes from and where it goes to you, because it kind of informs sort of like the logic of how we're going to approach this problem. But in, in the olden days, and if you watch any movie from the 1950s that has a computer in it. Um, or Star Wars, Star Wars as well, that has that kind of vibe. Um, there's a lot of lights on screens, right? And basically, with computers originally, the idea is that what you would have is you have a whole bunch of physical switches, and each of these physical switches would be in binary, right, right? So if you wanted to, To do something, you could flick a switch and it would make a binary, right? And you could make binary numbers essentially or binary commands, and then you'd have these lights and these lights would pop up with binary, right? And then you could interpret the lights as binary, it's the easiest way of, Easy's not the right word. It is the least effortful way of trying to represent what goes into and out of a computer, right? Um, because there's no processing here, there's no interpretation, it's just literally raw numbers. OK. In the 1970s, is it 1970s? In the 1970s, when my mother was going to university, she used punch cards, right? Um. Yeah, it's weird, my mum did like one computer science course for fun as part of like a, a what do you call it, like a psychology degree I think she was like. But anyway, she was talking about, she's, she has fond memories of this. So basically the idea is what you have is you have this card and it's got holes in it, and you, you get a paper punch and you punch the holes, and the holes are your program in terms of machine instructions. Right, so if you can imagine each one of these like lines. is an instruction or columns is an instruction and then you've got a whole series of instructions that go across, that's your program. And you have a physical machine that reads in the holes, right, so basically it has a physical like hardware device that goes, oh, is there a hole or not? And it reads that in as your program to the computer. And then, once it's finished, it would print these holes physically onto another card, right? So you, you put in one card and you get out a second card and both of them would have holes in them. Um, and that was how we would represent, You know, programs back in the day, right? And so this is beginning to look at sort of like the basics of like the concept of input and output, right, like as in things going into machines and things coming out of machines, right? So, nominally we're reading binary numbers and writing binary numbers, right? Um. So the way that we do it now is way more complicated, and I'm not gonna go into a huge amount of detail about it, but like, basically, you know, like you've got these buses, right, so you've got, you know, your PCI and your SADA and you know all these other random ones that I'm really not a hardware person, so I don't care about. Um, so, but they, they're basically just channels through which you can like channel data, right, like so you can just be like throw data down this thing, something else will read it from this, this, this bus, um. And there's a whole bunch of stuff that we've got here, right? We've got our disc controller, we've got a USB controller, you've got video adapters, you've got sound cards, you've got network stuff. There's, it can be as many things as you want, but basically you've got the CPU who's thinking, and then you've got all these other things that are like either taking data from or pushing data to the bus, which then goes eventually to the CPU, right? So it's just a transfer of data. OK, so at this point in time, pretty much everything here can be considered IO in a way, right, like even the, the discs are IO, right, in a, in a kind of way, you know, mouse and keyboard is a kind of IO, monitor is a kind of, Oh, unless you've got a magical touchscreen monitor, I guess, in which case it's I as well, um. And just as a sort of a matter of course, because we have so many different kinds of devices, different architectures, we'll try and like create all these different kinds of buses, right? Um, so you know like who who here has actually physically put a computer together? That is to say, OK, not that many people, right, like I remember when I was in my um undergrad, I had a friend. And I was in 4th year engineering, and he had finished his computer science degree, and he called me up and he says, oh, can you help me install a hard drive? And I was like, but you have a computer science degree. And he's like, yeah, but we didn't learn any of this stuff, like we never took a hard drive and undid a computer and then put the hard drive in, right? Um. So, one of the things I would recommend is that you do this at some point in your life, is, is you custom build a PC, right? Like, um, simply because in the process of doing it, I mean it might be easier than it was when I was a kid. I don't know, um, there's more chaty PT to tell you exactly what to do, and we had stuff about jumpers and stuff that I didn't realize was going on. But um. Um, actually put it together and then you can look at all the different buses inside a, you know, on a motherboard, on a motherboard, you know, it has all these different slots that you can put different things in and depending on the kind of thing it is, it will be able to go into different kinds of slots, and you've got PCI slots and you've got, you know, um, a whole bunch of them and I can't remember the names of all of them. But anyway, there's PCI Express as well, um. OK. What? Device controls, loco buffer storage and a set of special purpose registers. Yeah, this is all I owe. I all IO comes down to this, right? Like there is a, there's a level where every piece of IO does something different, right, you know, like a mouse is not a monitor, but from the perspective of a computer, a mouse and a monitor are not that different from each other, right? Um, as weird as that sounds, um, because from a computer's perspective, really it's just a case of like, oh, OK, um, it's going to be sending me data, or I'm going to be sending its data. And that's it. That's the only way that a computer can actually think, right, like that's all it can think about, it's just like ones and zeros, right? And so we're gonna essentially treat all devices, as long as we can come up with a framework where we can sort of, Control all devices using one interface, then we'll do that, right, like it's computer science, we'll just be like uh everything is ones and zeros, so, um, I'm going to get some ones and zeros, I'm going to send some ones and zeros, and I guess I need a couple of extra bits to control that, right? Um, and that's it. So You know, we have common registers, blah blah blah blah you could can read this yourself, but basically what we've got here is we've got sort of this idea it's like, oh, OK, so we've got like a status, a command, and data, right? Like it's, it's not much more complicated than that. That, that is to say, like, you know, like what is the machine that we're trying to talk to currently doing? OK, cool, um, what do we want it to do and What is the stuff it needs in order to do the stuff that we want it to do, right, cos in most cases you can imagine that like you might want, um, you know, like what's a good example of something you might output a command to? But you, you know, like, like uh mouse, right, mouse is gonna give you like, it's gonna move, right? And so those commands are gonna come up and you'd be like, give me, give me the moves, right? Like is it, how did you move? Give me the clicks. You're gonna have to have something like that, right, like it's some kind of like. Tell me what to do, and then there's gonna be some data, which is like the location or the button that was clicked, right? Um, and then yeah, status, it's like, are you ready to tell me that you're about to move, that kind of stuff, right? And if it was for a monitor, you know, the status might be like it's currently, Spraying stuff onto the screen, please don't give me any more information, or it might be like you're writing to a back buffer or something like that. And the command would be like, let me write crap to you, and the monitor would be like fine, right, and then, then you would write lots and lots of data to the monitor in the form of like graphics, right, like uh the, the values of pixels, like hundreds of pixels, and you'd be like pixel data, down this, down this cable to this machine and then it will interpret that stream of numbers and turn it back into a picture on the screen. Um, and that's basically it, I think, give or take, end of lecture. Alright, so here's an example of like how we could do it, and it's a very simplified example, but it kind of represents every single device that ever existed. While it's busy, while the device thinks it's busy and is is too busy to do anything, right, um, you wait, right, so you just do another spin lock, which we'll get rid of eventually. And then what you do is you write some data to the register, right? So you write some data, and then you write a command to the command, right? Um. And then, and then that's it, right, and then you, you wait until it's not busy, right, like it's, it's, it's not a very complicated idea. Um, so you're basically preloading all the data and then you have a command, and then you're like, command, do the thing, right? um. Now, burning CPU is probably a bad idea. Um, so if we think about the IO request here and we have this CPU here, like the device is currently processing, let's say C, right? And we'll say the IO request occurs when that red arrow comes in. We've got this area where the A is just spinning, it's just waiting for the IO to become free, right? And then at some point in time it's going to write some data, right, according to the data register, then it's gonna write the command, right? Um. And then it's gonna do some IO stuff while it's waiting for the IO to finish, right, like as in basically presumably, presumably, you know, the IO needs to do something, and then we will receive a you did it command at some point, so I'm gonna keep on pulling this thing and be like, are you ready, are you ready, are you ready? And then once I've got the stuff that I want from my IO and my IO is done, then I can do the rest of my CPU stuff, and then I'll run Process B. Yeah, it seems fairly straightforward, right, so we've got like 12345 steps, right, give or take. Yeah, um, but it kind of sucks, right, because, you know, like, like why are we waiting? Like it would be much better if we had a system where there was like, um, instead of polling it and constantly being like, I'm doing nothing, I'm waiting, um, we, we, you know, yield the CPU essentially. Um, and so we can set it up like we have for, you know, everything else that we've done so far, like the producer consumers and stuff like that, and set it up with interrupts. My God, we're gonna talk about interrupts again. Every lectures about interrupts, right? Um, and so we just set it up so the IO device is gonna ping the CPU and tell it when it's ready. And if we do that, we'll end up with something that looks a little bit more like this. To explain this in detail, you can imagine that so A, at the start of that first little red bit, got its interrupt, oh sorry, got its IO request, but because the IO is busy, it's going to seed the CPU and give it to B. Then when B's time is up, Right, it's gonna get back to A. A can do it's two things, writing the data and write the command to the command register, and then it will wait um until that job is finished and then when B is done I can do more A stuff afterwards, right? So, You can see here if I compare the two, you know, like, obviously a lot more B got done while I was waiting for A, and that's basically all that it's really trying to say. Um. Yeah, so polling sucks, um, we've talked about this before, I don't want to go over it again, but, um, basically, Interrupts are generally better. We discussed live lock, right, so that you could be in interrupt hell hell where they're interrupting each other forever, so it could be, can be bad. Um, and you have interrupt coalescing, fun times, um. One of the options is you can do a, a hybrid, right, so one of the, the models, like if, like, uh, I think I covered this before as well, but like one of the ways that you can have it is you go, I'll spin for a little bit, just in case, because descheduling is expensive, right, so you can imagine that like when you deschedule from the computer to put in another process. That's an expense, you know, I've gotta take everything out and then put it down and take everything else out and put it in. So instead of doing that, what I can do, I'll, I'll just wait for a bit. Alright, alright, and if it goes immediately, if it's a quick thing, then we're all good. And then if, if I spin for too long, um, before time X or something, it's not a short job, then I will, um, see the CPU and do stuff. Alright, OK, so how do we do it? Um, there's two ways of connecting IO. Like, I mean, if you think about it, like conceptually, um, I just said that IO consists of this nebulous command place, the nebulous data place, and a status register, right? So the question is, where are those things? Yeah, right, OK, where in the computer are they, right? And there are two options. One is port mapped, right? So port mapped means that the computer knows it has rules. It tells you where these things must be. And you can imagine that this is done by someone who is like super inflexible and uh basically was like, no, no, no, no, no, no, no, we should have a special place for the monitor and we should have a special place for the network code, and we should have a special, and that's why it's used on X86, which is the, you know. Where Windows comes from, right, um, which is why old Windows systems were really, really annoying to use, right, because they basically had all of these, you know, special IO places within the hardware architecture where they were like reserved memory, specifically for IO. And the other way of doing it is where you're just like, it's a bit of memory. OK, I'll just put my IO here and you can write to it, you can read from it, and it's just, and this is the Linux way of thinking about things. And this is why Linux is conceptually a much easier system to deal with, um, especially if you're a developer, because you don't really need to know that much about Windows. Right, like as in like with with Windows you need to know a lot of stuff, right, but with Linux you're just like, oh it's a file, OK, so I just need to understand how it's using that memory, right? So I'm just gonna say this bit of RAM is actually a hardware device. Sure, right, and a hardware device means, you know, some registers and a command spot and some data spots. Um The one complication here is caching, right? So we've gotta be a little, a little bit careful about this, right, because you can, you can think about it as like, oh, but what if I cache the hardware device and you're like, Alright, what does that mean? It's like you're taking a copy of its status and pretending that that copy is the real thing, right? You can see how that would be really, really dangerous, right, like because you can be like, oh I think, you know, I've cached it and is it actually ready or not, I don't know. Right, like as in because I'm just reading cache or something, right? Or maybe like, um, you know, like, basically, you know, if I have something that has, you know, specific timing, I don't want there to be an extra layer of caching interfering with that timing. Um. But yeah, you know, this CPU, the port map toio has special ports for each of its inputs and outputs, whereas the memory mapped, uh, memory mapped IO is basically just one gigantic shit ton of memory. In general, I think what they do do is they do kind of reserve it, you know, a kind of order if that makes any sense, but, um. Not, not quite as, not, it's flexible, you know what I mean? But there, you, you, you'll find that there are probably, um, what do you call it, conventions. Um, but it's not much more than that. OK, cool, alright, so that's, that's that, right, like that's basically describing all of IO. So if you're doing IO from a Linux perspective, it's really trivial because it's just a file, and if you're doing it from a Windows perspective, Well, I don't know how Windows works now, but if an X80, old school X86, it used to be a real pain. I don't, I haven't done that much stuff with Windows IO recently because why would I want to kill myself. Um, so the next thing that we're gonna do is, um, direct memory access, right? OK, so. What's this about? OK. We have a motivation? Oh yeah, OK, I do have a moti motivation. So here's the problem, right? One of the things that we tend to do, Right, and if we've taken the view that a hardware device, like a physical disk is a kind of IO device because we're taking input and output from it, it's not part of our computer, we installed it separately, right? Or like a USB, let's say a USB is probably a better analogy. I had a little USB. Right, and I would like to copy some data into memory, right, so there's something on this UFB that I want to load into RAM. So how do I do it? OK. CPU says that's my job, I'm the one who does the copy, right? So what I'm going to be doing now as the CPU is I'm going to be copying stuff from the USB. To the memory, right? So I will copy this bitte. And then I shall copy that bite. Because my CPU needs to be involved in every byte that is copied, right, because I, I basically it's go, oh, I will copy, I will, I, I, I will do this one and then I'll do that one and I'll do this one and I'll do that one. And so what you end up with the situation where the CPU is basically sitting there, all it's doing is copying files from one location to another, and that, that's kind of an insane thing for a CPU to be doing cos normally it's really meant to be doing, you know, computations. Um, and so basically, One of the problems with this, this idea of what I think it's called Programmed IO, right, which is um. Where you have this, you know, cop, the, the IO device is being controlled specifically by the CPU, um, Is you get this, you know, copier byte, copier byte coppier byte, right, and the way that you think about it is this, it's like I'm trying to go from the device to the RAM, via the bus, but I'm also going via the CPU for some reason. So what people came up with is this idea of a direct memory access controller. And so the logic is that like this job is very hm routine, right, like it's it's like it's a kind of a predictable job, right, like it's not like a you know cos CPUs are meant to do smart things, right? Copying stuff from one file to another. Is not a smart thing, right, like this does not require a lot of thinking, right? So if I'm trying to copy from like, I don't know, from a device to my RAM, right? I don't need my CPU to be involved, right? Because all I really need to do is be able to go, oh, start here, I want a copy from here. To here, right, and I just wanna do that in sequence, right, over and over again, so it's like a giant for loop, right? And so what we do is we create this like um DMA and the CPU all it has to do is say where and how much, right? Like so it goes where do you want to start copying from, where do you wanna finish copying to, and then the DMA, the DMA controller, basically pretends it's a CPU kind of, right, for the purposes of this, um, in doing the copying, right, so basically this the DMA will talk directly to the ramp. Right, and then the DMA will tell the CPU when it's done, right, and then the CPU will be like, I didn't have to do anything, right, so it's kind of just like a. Uh, what's a good way of thinking about it, right? Like, it's another analogy would be like a graphics card, right? Like, so, you know, if you have a computer, you, you would often have a graphics card, right, with your computer. Why? Because the graphics card is good at doing specific kinds of calculations, right? Now all of those calculations could be done on the CPU, but because they're so stereotypical and they're like, they're inefficiently done on the CPU, we have an extra bit of hardware that we have developed that performs that role. Well, the DMA is basically like a graphics card but for copying files, right? Like, like it, it's basically a bit of, You know, specific, um, construction that we have that all it's job is is copying files, um, and in this case it's mostly just to relieve the CPU. Um, Yeah, so the, the, the, the difference now is that like instead of having to write the data to the register, I just need to like write the command. Right, like so I'm not actually copying the the, the, the um the data in, in this process, so I'm just going, oh just do the thing, right, and then all I have to do is do that. I don't have to like queue up all the data and then copy the data across and wait for it to go across the bus. Um, and that's it, that's a direct memory access. Again, not, not super complicated, but you know, um. Um So, drivers, drivers. OK, so this is the bit where it gets messy, and this is the bit where we don't go into much detail because like of how ridiculously messy it gets. But um basically, In order to facilitate this, we have now said that the operating system conceives every single piece of hardware as the same kind of thing, right? Now in reality, each bit of hardware is not the same kind of thing, right, like as in that like they, you can abstract them to this level, right, where they have status, commands and data, and you know, are they ready or are they not, but you, you know, like beyond that, you can't. Then assume that they all do the same thing, right, like obviously a monitor is not a graphics card and a graphics card is not a hard drive and a hard drive's not a USB and a USB is not a mouse, right? They're all very, very different, right? And so device drivers are basically just bits of code that handle this weirdness, right, it's, it's essentially a piece of translation, so it's gonna turn, you know, whatever the device actually does into um stuff that the operating system can meaningfully interpret. So, basically we have our OS and we have our generic interface and then we have our device, right? And the device driver sits here where basically the OS in, you know, pulls stuff out of the um generic interface, which is just, you know, streams of data and commands, and then says what it is, right, so it has to translate it, right, so basically for every device, there is a driver. Who here has ever installed a driver? Oh good, right, you know what I mean, like, um, it used to be really, really annoying, and now because the internet exists, it's really, really trivial, but like basically whenever you got a, like, if you got like a network card, it would come with a CD and on the CD would be the driver, and then you would have to, you know, put your network card in and then you'd have to try and get it to load the driver and if the driver, there was something wrong with the driver then you were completely stuffed. Or if someone lost that CD and they, they were like oh. I want to move this to another computer and they'll be like, oh, where's the driver, what device is this? Does it have a label on it? Oh damn it, where do I get the CD with, you know, like the magical piece of code that allows this thing to work. Um And so yeah, um, there's this quote here that's kind of funny, it's like 90, 70% of Linux code is device drivers, right? Like most, and it's kind of true, right, like as in basically Linux itself is designed in this very generic kind of simple way. And so all of the complexity is basically foisted upon the people making the devices, right? But this is kind of a preferable way of dealing with things because it means that your system can be very, very flexible, that is to say, if you can write your own driver and provide your own device, then you're all good, right? Um. And yeah, it came on CDs. There's a bunch of other ways, right, um, in Macs, Macs this used to never be a problem. Did anyone own a, oh I guess Macs is still the same way, right? Has anyone ever installed a driver on a Mac? Really? No one has. It's good because that's a trick question, like why would you, because all the drivers are already pre-installed, right? The only, the only way to install a driver on a Mac is to sort of install the Mac, I guess, right? Um, So that was why uh Macintoshes were really cool back in the day because basically all the hardware, it was just one box, you know, like, um. And yeah, this is like just another picture, I don't know why I included it, I just copied it from last lecture, it's basically the same information but just as a picture with lots of, lots of different things. Um. I already said what this is. This slide probably should have been. Could've been earlier, yeah, there's nothing here, but basically it's just translation. OK, um. There is a sense in which you can divide a driver, right, like into two sort of two sections, right? You can have this idea of uh the top half of the driver and the bottom half of the driver, right? Um, and it's this, this distinction is really about the sort of like, sort of the outward facing and the inward facing part of the, the drivers, right? Like so each driver is going to, you can see here it's like, um, Yeah, the top half has the kernel's interface to the device driver, right, so this is how the, you know, the OS understands what the driver is, right? Um, and, and basically it's going to turn everything into read, write, open, close, and, um, different kinds of control calls, right, so like, you know, you're reading streams of BART data, you're writing streams of data, that kind of stuff. And then you've got this like bottom half, and that's gonna handle like a whole bunch of like the interrupt stuff that happens when you have a driver. Um, like how does, how do these systems talk to each other and when do they do them, and then like also, um, direct memory access, um, allocations. Um, but basically what you can do is you can sort of think about like how this works in terms of like a flow chart, right, to give you an idea or a flavor of what this actually means. Um, so you can imagine that you've got this user program, right, and you've got the program that someone has written, right? And it requests IO, right? And so the kernel, It's gonna have some system in it that's basically gonna be like, oh yeah, is it ready or not, right? And in the event that it is ready, right, it is going to just do some data transfer, so you know, like the device is either going to be read to or read from or did I request IO? Yeah, I just said request AIO so it's gonna be, you know, like I'm either gonna be pushing data into the, Device or I'm gonna be dragging data out of the device, right? And then I just, you know, I'll get a signal that says it's done and then, you know, that data will then come back into my application, right, in some way. So I've now requested some, like say I'm asking for something from a hard drive I guess is an easy way or I'm trying to get the location of a mouse, something like that. Um, basically I go, is the mouse ready to give me that information? If it is, then it will transfer the data, um, to me and then I can uh to the, to the kernel and then it can go back up to the IO. All things is, all things is fine. Um, but if it's not, right? If, if the data's not already there, then what I'm gonna have to do is I'm gonna have to actually query the device and ask it to do something, so this is more like, like get data from a hard drive, which might take a while to do, right, so I'll send a request, right, and so I'll send my request to the device driver and now we've got the device driver, right, and it's going to have to process this request, so if we now, sorry, shift up, I didn't animate this as well as I could have, um. Basically we're gonna have some device commands that you know like in order to process the request, it's going to turn that into some kind of language that the device understands, right? Cos each device is going to have, you know, like basically it's gonna have its own kind of interface, if that makes any sense. So the driver is gonna be doing the conversion to the correct interface so that the device can actually understand what's going on, um, and then basically what you're gonna do then is you can what's this say monitor, device, interrupt when IO complete. Right. So basically this is where the actual work is going to get done, and over time, right, theoretically, it's going to do stuff. The IO is going to like, I don't know, um, copy. Stuff from some sector, like a, a good a good analogy would be if you had, does, does anyone have the old um cassette tapes? Has anyone ever seen one of those ones where they like you spin it and it's got like a, it's like an old VHS and you can pull the tape out or have you ever seen a movie from like the 19. 70s or whatever and then and you get the pencil and you have to manually wind the tape so a lot of old discs have this, they're they're all these really big long bits of tape so you can imagine that when you ask for it for a bit of memory, it's gonna be like. Right, until it gets to the part of the tape that contains the piece of information that's relevant, um. So yeah, um, and people still do use backup tapes, so that's definitely a real thing. Um, but basically time will pass and eventually when it's done, when it's managed to get to the location it is and it's ready to, um, copy that data across, and we'll talk about how that works in a hard drive in a little bit. Um, but basically when it's ready it's gonna generate an interrupt, that's gonna be rece um received and then we're gonna store whatever data that gets transferred from the device into the device driver, which can then get translated and then we can work out, you know, is it, is it ready or is it not ready, how, you know, like what are we gonna do with it? Um, and then we can finally start passing that back-up, tell the, um, system that we're gonna do the data transfer, which is where we were before, and then we finally get to the point where the IO is completed. Right, and that's kind of what's gonna happen, right, like, so there's sort of this, you know, you, you make a request within the application, the kernel then has to think about it, it then sends its request down to the device driver, the device driver has to do a translation process. The device driver then talks explicitly to the hardware, the hardware does something. Then sends an interrupt back to the device driver which re register that interrupt, copies the data from the device, and then copies that data back up into the kernel, and then that data eventually ends up in the user application process, right? So hooray, that's what an IO request kind of looks like, um. And this is where we get, you know, like, um, I don't know if you've done systems programming with me, and well, not with me. If you watched my lectures for it, I would have said this, but I'm sure Matt said it as well. Everything in Linux is a file, right? Um, and this is where we get this idea is that basically everything is either reading from or writing to a file, right, like it basically all works out to be the same kind of thing, um. I skip a thing? Did I skip a thing? I feel like I should have a little. Title for this one. am I talk, just sorry, give me a second. Uh, am I actually going to be talking about drives? Or have I got this in the wrong order? Do devices, drives, makes it possible don't, yeah. Oh yeah, I mean, OK, so this one. I think I'm just trying to say that hard drives are also a file, right? Like, is the point of this, right? So like, um, basically the idea is that you're just accessing blocks of data, right, so it's like an IO device where the only thing that you're actually accessing is these blocks, right? Um, and, It means we're gonna have a bunch of commands, we're gonna have this extra command called seek which we'll cover when we're talking specifically about hard drives, but like we've got open, read and write, you know, like, can I make the machine do the thing I want, can I read to it, can I write from it, um. Yeah, and, and yes, you can do, uh you can use your DMA uh for this one as well. Uh. Yeah, this was interesting because this was like um if you go into slash dev, right, um. What you can do is like, when I say everything is a file, this is actually like material proof of the fileness of literally everything. Right? So if you go over here, sorry, right, um, in Linux, right, you can see that here there's like a little D, and that means it's a directory. So those would be the ones that you've probably seen before. But unless you're in dev, you're not gonna see these a lot. Um, but if you see this where it says C, C means it's a character device file, right? And then B is a block device file, right, and P is a named pipe and S is a socket. So within Linux, basically, it does differentiate them, but it differentiates in this kind of way, right, like what are we doing? In a hard drive we're accessing blocks of data. In some other devices we're just accessing characters generally, right, so in a, you know, a hard drive, I'm not gonna ask for one byte, I'm gonna be asking for like a gigantic block, right? Whereas with a mouse, I might just be wanting to know one piece of information or you know, a few pieces of information. Um, So character devices, as opposed to block devices, that's where this was supposed to go, um, basically refer to things like mice and keyboards and serial ports and stuff like where you're just throwing characters rather than giant blocks of data around. Um, and this has, you know, standard commands like get input, right? Um. Cool. And then we have network devices, right, and you know we have them for pipe pipes and then FIFOs, which is, I've never really understood the difference between a pipe and a FIFO, they sound like the same thing, but a FIFO is a kind of um stream. And then you have streams and queues and mailboxes and that kind of thing. So, um, the network ones, because networks is like a little bit more nuanced than just characters and stuff, it's got its own, um, Uh, universe where you have sockets and um functions like select and so forth like that, and if you've done CNA you would be aware of how sort of intricate, sending things over sockets is cause it's, there's more, there's protocols and a whole bunch of stuff laid on top of it. Um, so yeah, um, in terms of the timing, right, we can also have this idea of different kinds of, um, timing when it comes to these devices, so you've got like, what is it, blocking, right? Um, so basically the idea is that, When you request data, you sleep the process until the data is ready, right? When you write the data, you sleep until the device is ready for the data, right? So a blocking interface is basically, I'm going to, I want to do something, so I'm gonna write to the hard drive. Something like that, right? And then as soon as I get interrupted, I'll be like, OK, then I'm not gonna do anything for a while, I'll wait until the IO is done and then, um, you know, uh, pick up when it's finished, um. A non-blocking interface is basically going, do it, how much have you done? Do it, how much have you done? Do it, how much have you done, right, like, um, so it, it, it sort of, it comes back and it, it sort of, it tells you how much that it managed to do over and over again, but it doesn't really block, it's sort of like continuously hammering the thing just going, I want more, I want more, I want more, right? Um, and sometimes it will return nothing, like, as in if it's actually like the hard, the hardware is not available, it'll just be like, I tried to write something and it was 0, what a success. Whereas the other one would be like, come back and come back later and tell me when you're done, right? Uh, this is more like, you know, a micromanager kind of um thing. Yeah, and then we have an asynchronous interface which is literally tell me later, right? Um. So Yeah, Winston. Next Yeah, I think it, I mean, let's just, let me just double check if I've got. Data take pointers to use buffer, return immediately. Later camera as buffer and notifies us, yeah. Yeah, so this one is basically like it, it has a, the, the, the distinction here is it has an instantaneous um return, right, so it's basically this is where I'm up to. Right? Um, and it's to do with like the, the reason that you would like dis differentiate between these ones is, is literally to do with the, the way that you want these different kinds of systems to behave functionally, right, like, so. Yeah, it's all to do with this, right, so, you know, like I, like for some devices you want them to be really, really responsive and you don't care whether they've done it or not, you sort of just want an instant response from what, you know, like what, where are you up to, what have you done? Right, you know what I mean? And then for some systems, uh, and for uh for different um IO devices, it's, it's more a case of like, It's only useful once it's completed its actions or its operations. Um, and so you would choose different kinds of, um, interfaces depending on what kind of um one that you wanted to use. Um. Yeah, device types, there's lots of different device types, as I said before, you know, you have like um. You know, they're talking about things like access patterns, so, uh, a block device is one that's asking for like a lot of stuff that's all in sequence all the time. Um, there are other devices, you know, like a mouse, the mouse is giving you random crap all the time, and the main point with the mouse is that you want it to be pretty quick, right? You just, I, I don't care if it's, I do care if it's accurate, but I, I want to have my mouse updating very regularly. Um, and so, again, you know, the kind of device will determine the way that you, um, try and set it up. In your machine, sorry, I'm just gonna move that. Alright, um, alright, so that's basically all of IO I think, give or take. Now to get into very specific IO, right, so a good fun one is hard drives. Um, has anyone here actually got a disc hard drive? Is everyone else on solid state discs? There's people not know what the difference is. Yeah, OK, cool, alright. That's why you're here, we're in operating systems. OK, so. Tape drives, as I, I was saying, these are, these are tapes. When I was a kid, this is how like the Sony Walkman, right, which was this like the predecessor to the Discman, which was the predecessor to the iPod, which was the predecessor to the telephone, apparently, um, basically would take tapes, right? And so what a tape is, if you can imagine, is it is a piece of literally tape, like measuring tape kind of thing, but it's a specially encoded magnetic tape. And they were wound into spools, right, and these are still being used, I know they are still being used, and the they're mostly used for backups, right? And the reason that they're used for backups is because basically with a backup what you're doing is you're sequentially copying large amounts of data, right? So you don't care that it's takes ages to spool because you're basically spooling. It's in order, so that's, it's like best uh mode of operation. Um, and the tape itself, basically what you can do is you can sort of zap it with magnetic fields and it will store that information, right? So you can use it to like, it's almost like rewriteable paper, right? So you've got this really long strip of rewriteable paper. Um, that you write stuff on, and then you wind it up into a spool, and because it's wound up into a spool, it can be incredibly information dense. But, as it says here, it is incredibly slow, right, because to get any individual piece of memory that you want, it has to wind. Now I had a friend who had, I think it was an Atari or something like that, it was some really old, um, like predecessor to, like a Nintendo, and it would take discs, right, so you would put a disk in. And then you would have to wait for it to load the game into RAM, right, so it's like winding through this tape, essentially like copying data into the RAM of the computer, and then eventually you get to play this eight-bit game, it was, it was great times. Um, but yeah, incredibly dense. OK, so the compromise for that, this is where, like, this is where the technology was for a very, very long time, right, so when I grew up this is what I understood a hard drive to be. Hard drives still do exist, you would still get these kinds of um disk drives. They are being slowly replaced with solid state drives which we'll go through later. um, but basically the idea is that what we're gonna do is instead of using a long tape, we're gonna use like a circular tape, right, and the advantage of the circular tape is that I can wheel around to any part of it reasonably quickly. And so instead of having one long tape that is sort of one dimensional, I'm gonna have a kind of two dimensional tape, right? I'm gonna have little sectors on it and I'm gonna write stuff to this disc, and it means to get any individual bit of the memory, all I have to do is spin the disk to get to the right location. It's pretty dense, it's quick enough to not be really, really annoying, um, but it was still pretty annoying because it meant that like if you were loading a game, games used to have loading screens, whereas solid state you're just like memory, done. Um, so. In terminology, we have like tracks and we've got arms and sectors and spindles and platters, and they are marked on the diagram. But basically, if you can imagine, they have a whole bunch of discs, cos why not, right? And then they have a whole bunch of reader writer heads, and then basically we're gonna divide it into little areas called sectors. Yeah. Yay, and it spins. So some practical questions, how does the disc know where it is, right? Um, cause you know, like, it's one of those things you're like, oh yeah, OK, how do I know where I'm up to? Um, and one of the problems that you could have is that your platters could be misaligned, right, like as in like if it's got, you know, it's a mechanical device, right, so if it's slightly off, you're in a bit of trouble. Can you read the data to work out where you are? Um, but it requires some pretty high precision manufacturing. And um modern hard drives of this kind apparently contain helium, and the reason is is because they, helium is really, really small, like physically as an atom, for those of you who've done chemistry, you know, hydrogen and helium. Probably wouldn't want to have hydrogen. In a disc, but helium is OK, and basically if you put helium inside it, it means that You can't scratch it, and like the, the, the heads that read the disc, basically like, like a particle of smoke is too big. It gives you an idea of like the precision of the manu manufacturing. um. Yeah, so what we're gonna do is we've got this magnetic disc, we pass a field over it and we change its state and it lasts a long time, right? And then we've also got our servo system and that's just gonna be about, you know, um, operating where on the disc we're gonna be, right? And the old way we used to do it, it was, it was apparently with notches, which I thought was pretty funny, right, like that is to say that like there would be, you know, in your machine there would be like physical notches in the spindle essentially so that you could work out where the spindle was relative to its rotation. Um So, if we want to copy to or read from a hard drive disk, now we've got to try and work out what our latency is, right? And so there's a couple of different parts to it. One is to seek. So to seek is basically, if you can imagine you've got your reader and you, you like you've got the big disk there and you've gotta try and work out where on the thing you're gonna go, so you can either go backwards or forwards, right? So that's basically, you know. Are you at the middle of the disc or are you at the edge of the disc, right? Um, and so, one of the things that's cool about seek from a calculation point of view is that it's very deterministic, that you, you like you can know how long it's gonna take your little mechanical motor to go either into the middle of the disc or how to come out, right, you don't have to think about that too hard, um. And yeah, the average, you know, you can work it out that the average seek distance is about 1/3 of the maximum seek distance, right, so you can make a pretty good approximation. Um, then you've got rotate, right? And so if you can imagine this disk has lots of locations on it, and basically when hard drives are spinning, they literally spin at whatever this RPM is, and the idea is that you just wait until it's your bit and you go read, read, read, right, when it gets to the bit that you want, because it's just constantly spinning. Um, and it has different speeds and you know, like if it's faster. It means it should nominally have lower latency. But it would be harder to make a disc that can, you know, store that amount of information, then you have to have a more sophisticated reader and writer that can read. A disk that's spinning at 15,000 RPM, which is pretty fast, um, but you can work out the average rotation, so like here there's a calculation there's, it's 72,000 or 7200 RPM. That's rotations per minute, so in one minute. Yeah 72,000, so one rotation is 8.3 milliseconds, right? And because on average, the amount it will have to spin is gonna be about half the disc, then you can make a calculation and say, OK, the average rotation is 4.15 milliseconds, right? So we've got the seek, which is like the little thing going out, and then we wait for it to spin, and then it's in the right location, and we can't do both at the same time. Why can't we do both at the same time? If people are actually paying attention. Why can we not seek and rotate simultaneously? I Well, like for see we're going in, right? So if this thing is spinning. Right? And I'm going in at the same time. I have no control over its spinning, right, like no control, right? Otherwise I'd have to stop the disk to get it to the right location and be like, I'm gonna read here. Right, but the thing is constantly spinning, yeah? So, so I can't get it to spin to the right location because the spinning speed is like. Constant, right, I guess I could slow it down, yeah. Is my microphone on? Oh, OK, um, I can. Make it a bit shorter. How about this? Better? It's, it's the same. Oh, well then I have no control over it whatsoever. Unless this has got a like a. I don't think so. Um, anyway, um, so, um, maybe I'll go around this side then. Maybe it's canceling me out because I'm on that side. Um, so basically, let me, let me, let, let me explain, right? Um. I'll just make a new presentation. So if you can imagine, right, you've got this, these are the choices that you've got, right, because basically the idea is that I'm trying to get to this location over here. Yeah. And if I want to get to that location over there, I have two choices. Either I can spin the disk until it's in line with my reader, let's assume that my reader is over here. Yeah. And then I move my reader in and out in order to get to the right location, right? So what actually happens in practice is this thing is constantly spinning, right? And so I'm just gonna race here as fast as I can to get to the right location, and then I've got to wait until it rotates around to get me, right, like I can't do both at the same time, because if I did both at the same time I'd have to change the speed of the disc, and then the disc would start accelerating and decelerating and that would just break everything, um, and probably wear out the hardware amongst other things. But instead, it's just constantly spinning, so basically what will happen is that like I've gotten to the right location and this is where it was when I reached my location, now I have to wait for it to get all the way around here, and then I read. And then I'm done, you know. So that's how that, um, that's why you can't do them both at the same time. OK, um, and yeah, it can be pretty fast, right, because the RPM of these things is really high, you know, um, and obviously the faster it is, the more you can do, the higher the data density, the more data you can do, so if the density of the data is higher, it means in a smaller amount of turn, you'll have covered more data, right? And so again that would increase your, um, Throughput and then the, what do you call it, the, the more you request, the more data you're gonna get, right? Um, but yeah, typically it's gigabytes per second, so that's actually pretty fast, right? Um, and, This gives you an idea, so if you wanted to get 4000 bytes at 1 gigabyte per second, it would take you about 4 milliseconds to do so, so it's pretty good. Um, so, one of the classic things that we could ask you in, uh, exam, if we were asking you a numerical question just for the sake of it. What is the throughput? Uh, how would we calculate the throughput of these things, right? OK, so how would we do it? Right, we have a cheetah and we have a barracuda. Uh, off the top of your head, which one do you think is the better hard drive, by the way? Who votes for cheetah? Who votes for Barracuda. Uh, one of these classes, people who don't wanna vote. Who wants to vote? Everyone wants to vote. Alright, not everyone wants to vote. Oh God, why am I even here? Alright, um, but basically, um, you can see here that the cheetah, OK, let's look at the numbers. So the cheetah spins faster, yeah, um, the average Sik time is shorter, the max transfer rate is higher, the number of platters is the same. Um, it's got a smaller cache and a smaller capacity, right, so. I mean, I don't know when this was made, like I mean you could probably get like, I don't know, a petabyte. What's the, sorry, just out of interest, I haven't bought a USB. What is the largest USB anyone's ever had? Yeah. Huh? 3 terabytes. 1 terabyte. Alright, so we're up to USBs that contain 1 ter. Can anyone beat 1 terabyte? OK. That's an ins sorry, when I was a kid, I had 779K, alright, that's what I had, right, and I, like I'm old but I'm not that old, Jesus, 1 terabyte. Like what would you put on a 1 terabyte drive, that's like 1000 gig, like but it's like all the movies that you've ever watched, right. OK, OK, so how are we gonna calculate this? OK, so how long would an average random, and we're gonna get into this, you know, like what does it mean random versus um there's there's two, there's random versus non-random. Um, 16 kilobyte retake with the cheetah, right, so if someone were to ask you like how would you work this out, right, cause being able to calculate this answer basically demonstrates that you understand the principle of how the machine works, right? So, we're gonna start with the Sik time, right, and the average seek time is 4 sec uh 4 milliseconds. So it takes 4 milliseconds for this device to move its arm to the middle of the disk, right, or the sort of the, the ring of the disc, the appropriate ring distance. Um, OK, cool, that's easy. Um, the next one is we're gonna go, OK, on average, it's gonna take half a rotation, right? And we're rotating at 1500 RPM. Um, and there's a minute cal uh conversion in there and there's a 1000 conversion in there because we're, you know, talking about seconds versus milliseconds, right? And so we can calculate that that comes out to about 2 milliseconds, yeah. So we have a rotation, it took, as a rotation, took about half the length of the disc on average, cause we're doing the average random, right? We go half the length of the disc, the disc rotates 15,000 times a second. Ah, sorry, 15,000 times a minute, convert to minutes, convert from minutes, minutes to seconds, from seconds to milliseconds, we get to. OK, cool. Uh, the next one is the max transfer rate, right, so this is saying how fast, right? So like how many megabytes per second can you transfer on this disc, right? And we're saying it's 125 megabytes per second, um. And we want to, um, what do you call it, we want to transfer 16 kilobytes, right? So 100 and we've got a 16 on the top and 125 on the bottom, but we do have to convert units and we have to um, do both of those so that we get to milliseconds and so we get to, From megabytes per second to kilobytes per second, and then from kilobytes per second to kilobytes per millisecond, right, and then that gives us 0.125 seconds, and so we can calculate our um transfer that's how long it would take, right? So if you've got your head around that, that's how a hard drive, how long it takes a hard drive to work. I mean it's kind of a pointless bit of math, but you know, I can ask it in an exam and it kind of demonstrates at least that you can fill in formulas. Yay, um. One of the other things that we have to consider here is that um all of these devices are gonna need some buffering, right, like, or at least um it's helpful to have some cache, right? Um, and so one of the examples of where cache is useful is that like if you can imagine you've got this disk and it's spinning, an intelligent hard drive would be like, hang on a second, there's a good chance that if they, They wind in a circle, right, cos the hard drive is permanent storage, right, so it, it doesn't lose its thing. But I can store it in like my little mini temporary RAM inside my hard drive, and when someone's recording something, I'll be like, you started recording here, well I'll record this and a little bit extra, right, because I think on average you're probably gonna grab the little next bit in my disc, right? It's a very, very common thing for people to do. So it sort of reads ahead, and then the next time someone asks it for memory, it can be like, ha ha, I already have that in my RAM, yay, right? Um. And so, you know, like, um. Yeah, you can write, you know, like you can do some caching stuff like that, uh. Yeah, now this is one of the things where we get into the, the, the complicated things, right, like complicated and nasty things, right? One of the things um that is dangerous here, is that you can have a hard drive which is smart, and as soon as you start getting a smart device acting in concert with another smart device, the overall system can get pretty dumb, right? Because the, the CPU can be looking at the hard drive and be like, oh, OK, cool. Copy this data, and the hard drive can be like, I'm smart. In order to optimize, I'll tell you that I've copied it, but won't have actually copied it. But I'll have it ready to copy, right? And by the time you make the next request, I will have copied it, and that way you think I have a really low latency and it's gonna get copied through the DMA or whatever, right? Um, but it won't actually be copied, right? And so, one of the things where this becomes really dangerous is in power outages, what can happen is that you can get the receipt that something was done. And the power cuts out, and then it was in the volatile memory and then it disappears, right? Um, so, whenever you have a system that's like intelligent, um, it makes it really, really difficult to control it. The the other example or like a analogous example, like an analogy, is that like on your phone, right, if you wanted to write an application, right, on a phone, and one of the things you wanted to optimize for was to reduce power usage of your app, how would you do that? Right? You'd be like, oh well I'll, I'll change, you know, like the uh like the what I display on the screen, or I'll change this, you know, like the, the amount of sound that I'm outputting or whatever, right? And you'd be like, I'll do all of those things, right? But the problem is that the phone's smart and the phone's gonna be like, oh well I'm also trying to save power, right? And so when the app tries to change something, sometimes the phone will change it in somewhat, in, in such a way as to basically undo what the app is doing or vice versa, right, like as in the app's like ah. I'll, I'll, I'll, I'll try and save power and then the, the, what do you call it, the operating system's like, oh, this, this app's not using very much power, so I'll use all this power on this other thing cos I'm, I'm, you know, like, um, I now have that opportunity to do it, and so the phone actually ends up draining faster when you're trying to save power. It's a similar kind of idea with um, as soon as you introduce like, buffers and caches and, and memory, one of the problems is that like, um, basically, It allows you to cheat by having a cache, but in the event that you get called on your bluff, um, then it breaks. That was a very long winded way of explaining something relatively simple. Um, but yeah, like, one of the advantages of this kind of approach is that you can have like multiple outstanding requests, so that someone can send you like lots of requests and you can be like, I know, I, it's cool, I received all of your requests, I'm going to do the thing, right? Um, and then you've got this list of things that you're going to do, and then the operating system can be like, I can go off and do other things, I don't need to wait for the hard like the hardware anymore, um, but then you actually have to go and do them, and in most cases it's fine, but sometimes it, um, We'll stuff up, and the advantage of this, as you can see here as well is if you have multiple outstanding requests, you do again have the option to like reorder the requests. If you know that someone tells you you have to do 16 things and you tell them I'm gonna do those 16 things, and then you're like, but I'll do them in the order that I think is the most convenient, um. And as long as you meet all your timing deadlines, it's fine, but like um it does mean that sometimes there can be some like shenanigans going on behind the scenes. All right, what's next? Uh. Yeah, this can, yeah. Um, one of the things that like as I said, this is very dangerous because this can reorder operations, right? Um, and that basically means that it's impossible to try and like figure out how they work and so you can't optimize for them anymore because they're doing their own optimization. And so they become very black boxy, right, in the sense that like, um, Yeah, you just don't know how you would optimize it because it's already optimizing it and you don't know if perturbing it in a particular way will actually make its performance worse. Um, cool, alright, so that's hard drives 206. Maybe we'll take a 5 minute break cause I'm getting a sore throat. Uh, we'll be back at 2:10 past 2, so 4 minutes, uh, uh, 11 past 2. All right. Wait. Hello, come on. I'll touch any word to dismiss. OK, cool. All right, so, um, last thing for today, I think it's the last thing for today, we've done canonical devices, we've done. Direct memory access, we've done hard drives, so we're gonna look at solid state discs, right? This is what literally everyone has in their computer right now. If there's a laptop here, it has an SSD in it, right? Um, the reason is, is if you were to shake your laptop from side to side and it had a disc in it, it would damage it. Um, so, old laptops used to be really fragile because they used to have discs in them, but as soon as someone came up with the idea of solid-state discs, everyone was like, yeah, we gotta have as many of these as we can, um. But they're pretty dumb, they're pretty dumb, and so we have to go out of our way to make them functional, right? So how do they actually work? Bye. Does my mouse actually work? oh there we go, OK, cool. So it's got no using, no movable parts, so that's good. um. Written in flash memory, and we'll talk about what flash memory is in a bit, um, it's written in pages, right, and this is intrinsic to its idea of flash memory, right, because what, what we're gonna, you're gonna, There's going to be a point where you're like. It sounds like a terrible idea, right? In practice it's fine, it sounds like a terrible idea. Um. It's not bite level addressable, right? So you read whole pages or you write whole pages, so you can see how this might have come into being after people discovered that paging was the way that they wanted to go, um. And as a summary, you can read a whole page. And you can write a whole page, and to write a whole page, you sort of modify a whole page, um. So what you do is you, you read a whole page and then you read it into memory, and then you, you write, you modify it, and then you write a page. But it's important to understand that where you read and where you write are never the same in an SSD ever, under any circumstances. Right? Because the only place that you can write to in an SSD is an erased block, right? So we'll we'll go through what that actually means. So, um. Basically, you know, uh. Prior to. Prior to the common SSDs, basically you needed, in order to have like memory that lasted forever, right, and, and this is the thing, right, like we're talking about um non-volatile memory. So like with RAM, as soon as you turn your power off, the RAM is toast, right, because it relies on having two rails, one at like 0 volts and one at 9 volts or something, I don't know what the actual voltages are. Um, and the 1s and zeros are stored by having the differential of voltage. When you turn the power off, that disappears and all the data just gets corrupted and wiped, right? So what we're arguing for here with both the hard drive and the SSD is that both of them need to store data essentially forever, right? Um, and by human standards, right? So like 3 years. The data should last about 3 years or something like that, um. Uh, the magnetic tapes actually last ridiculous amounts of time, um, but, you know, you know, something like this doesn't have to last that long. OK. So, originally to do this, there was what was called battery-backed DRAM, right? And so the idea is to make a solid state drive, what you do is you attach an external battery to it, and when you turn the power off, the battery keeps the, the um the data in, basically, it's sort of like RAM but like powered RAM, right? Um. But in 2009, this is when we get to um You know, flash memory, and this is the point in time in my life where I suddenly realized that getting a faster CPU and more RAM wasn't useful, right? Because up until that point in time, basically, Um, there was always this thing, it's like, oh, you need to get a better CPU, you need to get a better CPU, you need to get a better graphics card, you need to get a better graphics card, you need to get a better RAM, right? Well, my computer needs more RAM, it's slowing down again, right? That was all nonsense. It was all hard drive, right? Like the hard drive was actually the bottleneck in the vast majority of things that people did, because when you wanted to load something, what would happen is the hard drive would be like, OK, now just wait a couple of hm. Alright, just right, it would load something and then he would have something loaded, right? And then, you know, while you were playing the game, the performance of the game could be pretty good if you had good RAM and a good graphics card and a good CPU, but like just loading stuff took a long time, right, um. And SSD solved this, right, so, OK. So here's the logic. We're gonna take our memory and we're gonna divide it into pages, and then we're gonna have groups of pages which we're gonna call a block, right? OK. The pages are initially empty and in the case of SDR RAM that actually means they're all ones. Oh, not SDR RAM, SSD. In the case of SSD it means that they're all ones. It's kind of meaningless, but it's, uh, it said, it told me it's they're all ones, who cares? 110, it doesn't really matter. Um. And so what you do is when you want to write, you can write a whole page, and that's all you can do, so I'm going to just keep writing pages. Right? But once you have filled up all the pages, you cannot write a full page, right? So if a page is already full, you can't actually write to it, right? And you might be wondering like, oh well, why can't you write to a page? You, you could write to a page before, right? And the answer is, is because writing only involves zeros. Right? So the, everything is ones, right, and you can turn, you can write a page by turning some of the, Beat parts of that page into zeros, right, and that's all you can do, right? So once you've written some zeros, right, to something, you can't rewrite it by turning them back to ones, it just doesn't work, right? So there's no, there's no writing of ones, there's only writing of zeros, right? Um, and so you overwrite it. And so basically now you've got this situation where you're like, well, I, that was a fun experiment, I've, I've written all my SSD, right, I'm done. Um, I'll get a new hard drive. Um, instead, the idea is that what you can do, there is the facility within the machine to erase an entire block, right? So you can write a page. And you can erase a block, and those are the two operations that you have access to, right? Now, fortunately, both of these things are pretty quick, right? But you can see where like writing a page, if you need to erase a block, is probably not that quick, right, because you have to erase the entire block in order to um write an individual page, right? So, It's a bit like um what was the one that we were doing, you know, it's a bit like page tables and stuff like that, right, where, where you're just like, oh God, this is gonna not be what I think it is, right, like so we're gonna take something that was nice and logical, where everything was in order, and now we've got the page table which is like everything is everywhere, yay, right? And now on top of that we've got a thing where when we try and physically write to our hard drive, the hard drive's like, I will find space for you. And it won't even be the same space the data was in before, right, so I'll read, if you read something from the hard drive, modify it, and then put it back in, it is never in the same location that you took it from, right? Um, so it's a bit confusing in that sense, right? But that's basically 90% of how an SSD works, right, like it's, it's just literally you have to erase an entire block and you can write an individual page, right? Um, when you read, you take the whole page, you can't take like one bite, you just take the whole page, so that's kind of a, um. Uh, the issue, um, so broadly, What are the problems with this and what can we do to fix this? OK, so. Um, What's this say, copy and paste pages. Yeah, so like, if I have like, I want to copy and paste something, or like I like I want to take something and modify it and put it back in, I'm basically gonna take this green block, right? And then. I will mark it Like, uh, the the what do you call it, uh, the old page, because it's been modified, right? It's still in the machine, right? Like as in if you think about it, right, like I'm going to, I'm gonna, I'm gonna take this bit of memory, I'm gonna load it into RAM, I'm gonna change it. But it's still in memory, right, because I've made a copy of it, right? Well now what I have to do is I have to mark the one that's in memory as wrong, like it's invalid, so I, I, I go, that one is no longer actually memory, that's a fake page, it's a fake page that refers to something that doesn't exist anymore. And then I paste the new page with the modifications into an empty block, right, like a block with an empty page in it, right? So it means that now I've got a, OK, so for every page in every block I need to, You know, maintain this list of, oh well this page used to be data and now it's not data anymore, it's garbage, right? Um, and then essentially, we have to have a garbage collection process, which is once a block contains enough garbage, I will erase it, right? Um. And yeah, once it's mostly invalid, it can be scrubbed. OK, cool. um. And so if I'm going to delete something, right, like if you think about it, right, like if you want to delete a file from your memory, it's actually really, really fast because deleting just means it's invalid. I'm not even trying to return it to all zeros, I'm just saying it's invalid. Now obviously that's gonna create a bit of a security concern because the data's still there, um, but yeah, deleting is really, really quick. So basically now I have this device, it's optimized, it reads pages really quick, it writes because it's always writing to a blank page really, really quick, and I can delete things really, really quick because delete just means, you know, market it as invalid. Alright, so this wasn't in the last year's lecture, but I thought I would put it in because I was curious about like how this actually worked, um, so I don't think I'm gonna be assessing you on this, but it's just, just for funsies, like, um, it's good for cementing the memory. So, so basically, what, what we're gonna do with a flash memory is we're gonna have like, uh, it's like a, what do you call it, a transistor. Has, has anyone here actually done electronics? Uh, one Oh scary. OK. Right. The entire, your entire career rests on this invention, OK, right. Um, basically transistors are these things where like there are 3 pins and usually the one in the middle is used to control where the current flows from the first one to the second one, right? And so that's where you get the idea of a switch, so you know like, Um, what you can do is you can have, have this input and that changes where the current flows and so you can build gates like and gates and or gates and all of the, you know, basic binary logic. But in this case, basically what's gonna happen is we're gonna have what's called the control gate, we're gonna have a floating gate and we're gonna have two regular, you know, this, this copper thing where it's gonna, um, go through this substrate made of a material which I think is, Nitrogen and phosphorus. Think and PPN and PNP um, anyway, um, so basically the current's gonna go through. OK, cool, that's fine, right, when it's in this setting, I've got 03 and 3. OK, so, This is when the floating gate is empty. If there are electrons, OK, who here has done enough chemistry so that when I say the word electron, you're not confused. OK, so that's more reassuring, right? If there are some electrons in this little floating gate region, it prevents current from going through when the current is at low voltage, right? Does that make sense? Right, so basically, in this case, it's a one, because there's no extra electrons in this little floating gate space, and so the current goes through fine, but if you have electrons in this floating gate space, then it stops the current going through, right? OK, so that seems kind of reasonable. Yeah. If you up the voltages here, see how it's 10 and 7 instead of 3 and 3, Animation, it forces electrons, there's so much current that some of the electrons will, will move through this material and end up stuck in this sort of floating space, right? And now, because they're stuck in that floating space, we have essentially written a 0, so that's a 1, that's a 0, and this is writing a 1 to a 0, right? Um, and then, Oh yeah. Then, last one, if I change the voltages dramatically, right? I can actually get it to, and you can see here where it was like 0, 10, 7. This time I'm gonna like reverse the voltages, so it's 10, 0, 10. I can drag the electrons out. OK, cool, and now I've gone back to 1. Now the thing is when I do this operation, I'm doing it to a whole block. This is why the, the reason I'm showing you this basically is to sort of elaborate on, on like, like why, you know, like why would you set, you know, like if you can set up a system like this, like why would you do it? Right? And the reason is is because, you know, I can control these voltages, but when I do it, when I do the erase option, it's pretty brutal. Right, like it's like basically dragging these electrons back out again. So, you know, to put them in is pretty easy, right, I can do that. Um, but to drag them out, I basically have to drag them out everywhere, yeah. Um, and you can see that because I'm not using the control gates anymore, I'm using the other gates, and I like the, the values here are dramatically different, right? So this is going from like 0 to 10, right, so this one, which is normally 0, it's been 0 the whole time. And then suddenly I'm changing it to 10 volts, so it's like I'm kind of nuking the block, right? And that's what gets rid of all the electrons from these floating gates. Um. So, and the reason that I'm, I showed you all of this is because it comes down to this, Nasty fact, right? On top of all the silliness, right, one of the, one of the things about an SSD is that you can only do this nuke operation a finite number of times before you destroy the hard drive, right? So, every time you erase a block, you are reducing the lifetime, or like the, the, the, I don't know, longevity of your hard drive, right? And now I've got to think about it again and go, oh god, alright, so not only every time I read something, I've gotta write it somewhere different. I need to write and distribute all my rights throughout my hard drive in such a way that it's balanced, because if I do it in one location too many times, that block will become unusable. Right, and it'll be hard for me to tell, right, it'll just stop working, but I won't necessarily know that it's broken. Yeah. Um Yeah, um, just in terms of timing, we can see here that writing a 4 kilobyte page is about 200 microseconds, which is really, really fast compared to what we had before, right, to about 1 1.7 milliseconds. If we were looking at the numbers before it was like 67 milliseconds. Here we're going like a fraction of a millisecond up to 1.7, and even 1.7 is much faster than we'd had with the regular hard drive. Um, but yeah, you can only write to empty pages, and erasing takes about 1.5 milliseconds. So if you were to be erasing, Whenever you did a right, not only would it be slower, quite significantly, it would also destroy the hard drive in the process, so we're trying to minimize the number of erasers, um. So, yeah, uh. Yeah, one of, one of the things that was kind of interesting actually, like just when I was researching this, um, is that when, when they invented SSDs, um, Originally, um, they were written on the starter bus, right, so just as a, as, as a side note, right, there are different buses, as I said, there are different buses inside your PC that have different, um, basically throughputs, right? And because hard drives were slow, they would go on the slow bus, right? Um, and basically when they first used, you know, SSDs, they're like, well, we'll put them on the hard drive bus, and then they're like, hang on a second. Our SSDs are actually really, really fast, um. And so they put them on like faster buses, but one of the things that was kind of funny was that like, They were so unexpectedly fast that like originally they had to write different kinds of software to be able to handle how much faster they were than the old ones. Um, and that was uh what is it, the AHCI um whereas nowadays they use NM NVME right? Um, and basically that protocol allows them to, um, what do you call it? Transfer data way, way, way, way, way faster, right, and everything is now on your PCI Express bus, which is, you can see here, it's like 7 to 14 gigabytes rather than um 600 meg. Um, so it's, um, a lot faster. Um, but yeah, the, the, what I was mentioning before is this idea of we levering, uh, we're leveling, right, and the idea of where leveling is that if I do this, is if this is the distribution of where I'm doing my data in terms of blocks, not pages, um, then I am messing up badly, right? Um, because basically the hard drive will become useless when the first block becomes useless, effectively, right, if you think about it, right? So I need to make sure that I have that, you know, the device actually has to be incredibly intelligent, right? Like as in so it's device driver has to be, you know, like internal, not device driver, not the driver on the um operating side, but the internal device logic. So when you send a request, it needs to be like, uh yeah, actually I should put it here, then I'll put it there, then I'll put it here, then I'll put it there, um, to ensure that it doesn't overwrite the same location multiple times, because if it does, then you'll just break the device. Um, and so this is the better, I don't know, version of it, um. And this was the one where I was like oh come on, this is just mean, right? OK, so I've just told you, I've just told you that if, If, if you erase the same block 10,000 times, the device is broken. At the same time, if you leave. An SSD with the same data for too long, it will also break, right? So you're screwed either way, right? And so, one of the things I thought was really hilarious is that like in order to maintain its livelihood, that is to say to last longer, it actually sometimes shuffles data for no reason other than to maintain its like life, life cycle, right? Which I, I thought was just hilarious cause I was just like, hang on a second. And the reason that static data is bad is because it does have the thing that if you leave data in this, like you, if you leave these electrons floating for too long essentially, um, they can't get pulled out somehow, I don't know. Maybe they create some kind of confirmation change in the substrate of the material or something, I don't know. Um, but yeah, um, so you've gotta have this situation where you're like, not only do you have to like shuffle the pages around, right? Um, in order to avoid wearing, you also have occasionally have to shuffle them around to avoid them being the same too long, which is just madness. But 10,000 is a lot, you know, like it, it sounds like very little, right, but it's, uh, it's actually quite a long time, like, um, and it's much longer than the average person will own any of these devices. Like, you have an SSD, you'll have an SSD in your phone, right, and they last for quite a while. Um, presumably you have an SSD in, I don't know, I, I'm just making that claim. I'll have to Google that just to make sure that I'm correct. Do, do they have SSDs? I'm assuming they have SSDs. They certainly don't have hard drives. Um, ah. Uh, yeah, so, oh yeah, so one of the things about we're leveling again is that like, again we've got another level of like indirection, that is to say that, The operating system has page tables to say that within regular memory, you know, within my mappable memory space, whatever. You know, I've got, you know, this, this, this process is, is like mapped in all of these locations, right, you know, like I've, I've got this page here and this page here and this page here and I've shuffled everything up. Then the hard drive's like, no, no, no, no, no, no, no, no, no, no, no, no, no, I'm gonna do my own shuffling on top of your shuffling, um, to try and like uh make sure that you don't, you don't stuff me up, right, so um. Basically, um, one of the, the consequences of this is the memory in a SSD can move and the heart of the operating system would not know that that has occurred, right? Because the SSD itself manages where, like the mapping from where the operating system thinks everything is to where the SSD actually knows where everything is, which is quite hilarious. Um. And yeah, there's a couple of other things that you can do like the copy on write, like for example, you know, like we, we really, you know, with, with an SSD we're gonna be really vigilant about not, Doing more stuff than we need to, so for example, copy on write, which is, you know, like if I have two copies of something, I will maintain them, as a copy until I really have to create the second one, right, because it makes sense that I don't want to do those writes unnecessarily. Um, And then yeah, you just write a new version to a free page. Um. Uh, yeah. So yeah, flash translation layer, if you're ever asked what that is. I don't think I'd ask that question, it's a bit too um. Specific, uh, so yeah, um, if we talk about like, um, the benefits and, uh, drawbacks of an SSD, it's basically all better, right? Like as in it's better in all the ways that anyone actually cares about. Number 1, it's faster, and number 2, you can't break it easily, right? So you can drop your phone and your phone will continue to work, right? Um, mostly, right, like if you were to drop a hard drive, that's it, that thing is done, right? Um, if it's spinning, right, just because of, you know, angular momentum and a bunch of other things, there's no way that you can drop a hard drive without smashing the crap out of it. Um, they, they, they, they became more robust over time, I think, but like they're still pretty, pretty, um, fragile, uh, while they're running. Um, the cons are kind of fake, right? You know, like, like, so they're like, oh yeah, well it's, it's, it's kind of annoying because, you know, writing and reading and er reading have slightly asymmetric performance, you're like. But they're all like way faster than a hard drive, so how is that a disadvantage, I don't know. Um, it is more complicated, so you need to have smarter, like, a hard drive can be pretty dumb, whereas the SSD has to. Like spend a lot of time thinking about how and where to store the data, and then yeah, the um hard drive will last a lot longer than an SSD. In general, um, in the same way that tape will outlast, outlast all of them for all time. Um, We also have the idea of schedulers, right, um. So, you know, like, uh, like where do you put the scheduler, so like if you can imagine you've got like a. Uh A huge number of requests that you're gonna put on your disk and you're gonna be like, hey disk, do a bunch of things, right? Um, you have a choice of where you're gonna put, like how you're gonna do the scheduling, like as I said, you know, hard drives can change the order in which the requests come, that's a thing that could happen. Um, you know, do you put it in the operating system or do you put it on the desk, disk, um, first cut, first serve is a really obvious one, we've, we've covered this before, um. There's a couple, you know, like um for hard drives, um, there's, what is it, shortest positioning time first, right? Yeah, and so like the idea here is like first come, first serve is pretty obvious because you just, you know, like if I get a hardware request, I just do a hardware request. But if I'm doing it on a hard drive, now I have some physical considerations, right, unlike, like, um, scheduling uh page, page, pages and scheduling and all that kind of stuff. When it comes to a hard drive, there are physical limitations, right? So if you were a hard drive, and I want to write in two different locations, those two locations are physically in space. And so I need to now start thinking about, well, how do I account for the physically in spaceness of them, rather than the order in which they come. Um, do I want to go, you know, like, a, a really simple analogy would be like if I was to go, I want to go to Melbourne, Brisbane and Sydney, I would be insane if I went Brisbane, Melbourne, Sydney, right? I would, I would go Melbourne. Sydney, Brisbane, yeah, cause, you know, it would be the, from Adelaide anyway, right? Um, that would be the order I would go if I wanted to go all three and take the least amount of time. Um, so, we have shorter seek time first, right? Um, obviously one of the problems with that is that like if I get lots and lots of requests, um, I think, you know, like if someone's like, OK. Uh, if you live in Perth, right, and it's like, oh you need to go to, you know, I get a whole bunch of requests for like Sydney and, or let's say, uh, Melbourne and Hobart or something like that. And you can imagine like some operating system just flying back and forth between Hobart and Melbourne, essentially going permanently, and it's like, because Perth is never the closest, so I will never go to Perth because it is never the closest. So, there are some shortcomings here, right, and you would end up with starvation of distant requests. Um. It turns out like the best algorithms are basically um the elevator algorithm and um circular scan. And so the idea uh it's one of them's called scan and the other one's called C-Scan. Um, but the idea is it's like an elevator, you just keep going up and down, and that's it. You just, you go up and down, except in this case you just go in a circle. Right, so you, you basically, um, if you can imagine you've got the um, Uh, the, uh, what's it called? Ah, the reader, the head, it just goes in and it goes out. And it goes in, and it goes out, and that's what it does, right? Like as in, like that's the, the, the most um efficient way of doing it. Um, you can like, uh, uh, what do you call it, there's an algorithm called look where you can uh improve it slightly, and that's where like if you know that you don't have to go all the way to the end, you don't go all the way to the end, you go to the last request. So if you're like, I don't know if you're in Ngani Wadley, and there's only a request for floor 6, you go to floor 6 and then you go back down again. So you could go like 463, 63, 63 or something like that, unless there's actually someone there, um, but yeah, it's basically. I'm going back and forth, and so, oh, we got 2 more slides and then we're done. Alright, so summary. Um In general, when you're doing IO like from a scheduling point of view, the goal is to have IO and CPU doing both doing things as much as possible, right, so that's like the general thing that you want to do, which means that using interrupts to do your scheduling um of the IO devices so that they tell you when they're done. Um, and that you like yield the CPU while you're doing IO is a really good thing to do. And number 2, what's number 2, DMA, direct memory access, which allows the IO to talk directly to memory, might load things into RAM, um, are really, really good for this purpose, so like that's how you would optimize for them, um. Yeah, um, storage devices pretend to be one big block even when they are not, right, so we know that the SSD, for example, is like a hodgepodge of a billion pages in a billion different different locations, but it's gonna just pretend it's one big block, right, and so it's got this like common external interface, um. Yeah The next one is one that like. I guess it's like a side effect, right, so. Um, when you guys would have done like operating systems, not operating systems, you're doing operating systems now. Object-oriented programming or foundations, you probably would've come across a point where you learned about linked lists, right? And from a, like a logical point of view, the linked list seemed like a really cool idea, right? Yeah, good. Someone, someone's shaking their head. It's, it seems like on paper, if you were like a mathematician, a really, really great idea. But we find that in all of these circumstances, arrays tend to outperform linked lists, right? And it all comes back to this kind of stuff, right? Like as in like we're looking at hard drives or memory or whatever. Because everything has to be stored somewhere and everything needs to be stored somewhere, right, um. And because computers load things in batches, right, um, you want to take advantage of that as much as you can, right, that is to say, like, um, like, for example, in assignment two, when you're looking at all of these requests, um, for pages and stuff like that, right? Like you better hope that you're always accessing the, the same pages over and over again, right? Because if you're not, then your performance is gonna be crap, right? And so, in general, your goal is actually trying to make it so everything's always reading from the same set of pages, right? Um. Sort of indirectly, right, and this sort of applies across the board for these things, is that like you want to have everything in nice neat blocks, right, so that it's much easier to read stuff. So for example, like um, you know, if I read all of, you know, like on a hard drive for example, if I'm reading like a big chunk of the hard drive all at once, right, with the disk spinning. In its sectors, that's actually really easy to do because like basically, I'll read this section, then I'll read that section, then I'll read this section, then I'll read that section, it's really, really easy. Whereas if you're doing random access and you're doing random ones and you're like, OK, I'll get that one and then I'll go across here and then I'll get that one and then I'll go go across and get that one, right, um, analogously, right, that's one of the things that you want to try and avoid. So random access is actually really bad, um. And what that means is for slower devices that scheduling is actually a viable option, right, like if, like on an SSD scheduling is like less useful, right, because everything's just like instantly getting read out of this, um, you know, you're reading whole pages at a time, you're like this one and this one and this one and this one, right, they're coming out reasonably quickly and it's very, very, very rapid, so the question is, do you have enough time to do some scheduling? Yeah, maybe, but like, um. If the device is really slow and you can have multiple requests at once, like an elevator, right, you can program it so it's not first come, first serve, and it actually has much higher throughput. Um, and then the last thing I guess is just about file systems which I'm not gonna talk about a lot because. Wasn't really a lot to talk about them, it'll probably be covered a bit later, um. But basically, you know, like. Um What am I trying to get across here? I, oh yeah, basically, um, if you can imagine in concert with hard drives, right, we're going to have to have a file system, yeah. Um, for those of you who've done systems programming, you would know that in Linux we use like Iodes and the Iodes map to other I nodes and the Iodes map to actual physical data. So what we're gonna have is we're gonna have like this idea within the file system of blocks, and so the file system is gonna be laid out like a tree where everything is in a logical location. At some point that has to be translated into, it all fits into one big bucket, which is your um, Different sectors of your hard drives or your SSDs, right? um. So that's basically, I don't know. Or you really need to know about that. Um, and the last, the last thing that, um, is just a curious aside, right, um, to do with file systems and, and this stuff, right, is that, Who here has heard of a sea drive? Right, good, most people. Now this is one of those things that you sort of take for granted, working on a Windows machine. Is there a C drive on Linux? Who thinks yes? Who thinks no? Should there be a C drive? That's a more complicated question, right? Because basically, you know, A drive and B drive are all to do with like um, Floppy disks essentially I think. One of them is definitely floppy disks cause I used to have B drive. Um, or was that D? I can't remember. Um, but basically C-drive was sort of at some point in time became like the canonical hard drive letter in Windows, right? And one of the things that's kind of, like, it's something that you kind of take for granted, but if you sit and you stop and you think about it. Does that make sense? Cause in Linux, right, your file system is just a big tree, right? At the top you've got root and everything else is like hanging off that tree from root. It's a series of directories. Each of those directories point to like I nodes, and those I nodes are somewhere in memory, whatever, like it's another, you know, like, essentially mapping, table mapping, but whatever. Right, your actual file system is this tree. But on Windows, there's C. And see. Refers to a physical device, right, because your C drive is a hard drive, right? And then when you've got a second hard drive, it's like the D drive or a global one, it might be mapped to the Z drive or the R drive or something like that, right? Why is there a CD drive? Why does the file system know that the hardware exists, right? This is a, like a design decision that they made in Windows, which it kind of makes, like if you think, you know, like if you're thinking about naively, you'll be like, oh yeah, of course, all all my data's on this, this hard drive, so this is where I'm gonna store all my data in my file system. And you're like, yeah, but what if, what if one day you have hundreds of hard drives or you're not storing it on hard drives anymore? Like how does your file system work? How does it know? Right, and so this is, this is one of those things where you're like, ah, so that's why Windows kind of sucks. One of those other reasons where you're like, ah, that, that, that's like a, that, that's a decision made by an amateur, right, rather than by someone who's actually thinking about it like long-term. Oh yeah, um, so today. IO devices, DMA hard drives, solid state drives, I think that's everything. Um, have a good weekend and good luck with your quiz. Oh, and questions, if you a question that come up at the end. Oh yes, I have one question before we go, yes. If you are, I will make sure that there is a version of me on a video doing it. Explicitly, just for the sake of it. I don't know whether there's any point to it, I agree, like this is like we're we're, we're plumbing the depths of like pointless algebra, right? Um. To be honest, I don't know how valuable it is to know how hard drives work, right? Like I'm like, yeah, maybe, I don't know. I, I will, I will be explicit on whether that is true or not. If I can make an exam without it in it and it doesn't feel like it's a crappy exam, then I will probably not include it. It's not on my high list of priorities of things for you guys to memorize.
