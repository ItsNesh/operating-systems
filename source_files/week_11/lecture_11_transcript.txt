SPEAKER 0
Alright, hi everyone, sorry. Is it on the right screen?

SPEAKER 1
Yeah, maybe. I have the right lecture, lecture 11, there we go. That's not lecture 11. Oh, I, I, I called it revision, that's why.

SPEAKER 0
All right.

SPEAKER 1
Um, first things first I guess, wait, it is recording, right? Microphones are docked, touch anywhere to dismiss. Go away. Yes, OK, cool. Um, today we're gonna be talking about log file, uh, log structured file systems. Um, but before we do that, I thought I would just go through quickly, briefly, um, in preparation for next week, um, because presumably, um, housekeeping, there are gonna be either questions about the assignment which you can ask me at the end cause like, I don't know, I'm not gonna do that now. Um, unless there's, I don't know, some obvious one to ask. Um, what I was gonna say is I'm getting many, many, many, many, many, many questions about exams, right? And people are fishing in all kinds of different ways, and then they're like, can I have a practice exam, can I have this kind of exam? I'll show you what I'm going to provide, right? Not in detail, in summary, right? So next week I'm going to provide a revision lecture and the, the PowerPoint for it up will be up hopefully sometime on Monday. Um, but to give you a vague idea of what it's going to look like is I'm gonna tell you what's in the exam, and there might be a bit more detail here. Um, but this is basically what I'm going to provide, which is like hundreds of questions that Bernard thinks about when he's teaching subjects, right? So you know, like it'll be like these are not exam questions, these are vague versions of exam questions on things that I could reasonably ask, right? In an exam, so you know, like I could reasonably ask what is a process, what is a program, what is a thread, and what's the difference between all of them, right? That's a reasonable thing I could ask in an exam, right? Uh, give an example of OS abstraction, right? That's a reasonable thing. I probably word it better than that, but like this is the vague milieu in which. You know, this kind of exam question is going to exist, right, you know what is direct execution, what is the alternative and why might we bother with direct execution? Again, I'll probably word it slightly more formally for an exam, but this is the vague idea of the kind of question that I will ask, right? So this will give you a sort of like a, a full overview of the kinds of things that, like the way that you can engage your study, In in the sense that you should be able to basically answer these questions. So if you feel like you can answer most of these questions or all of these questions, you should be reasonably well, um, prepared for the exam. The, the last thing I'll have is I'll have things like this where I'll be like, hey look, here's a table, I haven't filled it in yet, but you know, with numbers, calculate these numbers for me, right, like, so I'll give you an example of the kinds of numerical questions that I'm likely to or um unlikely to ask in the exam. Now just remember that this is a uh what's the word for it? The exam is not strictly a subset of this, but is effectively a subset of this. So I'm gonna put up lots of questions that I'm going to try and trick you into learning stuff that isn't gonna be in the exam because I'm mean and I want you to know things, and then later in your life you can come back and you say oh I had this lecturer, and he made me learn things and it was so unpleasant, right? Um, and I'll be like ha ha. But, um, broadly speaking, pretty much everything that's in the exam should be kind of vaguely hinted at in this presentation, but that's next week and I'll have the PDF PDF up on. Monday and then I will give the actual lecture on Friday. Um, are there any other housekeeping questions? I guess we can do assignment questions if anyone has any questions about assignment 3. Who here has started assignment 3? Buhera has basically finished assignment 3. No one can have finished assignment 3, unless you, have you had your, have you already been interviewed for assignment 3? I don't think anyone's been interviewed. Um, the, uh, interview process is being handled by my tutors, so, um, I would suggest either post to, uh, What is that tool called? There's a tool. The answer or email your tutor if you have questions, right, like as in um they've given a list of like which groups are getting interviewed by which people. If you have specific questions, email the tutors, because if you email me, I'll just email the tutors and then they will email me and then I can email you, and then I will hate the whole process and nothing extra will have been gained by emailing me. Um, so, yeah, that's it. Any other questions? All right, all right, let's get going. Um. So today is our last like formal lecture, I guess, about the course, other than, you know, revision, so um. Yeah, uh, where were we last week? So last week we were talking about the fast file system and the week before that we were talking about file systems. So we're gonna finish off with log structured file systems. This wasn't covered last year, um, because the lecturer ran out of time. But I thought that this was interesting enough to just, again, it's one of those ones where you're like, I don't know how useful this is, it has been used, um, but it's useful in a sense of thinking about problems that you might have in this domain and what you would do about it. Alright, LFS. OK So some broad observations, right? So we're we're we're back in file system land and we're saying, OK, what are the problems with the file systems that exist? And really, you know, in my experience, and, you know, like it's interesting that when I was learning about this, which I learned about, you know, in the last couple of weeks, um, That it mapped so well to my lived experience, which was the invention of the SSD got rid of lots of these problems, right? Um, but basically, you know, what happened was, you know, uh, we've got this, you know, these fast file systems, but we've got this problem that people, Behave in particular ways, so right, so in theory you go oh I've got this really cool idea for the way that I'll set my file system up, but in practice things change and when in practice things change, you have to sort of adapt to those changes to match usage, right, so, it's a it's it's we're back to the same logic that you know an array is better than a linked list, not because a linked list is theoretically worse. A linked list is basically theoretically better in many, many cases, it's just in practice, it's really bad because you don't wanna have this, you know, all these bits of memory spread out throughout um the universe, it's very inefficient. So, One of the things that became true is that memory became bigger, right, over time, right, so for every computer, originally memory was really, really scarce cos it was very expensive, but it became cheaper and cheaper and cheaper and cheaper and cheaper and the amount of memory that we have increases and increases and increases. As memory increases, it means that what you can do is you can store more things in memory. And it means you can store more things in memory on the chip, you can store things in more memory in your cache, and you can store things, more things in memory, in memory generally, right? And what that means is that reading becomes less frequent, right, because the more cache you have and the more memory you have and the more everything that you have, the faster the machine works, the less time that you have to go back and refer to the slowest kind of memory in your system. You just cache everything in the, you know, as high up the memory pyramid as you can. Right? And so what ends up happening is that like the balance between the concept of reading and the concept of writing starts shifting, right, because everyone sort of assumed originally that you know you have sort of an even balance between reading and writing. But in reality, you can kind of hack with reading and and cache everything so you're only sort of reading a little bit, and when you're doing any kind of writing, right, like that's where the actual cost comes in, right? And we will have seen from last week, a lot of the solutions that we are presenting, especially with things like journaling and, and, and stuff like that, where it's like, OK, well I have to write something here and then I write something there and then I write something here and then I write something there and I write something here and then I've got this, you know, if I wanna read something and I've got to go to this table and then read it and then, you know, if I wanna write something I need to know where it is, and then I read this table and I look at this table and then I go to here, I follow it to here, and then finally I get to write something at the end. Right, so it's a long and convoluted sort of process of just performing an individual write. Yeah, so our hard drives are getting better, but one of the things that's interesting, the hard drives keep getting bigger and bigger and bigger, but hard drives don't get better, right? So, And this is again, this is why it's like, is this entirely relevant, but it is kind of right, so you've got. The hardware technology, which is basically the density improves of the hard drives, right, so you can store a greater amount of data in a smaller amount of space, right, which means that you can sort of read faster. But the spinniness, like the RPM doesn't improve very much because no-one wants to have a jet inside their computer, right, like there are limits to how fast you can spin the disc, um, before, you know, like the smallest nudge will cause it to smash because of, you know, inertia and stuff. Um, and then the little motor that takes the, you know, the reader in and out from the, um, edge to the middle of the disc, um, there's a finite limit on how fast a physical motor can move, right? And so because all these discs had all these moving parts, the limitation was the physical motion, right, like as in like that was the thing that was driving, um the problem. So seeking and rotating is really really slow, but the sequential read became really, really fast, right? Um, because you could store more and more per hard drive, right? And so like, as long as you're sequentially reading in the hard drive, you're all good. If you are randomly reading, that's really, really bad. And you can imagine that over time this balance changed so that like, You know, originally, the difference between random access and um sequential access was, you know, some ratio, but it just became more and more favorable to sequential access over time, right? Um. The other thing is that, you know, like if we looked at our fast file system, we had this idea of the I know the data, the bitmap and the other bitmap, so the Iode bitmap and the data bitmap. And you're like, OK, so for every bit of data we're storing like 4 bits of data, so when you're writing that feels really onerous. And the last part is that no one was really thinking about raid, right? So when you, when you develop your fast file system, and then someone invents raid, you're like, oh hang on a second now, how many places am I writing in? I have to write to all of these different hard drives and um as we saw with um Raid. Um, the right performance is a little bit annoying because you need to, you know, you need to read stuff and then write to raid in order to do your parody bit stuff, right? So, um, basically the terrain changes and now we have to rethink operating systems. OK. Long story short is writing is way more important than reading. OK, cool. Alright, so. Now what we're doing is we're going, OK, if writing is much more common than reading, then the, the main thing that we have to worry about is the right speed and so we just become obsessed with trying to minimize, The number of writes that we do or the time that it takes. Now we can't do anything about the time that it takes because these discs are fundamentally limited, but what we can do is we can change the number of times that we write. And so the goal is to say, what if I can make a random access look more like a sequential access, right? Which for reading makes no sense because you can't really control where you're reading from, but for writing, You can get away with it, right, like as in what you can do is you can say, oh OK, instead of writing everything randomly throughout the hard drive, what I'll do is I'll just grab everything in a bucket and just write it in one big chunk. Right, and that's the, this is the sort of inspiration for this style of file system, right, so we have the what's called a segment, and the segment is going to be consistent of, Um, a whole series of things that we want to write to the hard drive, and we're just gonna group them all together and write them down as one big slab, right? So it doesn't matter what they're about, right, so it is essentially random access, that is uh we're gonna write a bunch of random things, um, but we're just gonna write them all in one big chunk, all in the same place. Um, in theory at least, right, um. Yeah, and that's it. So, that's, that's like the, I don't know, the, the nucleus of the idea. Alright, so in practice that has lots of issues with it, right, like, you know, um, Uh, firstly, like, just writing everything together, you can't just, you can't just do that. That's not going to just work, right? Like, like there's like lots of issues with this, right? So you know, like, Um, the data bitmap, the Io bitmap, the I node and the data, you're like, oh we'll just write them all together in the same segment, right? And you're like, that's not how that works, right? Like it's in the bitmap is meant to refer to the entire hard drive and the other bitmap is referring to the entire hard drive, right? And the I nodes are nominally all together, right? And the, and the data can be distributed through the the hard drive, but like trying to pretend that you can like just I'll just write that all together randomly throughout the hard drive. Like that's not, that's not free. We have to think about how to actually do that in a way that makes sense, right? Um, Yeah, so, so you know, like, OK, the goal is we're going from this like sequential to contiguous idea, right, now, now just keep in mind there's a difference between sequential and contiguous. Sequential means that you do everything in order, contiguous means you do things as one gigantic block, right? Now, in practice, they look like they end up with the same result, but in, In the real world, again with the hard drive, you can imagine you're like, we run into that problem where you're like, I'll write something, and now I'll write something here and you're like, oh, but, but the instruction to tell me to write something there took a little bit too long, so I'm going to go around the track again and then get to here and be like, OK now I'll write this thing, right? So we do need to make it contiguous, we can't just, you know, like try and make things sequential and write them in increasing address orders, we need to literally block things together and write them as giant blocks. OK, so that's fine. Right, so what we're gonna do is take a, a bunch of little rights and turn them into one big right. OK, so that's fine. Um, How much to buffer, right? Like so this is a weird kind of, you know, uh, performance trade-off kind of question, you're like, OK. Now instead of writing one right, I'm gonna write how many rights? Maybe 5, 1050, 100, 1000? How like how much am I buffering before I do my rights? Right? Um, so, as, as it says activity, so, um, basically what I want you guys to do, I'll do a little lap and see if we can populate some of the words that would go in here. What would be good about a big buffer and a small buffer and what would be bad about a big buffer and a small buffer. So like you basically the idea is that you're holding onto your, like, It's, it's a question of I have a number of rights, if I, I glue them all together, a big buffer means I'm gluing a lot of them together, and a small buffer means I'm only gonna glue a couple of them together. Right? And I'll do my little lap and then we'll come back and we'll, we'll get some wake people up on a week 11 Friday, hopefully.

SPEAKER 0
Alright. All right.

SPEAKER 1
Do we have any answers? Does anyone have any suggestions? What would go, what would be good if we had a big buffer? Yes. Less ride operations, I like it, yes, that's a good one, alright. What, what would be good if we had a small buffer? Yes. That's good, right, so basically there's an issue of latency here, right, like it's, if the buffer is big, then, I am filling up the buffer for a long time. Before the right actually occurs, so if you're the first in a series of rights, and there's 50 rights to come after you, um, then the big buffer would be quite slow, whereas the small buffer, you know, like as soon as you write it, and you take it down to its like logical conclusion is that with the smallest possible buffer you're just operating, you just get instant latency. Uh, any other answers to good for either a big buffer or a small buffer? Alright, what about bad things? What, what, what's bad about a big buffer and a small buffer? No one got that far. Oh yes. Yeah, yeah, OK, good, alright, yes. Yes. All right, good. All right, cool. I'm, I'm glad that we, we, we, we realized this, you know, like they're basically the same question twice. Um. So these are sort of my answers, um. One of the things that like, again, you know, just from an exam perspective, um, one of the things that I find students often do. Um, which I find really funny. If there is a question where it's like I ask a question like this and it's worth 2 marks, and it's like, what, you know, and the question would be like, compare having a big buffer and a little buffer for memory writing or something like that, right? Um, and there's 2 marks, they, they will write. A big buffer has less right operations, and a small buffer has more right operations. That's my two points, and I'm like, no, that's one point, it's the same point, right, like, you know what I mean? Um, but yeah, so, uh, cool. That, that's basically it, it's not a very complicated one. so I've included this just for the sake of like to get your head around sort of what's going on here. But basically, if you think about it, right, um. You can use a formula, or you can use this formula. To calculate how fast the actual right time would be, right? And so the idea here is like how fast you're writing is going to depend on sort of like the, how fast you can theoretically write, right? Yeah? Plus the timing it takes you to do the positioning, right? So data divided by rate peak, if you think about what that's gonna do, that's like data divided by rates per second, that's gonna give you time, right? So T position plus data on rate peak is gonna give you two times. One of them is gonna be how long it takes to write, and the other one is how long does it take you to waste time getting to the writing position, right, cause we're again thinking hard drives, like how long does it take to position the little thing to the writing position, plus the total amount of time it takes to actually do the writing. Right, um, from this we can work out like how fast is it effectively, right? So basically, if you look at the formula, I think if T positioning is equal to 0, you would get that data divided by data is 0, right? Like and then data divided by 1 on rate, oh sorry, 1 divided by 1 on rate will just give you the rate, right? And then you end up with the rate effective, right? Um, as The position gets bigger and bigger and bigger, your effective rate is gonna go smaller and smaller and smaller, right? So basically, you know, like if it takes you as much time to position as it takes you to write, like physically write the bits, then your effective rate at writing is going to be half as much, right? Because you spend half the time positioning, half the time actually doing um, the transfer, right? Um, what this means is you can work out, How big it should be, right? Because what you can do is you can start going well how big does everything need to be, right, so let us assume that we want a 0.9%, performance, right, so we're basically saying I want, My segments to be the correct size, so that I'm getting about 90% of the performance of a sequential right, even though it has some random access. So in a, in a sense, I'm sort of saying I only want to spend 1/10 of the time seeking, right, give or take, right? Um, and I wanna spend 90% of my time writing. So now what we can do is we can take our formula and then we can, you know, do some math, you know, replace the rate effective, I want it to be um 0.9 times the rate peak. Yeah, and then I can do some more math and I can, you know, move things to the opposite side of the equation, and then I can do some more math and then I can, you know, move other things to the other side of the equation and then do some substitutions and you can do this in your own time. Um, I've gone through every line in a sort of like the top line, how the top line turns into the bottom line for the derivation. But what we end up having is we eventually get down to, is this it? It eventually get down to this formula, right, which is, you know, like the data is 0.9 times the rate peak times the T position on 1 minus 0. 0.9, which means that, you know, like I, I, I made it 0.9 to begin with because that's a little bit easier in the head than say F which is whatever the rate I want it to be. But you can see now that I could just replace the 0.9 with an arbitrary number so I can um just calculate whatever I want it to be. And you end up with something that um kind of makes sense. It's like 0.0.9 divided by 1 minus 0.9, which means it's like 9 times or something, you know, like um, so basically I need to like have nine times as much data um. For the size Um, so from this you can now work out how, how big the the block of data that you would need to have in order to achieve, um, the kind of, um, performance that you would want, right, so we can, we can sort of mathematically derive the size of the segment. Um, depending on what our goals are. Alright, so that's, that's all fairly straightforward. OK, so now what are we at? Oh, we're problem number 3. Alright, OK, so let's assume that we've got that out of the way. At the moment we're like, OK, so it's fine. We are going to have, you know, a bit of a latency between when we write something and when it actually gets written. This is going to be a problem for power outages later on, but we won't worry about that for now. We know that we need to group things together to make them contiguous, to chuck them into the system. That's all good for now. I nodes. Now at the start I said, OK, well how are Iodes normally stored? They are normally stored, even in fast, the fast file system, they're stored in a big block. Here are all my Iodes with all the data that's inside each of the Iodes. I mean they're just basically a little index file. Um, and they're all together, and the reason they're all together is so I can goddamn find them, right? Like as in like, and if you think about how we used to do it, basically, where is it, You, you know, like if I asked you for an I node, you'd go to the Iode block and you would just count along until you found the I node that you want. You know, if I said get I node 75, you'd be like, where do the I nodes start, how big is an I node? Alright, 75 times the size of an I node plus the starting address of the first I node. And that gives you the address, right, so it's very easy to find the I nodes. Um, but if I am now, Pretending that I'm gonna chuck an I node in this segment where I'm every time I write something I've just got to chuck some random I node in a random segment of data is, you sort of sit there going, OK, well how the hell do I find all my I nodes? That makes no sense, right? Like, like if I was like, oh, OK, uh, this is your file, it's associated with this I node which is associated with this data, where is the I node? And you'd be like, uh, I don't, I don't know. Um. So that's the problem, OK, but we can solve that problem, right? So what we're gonna do is we're gonna have scattered I nodes, right? Um. And because of the way that this, you know, um, log-based log structured file system works, is we're not gonna update existing data anymore. Whenever we do a write, we're just gonna write a new slab of data, right, which means we need to keep track of where's the latest slab of data, right, like cause there's gonna be an old version and there's gonna be a new version. And the old version is gonna be scattered throughout the hard drive, and every time I do a new write, there's gonna be new I nodes in it occasionally. And so I need to somehow keep track of where all these I nodes have now been stored. OK, that's fine, so we need a map, so we need to make, we make a map, we make an ode map, right? Um, and so we create a Iode map and all it is is, you know, a list of I nodes and where they're stored on the hard drive. OK. That's fine, so instead now of just going to the Iode space and counting, I go to the iNode map and I read in my iNode map, and then I look at all the, you know, I do a lookup table and I know where all the iNodes are. Whenever I write a new iNode to the hard drive, I can update my map. That seems fine. Of course, whereas the map's stored, the map is stored on memory, you're like, uh, OK, that sounds like it's gonna be bad because then I have to read and write again. But the reality is that the Iode map is usually, you basically design your system so that it always has this loaded in the fastest memory that it can have. Um, obviously that can be a problem for, um, You know, like if you have a power outage, um, but, you know, that's the basic idea, um, we store it in memory, yeah, that's fine. OK, um. So what I'm basically saying here, like, uh sorry, I, I, I found this really funny because basically when I was reading this I was like, OK, right, so what

SPEAKER 2
we do is we don't know where the data is, right? So what what we'll do is like I'll I'll make

SPEAKER 1
an Iode. And knows where the data is, and I'm like, now I don't know where the I node is, what I'll do is I'll make an eye map, right, that points at the I node and I'm like, OK, but how do you know where the eye map is, right? Like as in like like where is this eye map? Right? Um. And it doesn't make sense, it didn't make sense to me because like it it feels like kicking the can down the road. But the, the idea is that the eye map is like always in memory, right? Um, and that you always know where the eye map is, right? So again it's, it's like you've replaced the Iode block with an eye ma block, and now you go to the iMap block, and then you, you know, update where all the Iodes are, but it's now a lookup table rather than just all the I notes, right? And you're like, OK, so now the Iodes can be anywhere, the eye map block is always in the same spot. And it's always a lookup table, and it's loaded in memory so it's not too slow. Um. Yeah, and then we have what's called the checkpoint region, OK, OK, so what's this checkpoint region doing? Um. Yeah, Contains pointers to the latest pieces of the Iode map. Right, OK, so if you can imagine. Hang on a second. So the eye map is also getting written every time, and now I have this checkpoint region, and it's pointing to all the pieces of the eye map, and the pieces of the eye map are pointing at our nodes and the eye nodes are pointing at the data. Fine, 3 levels of indirection, whatever. Um. The difference is now that the checkpoint region can be periodically written to memory, right, which means that I'm not updating the checkpoint region every time, so I'm not doing hundreds of writes. I'm basically going, I'm gonna hold onto my checkpoint and every so often I will write stuff. Um, and so I can reconstruct the I I map from the checkpoint region and then I can get the I notes and then I can get the dot. Alright. Yeah, that sounds so good. Um. All right, all right, all right, all right, um. Yeah, so this is a a slightly. Hm, let's, let's have a think about how we describe this one. So you can imagine. I want to update a file, right? And by updating the file, my parent directory needs to be updated because the file's changed, right? Makes sense? You know, like my, my, my parent, I know is like, oh well, I point at the file and I tell you when it was last modified. You modified that file, so now I need to tell my parent who is a directory. That I've been modified so he can keep track of the fact that you've been modified. Yeah, cos it's in his, his space, right, you're like, OK cool, um. There is a problem called the recursive update problem, which is basically, Where You know, like if you update a file, you have to update the parent, oh, the parent got updated, oh you need to update the parent again. The parent's parent, and the parent's parent's parent, and the parent's parent's parent and the parent's parent parent parent parent parent. Um, in this case you don't actually have to do it that way, right, um. Because you know like the I I map is like distributed through a whole bunch of different things, um, and everything is written together and you've got this, this, this file that you occasionally update every so often, it means that you can just skip the, the, the issue of recursively updating it. OK, so that's, that's cool. Um, it is a tractable problem. Problem number 4, OK, so we're always writing in a new location with this big slab of data. Why are we doing that? Well, because we don't wanna have to like overwrite stuff, cause that would be annoying, and we'd have to find it. And you can imagine that it would be very rare that if I just grab 10 rights, it's going to be the same as the previous 10 rights that I had. It's probably gonna be in a shuffled order, it could be just random stuff. There's no way I can like just transplant it as a block. Um, over a pre-existing block. Um, but what it does mean is that whenever I write a new block, the old block must be invalid now, right? Because, you know, like, I just, it's like every time you write a like it's, I think the analogy would be like if you're using Word, every time you make a change to what like your Word file, you just save a new version of the Word file on your hard drive, right? And you don't get rid of the old version. Yeah, so like this is essentially what it's trying to do, right, and so you end up with 900 versions of the same file, right? Um, so logically, we have to do something about this old version, right? Like as in because we can't just leave it there. Um, we need to have some kind of system for remembering that all the old data is crap. Um. Now There are two possibilities. One is what we just laid down in our segment, everything is new, right? Like as in we, we change, you know, we changed the file and we changed the size of the file, so the, the file needs to be updated and the Iode needs to be, needs to be updated. But there is also the possibility that like only some of it changed, right? So you can imagine that like, Um, let's say I have an I node and I. Extender file, so now it needs another block of memory, so now the I node's going to point at another block of memory, but the original block of memory that it was pointing at is still valid, right? And I didn't have to rewrite it, so like, all I did was I wrote the new block, the data 2 block, rather than the data 1 block. So the data 1 block stays and the data 2 block is new. And so that's a pain, right, like, so now I've got to think about these two different kinds of cases, one where it's kind of easy and one where it's kind of a little bit finicky, right? So, um, basically just to give a description here, you can imagine a situation where basically, here you have the old version, it's now grayed out, and you have the new version with the new I node and new data. Um, or you have this other one where you have a new version where I node now points at D0 and D1, so it points at this new bit of data, and it also points at the old bit of data, but the old I node is wrong, right? A nuisance. Alright, so basically the logic now is that we need to have some kind of garbage collection. Who here is programmed in Java, by the way? Java, Java, 123, so you guys would know what the word garbage collection is. What about Python, Python, Python. Does anyone know what, when I say garbage collection in, in, in programming. Yeah, 3 or 4, alright. So, um, oh, you guys have all programmed in C, right? Or C++, yeah? C++, C++, C++? Yeah, yeah, yeah, OK. So in C++, you create a new object, what happens? You break your game, right? You create a new object and you don't delete it. This happens all the time, you get, um, you know, memory leaks basically. Um, in other programming language you have what's called garbage collection. So the idea is you have a separate process that goes around trying to find, Objects, right, so when you create an object but don't delete it, you ask for memory but you don't give the memory back, it goes around looking for bits of memory that no-one is using, right, because there's nothing pointing at it, and then tries to delete it, right? And so we're gonna do something similar for um this. Now whenever we write a new block, we're gonna have this separate processors, you know, running around the the hard drive going, hang on a second, are you real? Are you real, are you real? Um, that sounds pretty bad in terms of, you know, performance, but we'll see how we can get it to work kind of OK. Um. One of the things that's really annoying about it is holes. Right, cos you can imagine. Yeah, that I wrote an entire slab, like a segment, and it's got, let's say the letters A, B, C, D, E, F as the files, right? And then I write another slab later on that's just got like A, B, and F, right? Well, I didn't actually update C, D, and EE, right, so they should still be good, right? Or you know, maybe I updated CD and E and now they're bad and write A E and F are still there and it's fine, right? So because I'm writing things in batches, the, you know, the freshness of each of these files within the batch is completely random, so I'm gonna end up with holes, and holes is annoying, right, like so I have to be careful about holes. Um. And so one of the things that I want to be able to do is I want to, you know, as part of my garbage collection, is if I, if I have like these, these batches, and you can imagine like this where I've got like um, A total of 5 holes. I wanna be able to go, hang on a second, you know, a better way of doing this is I could, I could collab, you know, like basically pick everything up and then defragment it essentially, right? Um. So that leads to this question, you know, how do I actually find these dead blocks, uh, and how often do I do my gala garbage collection, right, like when do I do it, right? Because you can imagine you have a process that's constantly like going, hey, are there dead blocks, right, the whole time, and that would be really, really inefficient. Um, but then if you don't do it enough, then maybe your hard drive fills up and you don't have any space. Um. So To counter this, it's a case of OK well I need to record some information, right, in order to be able to tell whether the block is alive or dead, and so what ends up happening is every segment has a little summary block, right, and it's gonna contain, you know, like the I note number and an offset like which block am I amongst all the blocks, right, and so, At this point in time now I can query this segment block, right, to be like, hey, you know stuff about your data. I'm gonna ask you some questions about your data. I can verify those questions, and then if you think that your data is somewhere where it's not, I know you're full of shit. Right? Um, and so we've got a way of like, um, if we keep a sort of a little mini log every time we write a segment, we have a way of interrogating a segment and then working out, um, whether it's correct or not, right, so in terms of I've got the process here, you read the segment summary block, you find the unknown number, you check the I map and follow it to the data. Is it where it said it should be, and if it's not, you can get rid of it. Right, that's how you know that it's fake, right, so you basically um use this segments summary block to work out the discrepancies. Um, when do you do it? Um. The answer is kind of interesting, like as in like basically at this point in the textbook it goes, well actually no one knows. And there are some papers on it and one of the, one of them ones which were, I thought was hilarious because it's so counterintuitive. They were like, wow, actually you should only if a file is frequently changing, you should only collect the garbage infrequently. And I was like, What That makes no sense, right, like that makes no sense to me. So it's like it's constantly changing, so it's constantly leaving garbage behind, so you don't do garbage collection. Alright, that's fine. Um, but if something changes infrequently, you should collect its garbage more often. Right, and you're like, I, I don't understand this at all. I do not understa. I did not bother to write the paper, there was, you don't need to know this, but I just thought this was quite hilarious, right, cos I was just like, I, I, I just can't even, like it makes no sense to me. But you know, the rationale was something along the lines of, uh, if a file changes infrequently, it means that it's probably not gonna change for a while, which means that you can collect this garbage. And I was like, OK, yeah alright. That kind of makes sense, but if something's changing frequently, why bother collecting the garbage when it's gonna just change

SPEAKER 2
again, you're like, cause it's gonna have lots of garbage, I don't understand this. Alright, well anyway, it's like the, the, the logic of

SPEAKER 1
it is, is not, it's not a clear cut answer, so I can't ask you a question other than, is there a clearcut answer? And you would write no, and I don't know whether that would be useful in an exam. Um, but it's, you know, a natural question that you might ask if you were just interested in the thing. And I think that's it, I think we get to the end of the, oh no, no, no, no, no. Why am I a summary slide? What? What? OK. Let me just move this to the end. That makes no sense, maybe I mis-clicked on something.

SPEAKER 0
Summary, down the bottom, right. Right.

SPEAKER 1
Prob problem number 5. This is the obvious problem, right? The one that we've already sort of described. If I'm saving up all my data into a big segment for a right, and I crash, I shall cry. Right? Like everyone knows that the longer you take between saving your data or checking something into GitHub, the, the, the bigger a risk you are taking, right? Um. So, there are two ways. One is we could crash while writing a segment, OK. Um, and then the other is we could crash while writing the checkpoint region, right? So those are the, the two ways that we could meaningfully crash, um. When if we crash while we're writing a segment, we, we've got a bit of a problem, right? But um let's start with while writing the checkpoint region, right? Um, basically, one of the tricks is that you have two checkpoint regions, one at the start and one at the end of the hard drive. And basically what you do is you go, I, I wrote something, I wrote something, I wrote something, right, and when the, the hard drive crashes, then you can be like, I have two checkpoint regions, and I can check if they are the same or they are different. Right? Because if they are different, I can work out why they are different and what I missed and what went wrong, right? Um, and so you can use timestamps and stuff like that to work it out, right, so that's not too bad. Um. If we crash while writing a segment, yeah, we can, we can lose like 30, what is it, 30 seconds of of like write requests. Like if we're only writing these segments once every 30 seconds, right? Um, or something like that, right? Like we, we have these systems where it's only writing every so often, um, we will lose that much data, right? Like if we have a crash, right? Um, if we, Are careful about it, we sort of like write logs of what we're going to write, um, because we still haven't written it to memory, it's gone. It's, it's just gonna be in, sorry, in storage. We haven't written it to storage, it's just been written to like, um, memory, waiting to be written to storage. We are going to lose quite a bit of data if we're not careful, right? Um, but that's the price that we pay. Um, and yeah, you can, you know, go through logs and stuff and try and redo stuff that you were going to do. Um, and yeah, I think that's it, right? So that's the log. Structured file system, which is basically oh OK so what we're gonna do is we're gonna prepare to write something. And then write it in a big slab. Oh, any questions? Excellent. If there are any questions about anything else in the course, you can come up and talk to me at the end. Um, I will be fielding some questions about, Assignments and exams, I don't think, we don't have any workshops left. Um, there will be a quiz I guess next Friday. Oh yeah, yeah, sorry, sorry, yeah, yeah. So the, sorry, the workshops are this week, so like that's mostly done is how I describe. But um the last um summitative quiz will also be on next Friday, so uh. Other than that. No, that was the 3rd 1, there were 4. And you get the best of the The three best of the yeah, yeah, yeah, no, no, exactly, right, like it, it, it, it, whoever set up the course last year, I was like, thank you, thank you for setting up this best, uh, you know, best 3 or 4 thing because you know whenever a student's like, oh I, I, I was not sick but I forgot cause I, I was busy, I could be like, well you can still get full marks if you do well in the other quizzes, so please don't forget the other ones. Um, and it's just an app for students because yeah, like, it's annoying. These, these online quizzes can be annoying. Um, Yeah, all right. Yes. I, I, at this stage in the, the exam, the front of the exam says there is no cheat sheet. Yeah, like that is, I've been asked about this numerous times, um. I never had a, sorry, what? Yeah, I will, I will, I will, I will, I will, at the end of the day, I will post an announcement that says there shall be no cheat sheet. Um, it's, it's definitely on the forums like 5 or 6 times. Um, just before anyone goes, but, but cheat sheet. All right. When I did university, I only got cheat sheets for one subject. I had 11 open book exam. For that exam, cos it was open book, I literally wrote out every conceivable question for the exam and I just copied it, right? That's all I did for that exam, because I could, right, and all I had to do was find the right answer to every question, right? And so I was like, I don't know if there is value in that, right, um, because I now don't remember anything about that subject because I was not required to learn anything about it. Keep in mind that the you know like. For the kind of subject that I am on the kind of exam that I write, I don't think a cheat sheet is entirely necessary, right? Like, as in I don't, I don't see where it adds value. Because most of the questions I'm going to be asking are more conceptual, right? So the vast majority of questions are going to be like, well, what is the advantage of having a big buffer, right? Like, and you, you, if you, at the point where you're like a big buffer, I've got a little thing on a cheat sheet that says big buffer has, Less rights, right? Then I'm sorry, but I have no sympathy for you. You should be able to like, this is something that you should just know, right? Like, or be able to like intuit and have a think about and be like, oh I've got a minute in the exam, let me have a think. Alright, no, a big buffer, you know, if I have a big buffer, uh it means I do less things, right, you know what I mean? Or but it means I could lose more data, right? Um. So those kinds of questions, the kinds of questions that I ask, I don't think see cheat sheets as being particularly helpful towards that end. Um, keep in mind, I'm gonna ask you a question of what does SJF stand for or what does SJF do, right? Because I don't think that is useful, that's basic rote learning. If I tell you that there is an uh to use a particular kind of algorithm in an exam. I will tell you if it's preemptive or whether it uses priority. I will leave reminder text this algorithm does or does not use priority. I'm more interested in your ability to like apply the logic of an an algorithm rather than you memorizing. Specifically how an algorithm works, if that makes sense, like, um, so like, yeah, um, and then, and then. Yeah, that's about it. Right, so like, yeah, that's my justification for no cheat sheets. Um, I'm sort of ideologically opposed to them because when you cognitively offload something it means that you don't actually remember it, and my goal in life is to try and make people have things in their brain, not on pieces of paper that they throw out. Any other questions? Uh, I'm gonna pause the recording now. OK
