<!-- 
Generated by LectureQ
Date: 2025-08-09 04:42:19
Model: qwen3:30b
-->

<think>
I need to create comprehensive, well-structured markdown notes from the lecture slides and transcript for Week 2, Lecture 2 on Operating Systems Scheduling.

Let me analyze the content and organize it into a logical structure for my notes.

First, I'll identify the main topics covered in the lecture:

1. Scheduling concepts and definitions
2. Scheduling algorithms (FCFS, SJF, STCF, RR, MLFQ)
3. Metrics for evaluating scheduling
4. I/O blocking considerations
5. Multi-level feedback queues
6. Lottery scheduling
7. Completely Fair Scheduler (CFS)

Now I'll structure the notes with proper headers, bullet points, and include key concepts from both the slides and transcript.

Let me start by creating a title and overview section.

I'll organize the notes with these main sections:
- Overview
- Scheduling Fundamentals
- Scheduling Metrics
- Scheduling Algorithms
- I/O Considerations
- Advanced Scheduling Techniques
- Summary

Now I'll fill in each section with comprehensive content from the slides and transcript.

For each section, I'll include:
- Key definitions
- Important concepts
- Examples from the slides and transcript
- Formulas where applicable
- Visual descriptions of concepts (like Gantt charts)
- Important details from the transcript

Let me start drafting the notes.
</think>

# Operating Systems: Scheduling (Week 2, Lecture 2)

**Date:** [Current Date]

## Overview
This lecture covers the fundamental concepts of process scheduling in operating systems. We'll explore scheduling algorithms, metrics for evaluating scheduling performance, and advanced scheduling techniques like Multi-Level Feedback Queues (MLFQ) and the Completely Fair Scheduler (CFS). The lecture emphasizes the importance of scheduling in balancing system performance, fairness, and responsiveness.

---

## Scheduling Fundamentals

### Key Concepts
- **Virtualization Context**: Each process believes it has its own computer (from last week's lecture)
- **Process States**:
  - **Running**: Process is executing on the CPU
  - **Ready**: Process is waiting to be scheduled
  - **Blocked**: Process is waiting for I/O or other resources
- **Scheduler vs. Dispatcher**:
  - **Scheduler**: Determines *when* to dispatch a process (conceptual)
  - **Dispatcher**: Determines *how* to switch between processes (mechanical)
    - Handles mode switching (user/kernel)
    - Saves PCB (Process Control Block)
    - Manages context switching

### Scheduling Terminology
| Term | Definition |
|------|------------|
| **Workload** | The collection of jobs that need to be done |
| **Job** | A CPU burst of a process (current execution unit) |
| **Process** | Alternates between CPU and I/O (moves between ready and blocked queues) |
| **Scheduler** | Logic for selecting which job to execute |
| **Metric** | Criteria to determine good vs. bad scheduling |

---

## Scheduling Metrics

### Key Metrics for Evaluation
| Metric | Definition | Formula |
|--------|------------|---------|
| **Turnaround Time** | Total time from job arrival to completion | Completion time - Arrival time |
| **Response Time** | Time from job arrival to first execution | Start time - Arrival time |
| **Wait Time** | Time spent waiting in ready queue (not executing) | Turnaround time - Burst time |
| **Throughput** | Number of jobs completed per unit time | Total jobs / Total time |
| **Resource Utilization** | Percentage of time CPU is busy | (CPU busy time / Total time) × 100% |
| **Overhead** | Cost of context switching | Number of context switches × Cost per switch |
| **Fairness** | Equal treatment of processes over time | Subjective measure of equitable resource allocation |

### Hospital Analogy (Scheduling Problem)
- **Operating Room** = CPU
- **Patients** = Processes
- **Surgery** = CPU burst
- **Goal**: Minimize dead patients (maximize throughput), minimize wait times, maximize resource utilization

---

## Scheduling Algorithms

### Basic Assumptions
1. Jobs run for a fixed time
2. All jobs arrive simultaneously
3. All jobs are CPU-only
4. Run-time of each job is known

### First Come, First Serve (FCFS)
- **Concept**: Processes executed in arrival order
- **Advantages**: Simple to implement, appears fair
- **Disadvantages**: 
  - Dependent on job order
  - Big tasks can "starve" small tasks (Convoy Effect)
  - Poor average turnaround time

**Example**:
```
Job | Arrival | Burst | Turnaround
A   | 0       | 5     | 5
B   | 0       | 5     | 10
C   | 0       | 5     | 15
Avg |         |       | 10
```

**Convoy Effect**:
```
Big Task
Big Task
The Convoy
```
*Small tasks wait behind a long task, causing poor performance*

---

### Shortest Job First (SJF)
- **Concept**: Execute shortest jobs first
- **Advantage**: Minimizes average turnaround time
- **Disadvantage**: Requires knowledge of job length (not always available)

**Example**:
```
Job | Arrival | Burst | Turnaround
B   | 0       | 4     | 4
C   | 0       | 4     | 8
A   | 0       | 20    | 28
Avg |         |       | 16.6
```

*Note: SJF is non-preemptive unless modified to Shortest Time to Completion First (STCF)*

---

### Shortest Time to Completion First (STCF)
- **Concept**: Preemptive version of SJF
- **Idea**: Always run the job that will complete soonest
- **Advantage**: Better response time for short jobs
- **Disadvantage**: Requires knowing future job lengths

**Example**:
```
Job | Arrival | Burst | Turnaround | Response
A   | 0       | 10    | 10         | 0
B   | 2       | 10    | 18         | 8
C   | 4       | 10    | 26         | 16
Avg |         |       | 18         | 8
```

---

### Round Robin (RR)
- **Concept**: Each process gets a fixed time slice (quantum)
- **Advantage**: Fairness, good response time
- **Disadvantage**: High context switching overhead if quantum too small

**Example** (with 10ms quantum):
```
Job | Arrival | Burst | Turnaround | Response
A   | 0       | 10    | 26         | 0
B   | 2       | 10    | 26         | 0
C   | 4       | 10    | 26         | 0
Avg |         |       | 26         | 0
```

*Note: Response time is 0 because all jobs get immediate execution*

---

## I/O Considerations

### I/O Blocking
- **Concept**: Processes may need to wait for I/O operations
- **Key Insight**: Don't waste CPU time waiting for I/O
- **Example**:
  ```
  CPU  I/O
  Task A (2s) → (4s) → Task A (2s)
  ```

**Optimal Scheduling**:
- When a process blocks for I/O, immediately schedule another process
- This maximizes CPU utilization

### Scheduling Assumptions (Revised)
1. Jobs may have variable run times
2. Jobs may arrive at any time
3. Jobs may be CPU-bound or I/O-bound
4. Run-time may not be known in advance

---

## Advanced Scheduling Techniques

### Multi-Level Feedback Queue (MLFQ)
- **Concept**: Multiple priority queues with dynamic priority adjustment
- **Rules**:
  1. Run high priority jobs first (round robin for ties)
  2. Start with high priority
  3. If you run for too long, your priority drops
  4. Every so often, reset priorities (prevent starvation)

**Priority Dynamics**:
- **Fixed Priority**: 
  - High priority jobs always run first
  - Risk: Long jobs get starved (low priority jobs never run)
  
- **Dynamic Priority**:
  - Jobs that use CPU heavily have priority reduced
  - Jobs that use little CPU maintain high priority
  - Prevents starvation by periodically resetting priorities

**Evil Strategy (Malicious Process)**:
- Run for just under the time quantum (e.g., 9ms out of 10ms)
- This prevents priority reduction
- **Solution**: Track cumulative CPU usage over time

**Design Decisions**:
- How many queues?
- How long is an allotment (time quantum)?
- Are allotments the same for each queue?
- How often to refresh priorities?

---

### Lottery Scheduling
- **Concept**: Processes get tickets; random selection
- **Priority**: More tickets = higher priority
- **Design Considerations**:
  - Ticket trading (processes can exchange tickets)
  - Ticket inflation (ticket value changes over time)
  - Ticket currencies (different types of tickets)

---

### Completely Fair Scheduler (CFS)
- **Concept**: All tasks get fair share of CPU time
- **Key Idea**: Smallest `vruntime` (virtual runtime) gets priority
- **Mechanism**:
  - Each task has a `vruntime` (measured time)
  - Smallest `vruntime` tasks run first
  - Tasks run for a target latency period
  - Uses Red-Black tree for efficient priority management

**Why Red-Black Tree?**
- Balanced binary search tree
- O(log n) insertion/deletion time
- More efficient than AVL trees for this purpose

**Linux Implementation**:
- Used since 2007
- `nice` value adjusts priority (lower `nice` = more CPU)
- `nice(1)` = soft priority adjustment

**Example**:
- **Task 1 (Video Rendering)**: Long run-time, CPU-intensive, non-interactive
- **Task 2 (Word Processor)**: Intermittent CPU bursts, interactive
- **Result**: Task 2 accumulates little `vruntime` and runs immediately after user input

---

## Multi-core Considerations

### Linux Scheduler on Multi-core Systems
- **Per-core Red-Black Tree**: One tree per CPU core
- **Challenge**: Fairly distribute tasks between cores
- **Problem**: "Queue hopping" (processes moving between cores)
  - Example: A process might be assigned to a busy core instead of an idle one
  - Similar to choosing a long line at a supermarket

**Solution**: Requires coordination between cores to balance load

---

## Summary of Scheduling Algorithms

| Algorithm | Type | Key Feature | Best For |
|-----------|------|-------------|----------|
| **FCFS** | Non-preemptive | Simple, appears fair | Not recommended (convoy effect) |
| **SJF** | Non-preemptive | Minimizes average turnaround | Batch processing |
| **STCF** | Preemptive | Minimizes response time | Interactive systems |
| **RR** | Preemptive | Fairness, good response time | Interactive systems |
| **MLFQ** | Dynamic | Handles mixed workloads | General purpose systems |
| **CFS** | Dynamic | Fairness, no starvation | Linux systems |

---

## Key Takeaways

1. **Scheduling is about trade-offs**: No single algorithm is optimal for all scenarios
2. **Metrics matter**: Choose metrics based on system goals (response time vs. throughput)
3. **I/O is critical**: Don't waste CPU time waiting for I/O
4. **Dynamic priority is key**: MLFQ handles mixed workloads effectively
5. **Fairness is complex**: CFS ensures no process starves while maintaining responsiveness
6. **Real-world systems are complex**: Linux uses CFS with sophisticated tuning
7. **Design decisions are crucial**: Queue count, quantum length, and refresh frequency impact performance

> "The goal of scheduling is to maximize system throughput while maintaining acceptable response times for interactive processes." - Lecture Quote

---

## Study Questions

1. How does the Convoy Effect impact FCFS scheduling?
2. Why is SJF non-preemptive in its basic form, and how does STCF improve upon it?
3. What is the difference between response time and turnaround time?
4. How does MLFQ prevent starvation of long-running processes?
5. Why is a Red-Black tree used in CFS instead of other data structures?
6. How does the `nice` value affect process scheduling in Linux?
