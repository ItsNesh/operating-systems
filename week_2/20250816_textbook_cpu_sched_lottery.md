<!-- 
Generated by LectureQ (Enhanced Comprehensive Version)
Date: 2025-08-16 02:47:16
Model: qwen3:30b
Output Mode: Comprehensive
-->

<think>
We are creating comprehensive study notes based on the provided textbook slides about "Scheduling: Proportional Share" (Week 2). The goal is to cover every concept, theory, example, and principle from all slides.

Let's break down each slide and extract:

Slide 1:
- Introduction to proportional-share scheduling (also called fair-share scheduler)
- Basic idea: guarantee a certain percentage of CPU time for each job.
- Example: Waldspurger and Weihl [WW94] - lottery scheduling
- CRUX question: How to share the CPU proportionally?

Slide 2:
- Tickets represent share. Percent of tickets = percent of resource.
- Example with A (75 tickets) and B (25 tickets): should get 75% and 25% respectively.
- Lottery: every time slice, pick a random ticket from total (100 in example). If A has tickets 0-74 and B 75-99, then winning number determines which runs.
- Example output of lottery winners: [63,85,...] leading to schedule: A repeated 15 times, then B four times -> 20% for B (desired 25%, but probabilistic).
- TIP on randomness: advantages - avoids corner cases, lightweight (minimal state), fast.

Slide 3:
- Ticket mechanism is powerful and can be applied broadly (e.g., memory in hypervisors [W02]).
- Ticket mechanisms:
   a. Ticket currency: user allocates tickets to their own jobs in their own currency; system converts to global.
      Example: User A gives each of two jobs 500 tickets (in A's currency) -> converted to 50 each globally. User B gives job 10 tickets (B's currency) -> converted to 100 globally. Total global = 200.
   b. Ticket transfer: process can hand off tickets temporarily (e.g., client passing to server for faster work).
   c. Ticket inflation: temporarily raise/lower ticket count (in trusted environments).

Slide 4:
- Implementation of lottery scheduling code (Figure 9.1):
   - Traverse a list of processes, accumulating the number of tickets until exceeding a random winner.
   - Example with A(100), B(50), C(250) -> total=400; if winner=300, then:
        counter starts at 0
        add A: counter=100 (less than 300)
        add B: counter=150 (less than 300)
        add C: counter=400 (>300) -> choose C.
   - Efficiency tip: sort the list by tickets descending to minimize iterations.

Slide 5:
- Example study on fairness (Figure 9.2):
   - Fairness metric F = time_first_job_finish / time_second_job_finish
   - Goal: F=1 for perfect fairness.
   - Graph shows that as job length R increases, average fairness approaches 1 (i.e., more fair over longer runs).

Slide 6:
- How to assign tickets? Open problem. User allocation is not a solution because it doesn't tell you what to do.
- Stride scheduling: deterministic alternative by Waldspurger [W95].
   - Each job has a stride = large number / tickets (e.g., 10,000/tickets).
   - Example: A(100), B(50), C(250) -> strides: A=100, B=200, C=40.
   - Each job has a pass value. When run, increment by stride.
   - Scheduler picks the process with lowest pass value to run next (pseudocode provided).
   - Example trace in Figure 9.3: shows that over time, runs are proportional to tickets.

Slide 7:
- Comparison of lottery vs stride:
   - Lottery: simple implementation, no global state per process -> easy to add new processes.
   - Stride: exact proportions at the end of each cycle (deterministic), but requires setting initial pass for new jobs appropriately.
- Linux CFS introduced as current approach.

Slide 8:
- CFS (Completely Fair Scheduler) in Linux:
   - Goal: fairly divide CPU among competing processes.
   - Uses virtual runtime (vruntime): accumulates at same rate per physical time, unless weighted by nice level.
   - When scheduling decision occurs, pick process with lowest vruntime.
   - Schedlatency parameter: target period for fairness. Time slice = schedlatency / n (n=number of processes).
   - Mingranularity: minimum time slice to avoid too many context switches.

Slide 9:
- Weighting via nice levels (-20 to +19, default 0). Weights table provided.
- Formula for time slice: timeslice_k = weight_k / sum(weight_i) * schedlatency
   Example: A (nice=-5 -> weight=3121), B (default, weight=1024); then A gets ~75% of the time slice? Actually 3121/(3121+1024)=~75%, so timeslice_A = 0.75 * schedlatency.
- Formula for vruntime: 
   vruntime_i = current_vruntime + (weight0 / weight_i) * runtime_i
   where weight0=1024.

Slide 10:
- CFS uses red-black tree to efficiently find the process with lowest vruntime (logarithmic time).
- Example of a red-black tree for processes ordered by vruntime.
- Why not list? Because searching in a sorted list is O(n) per operation, while balanced trees are O(log n).

Slide 11:
- Handling sleeping processes: when a process wakes up after sleep, set its vruntime to the minimum value in the tree (to avoid starvation).
   - However, this can cause short-sleeping jobs not getting their fair share.

Slide 12:
- Summary of proportional-share scheduling approaches.
- Problems with fair-share schedulers: 
   - Not mesh well with I/O (jobs doing I/O may not get fair CPU)
   - Ticket/priority assignment is hard (how many tickets for browser? nice value for text editor?)
- When to use: virtualized data centers, cloud environments.

Slide 13:
- References and citations.

Slide 14:
- Homework questions about simulation of lottery scheduler.

Now, we will create comprehensive study notes in markdown format with the following structure:

# Hierarchical Headers
## Key Terms (bolded)
### Detailed Explanations
#### Examples (with detailed breakdowns)

We'll also include tables for comparisons and formulas.

Let's start writing.
</think>

# Comprehensive Study Notes: Scheduling - Proportional Share  

---

## **Core Concept & CRUX**  
**Proportional-Share Scheduling**: A scheduler that guarantees each process a *specific percentage* of CPU time (e.g., 75% for Process A, 25% for Process B), rather than optimizing for turnaround/response time.  
> **CRUX QUESTION**: How to design a scheduler to share the CPU proportionally? What are key mechanisms and their effectiveness?

---

## **Key Mechanisms & Theories**  

### ðŸ”‘ **1. Ticket System: Foundation of Proportional Sharing**  
- **Tickets**: Numerical representation of a processâ€™s *share* of resources (CPU, memory).  
  - `Process Share % = (Process Tickets / Total Tickets) Ã— 100`  
  - Example: Process A has 75 tickets, B has 25 â†’ A gets 75% CPU, B gets 25%.  

- **Lottery Scheduling**: Uses randomness to allocate CPU based on ticket count.  
  - *Mechanism*: At each time slice, pick a random number `0 â‰¤ winner < Total Tickets`. Process owning the winning ticket runs next.  
    > Example: A (tickets 0â€“74), B (75â€“99). Winning numbers `[63,85,70,...]` â†’ Schedule: **A repeated 15x**, then **B 4x** (20% for B vs. desired 25%).  
    > *Why probabilistic?* Long-term fairness improves with more time slices; short-term deviations occur due to randomness.

- **Advantages of Randomness**:  
  | Advantage                | Explanation                                                                 |
  |--------------------------|-----------------------------------------------------------------------------|
  | Avoids corner cases      | Unlike LRU (worst-case for cyclic workloads), random avoids deterministic failures. |
  | Lightweight              | Minimal state: Only track *number of tickets per process* (no per-process CPU accounting). |
  | Fast                     | Random number generation is O(1); decision speed matches hardware limits. |

---

### ðŸ”‘ **2. Ticket Mechanisms**  
#### a) **Ticket Currency**  
- Allows users to allocate tickets in their own "currency," converted globally by the system.  
  > *Example*:  
  > - User A: 100 global tickets â†’ Allocates 500 each to jobs A1, A2 (in Aâ€™s currency).  
  >   Global conversion: `500 / 1000 Ã— 100 = 50` per job.  
  > - User B: 100 global tickets â†’ Allocates 10 to job B1 (Bâ€™s currency).  
  >   Global conversion: `10 / 10 Ã— 100 = 100`.  
  > **Total Tickets**: A1=50, A2=50, B1=100 â†’ Lottery runs over global tickets.  

#### b) **Ticket Transfer**  
- Process temporarily hands off its tickets to another process (e.g., clientâ†’server for faster work).  
  - *Use Case*: Client sends message to server; transfers tickets to prioritize the request. Server returns tickets after completion.  

#### c) **Ticket Inflation**  
- Temporarily increases/decreases a processâ€™s ticket count in trusted environments.  
  > *Example*: A group of processes trusts each other â†’ If Process X needs more CPU, it inflates its tickets (no communication needed).  
  > âš ï¸ *Not for competitive settings* (greedy processes could monopolize resources).

---

### ðŸ”‘ **3. Implementation: Lottery Scheduling**  
#### Pseudocode & Workflow (`Figure 9.1`):  
```c
int counter = 0;
int winner = getrandom(0, total_tickets); // Random number in [0, total-1]
node_t*current = head; 
while (current) {
    counter += current->tickets;
    if (counter > winner) break; // Found winner!
    current = current->next;
}
schedule(current); // Run the winning process
```

#### Efficiency Optimization:  
- **Sort processes by tickets descending** to minimize list iterations.  
  > *Example*: Processes A(100), B(50), C(250) â†’ Sorted as [C, A, B]. For winner=300:  
  > - Counter += C (250) â†’ 250 < 300? Yes â†’ Next.  
  > - Counter += A (100) â†’ 350 > 300 â†’ **Winner = A** (only 2 iterations vs. 3 unsorted).  

---

### ðŸ”‘ **4. Fairness Analysis: Lottery Scheduling**  
#### Fairness Metric (`F`):  
> `F = Time_First_Job_Completes / Time_Second_Job_Completes`  
- Perfect fairness â†’ `F â‰ˆ 1`.  
- *Example*: Jobs A/B with equal tickets (R=10) finish at times 10 and 20 â†’ `F = 10/20 = 0.5`.  

#### Key Insight (`Figure 9.2`):  
| Job Length (R) | Average Fairness (F) |
|----------------|----------------------|
| Short (e.g., R=1) | Low (~0.4â€“0.6)       |
| Long (e.g., R=1000)| High (>0.95)         |

> **Conclusion**: Lottery scheduling achieves fairness *only over long time scales*; short jobs exhibit significant variance.

---

### ðŸ”‘ **5. Stride Scheduling: Deterministic Alternative**  
- **Goal**: Achieve exact proportional sharing without randomness (Waldspurger [W95]).  

#### Core Mechanism:  
1. Each process has a `stride = Large_Number / Tickets` (e.g., 10,000/tickets).  
2. Track `pass_value` for each process (initially 0).  
3. **Scheduler picks the process with lowest `pass_value`** to run next.  
4. After running: `pass_value += stride`.  

> *Example*: A(100 tickets), B(50), C(250) â†’ Strides: A=100, B=200, C=40.  
> **Trace (`Figure 9.3`)**:
| Pass(A)=100 | Pass(B)=200 | Pass(C)=40 | Who Runs? |
|-------------|-------------|------------|-----------|
| 0           | 0           | 0          | A         |
| 100         | 0           | 0          | B         |
| 100         | 200         | 0          | C         |
| ...         |             |            | **C runs 5x**, A 2x, B 1x â†’ Matches ticket ratio (250:100:50 = 5:2:1). |

#### Lottery vs. Stride Comparison:  
| Feature                | Lottery Scheduling       | Stride Scheduling        |
|------------------------|--------------------------|--------------------------|
| **Fairness**           | Probabilistic (long-term) | Exact at cycle end       |
| **State per Process**  | Minimal (`tickets` only) | Requires `pass_value`    |
| **Adding New Processes**| Easy: Add with tickets   | Hard: Must set initial `pass_value` correctly |

> ðŸ’¡ *Why use lottery?* Simpler for dynamic systems (e.g., new processes join mid-schedule).

---

### ðŸ”‘ **6. Linux Completely Fair Scheduler (CFS)**  
#### Core Idea:  
- Replace fixed time slices with a **virtual runtime (`vruntime`)** that scales by process priority.  

#### Key Parameters & Formulas:  
| Parameter               | Description                                                                 |
|-------------------------|-----------------------------------------------------------------------------|
| `sched_latency`         | Target fairness period (default = 48 ms). Time slice per job = `sched_latency / n`. |
| `min_granularity`       | Minimum time slice (default = 6 ms) to avoid excessive context switches.    |

#### **Time Slice Calculation** (`Equation 9.1`):  
> `timeslice_k = weight_k / Î£(weight_i) Ã— sched_latency`  

- *Example*: Process A (nice=-5 â†’ weight=3121), B (default, nice=0 â†’ weight=1024).  
  > Total weight = 3121 + 1024 = 4145.  
  > `timeslice_A â‰ˆ (3121/4145) Ã— 48 ms â‰ˆ 36 ms`, `timeslice_B â‰ˆ 12 ms`.  

#### **Virtual Runtime (`vruntime`) Update** (`Equation 9.2`):  
> `vruntime_i = vruntime_i + (weight0 / weight_i) Ã— runtime_i`  
- Where `weight0 = 1024` (default weight).  
- *Example*: A runs for 1 ms â†’ `vruntime_A += (1024/3121) Ã— 1 â‰ˆ 0.33 ms`. B runs same time â†’ `vruntime_B += (1024/1024)Ã—1 = 1 ms`.  
- **Result**: A accumulates vruntime slower than B due to higher priority.

#### Data Structure: Red-Black Tree  
| Why?                     | Benefit                                                                 |
|--------------------------|-------------------------------------------------------------------------|
| Avoids O(n) list searches | Modern systems have thousands of processes â†’ Linear search wastes CPU.   |
| Logarithmic operations   | Insert/delete/find in **O(log n)** vs. linear for lists (e.g., 10,000 processes: logâ‚‚(10k)=~14 ops). |

> *Example*: Processes with `vruntime` values [1,5,9,...24] stored in red-black tree â†’ Lowest vruntime found in O(log n) time.

#### Handling Sleeping Processes  
- **Problem**: A process waking after sleep (e.g., 10s) has much lower vruntime than others.  
- **CFS Fix**: Set `vruntime` to *minimum value* in the tree when it wakes up â†’ Prevents starvation but causes short-sleeping jobs to miss fair share.

---

## **Summary of Scheduling Approaches**  

| Approach          | Fairness Type     | Key Mechanism                     | Pros                                      | Cons                                       |
|-------------------|-------------------|-----------------------------------|-------------------------------------------|--------------------------------------------|
| **Lottery**       | Probabilistic     | Random ticket selection           | Simple, no global state                   | Short-term unfairness                      |
| **Stride**        | Deterministic     | `stride = Large_Number / Tickets` | Exact fairness at cycle end               | Hard to add new processes                  |
| **CFS (Linux)**   | Weighted Fairness | `vruntime` + red-black tree       | Efficient, scales well, handles priorities | Complex; I/O jobs may starve               |

---

## **Critical Problems & Limitations**  
1. **I/O and Starvation**:  
   - Processes doing frequent I/O (e.g., waiting for disk) wake up with low vruntime â†’ May monopolize CPU until they catch up (`CFS` mitigates this but not perfectly).  
2. **Ticket/Priority Assignment**:  
   - *Hard open problem*: How many tickets should a browser get? What `nice` value for a text editor?  
   - *Contrast with MLFQ*: General-purpose schedulers (e.g., Linuxâ€™s MLFQ) auto-assign priorities; proportional-share requires manual tuning.  
3. **When to Use Proportional Sharing**:  
   - Ideal in virtualized environments (e.g., assign 25% CPU to Windows VM, rest to Linux).  
   - *Not ideal* for I/O-heavy workloads or systems where priority assignment is non-trivial.

---

## **Key Formulas**  

| Formula                                      | Description                                  |
|----------------------------------------------|---------------------------------------------|
| `Share % = (Tickets / Total Tickets) Ã— 100`  | Ticket-based CPU allocation                 |
| `stride = Large_Number / Tickets`            | Stride scheduling base value                |
| `timeslice_k = weight_k / Î£(weight_i) Ã— sched_latency` | CFS time slice calculation |
| `vruntime_i += (weight0 / weight_i) Ã— runtime_i` | CFS virtual runtime update |

---

## **15-20 Study Questions**  
*(For exam mastery and deep learning)*  

1. How does lottery scheduling achieve proportional sharing? Why is it probabilistic, not deterministic?  
2. Explain the *ticket currency* mechanism with a numerical example (include global conversion).  
3. What are three advantages of using randomness in scheduler design? Provide concrete examples for each.  
4. In stride scheduling, why must `stride = Large_Number / Tickets` instead of just `1/Tickets`?  
5. Calculate the exact run order for processes A(20 tickets), B(30 tickets), C(50 tickets) using stride scheduling (use large number=100).  
6. How does CFS handle a process waking up after 1 second of sleep? What is the trade-off?  
7. Derive `timeslice_A` for two processes: A (nice=-2, weight=8876), B (default, nice=0, weight=1024). Assume `sched_latency`=48ms.  
8. Why does CFS use a red-black tree instead of a sorted list? Quantify the performance difference for 10,000 processes.  
9. In lottery scheduling with two jobs (A:50 tickets, B:50 tickets), what is the probability job A finishes before job B if both have length R=2 time slices?  
10. How does ticket inflation differ from ticket transfer in practice? Give a use case for each.  
11. Why canâ€™t stride scheduling easily handle new processes joining mid-schedule? What happens if you set `pass_value` to 0?  
12. Explain why CFSâ€™s fairness metric (`F`) approaches 1 as job length increases (based on Figure 9.2).  
13. Describe the *crux* of proportional-share scheduling: Why is it harder than optimizing for response time?  
14. How does Linux CFS map `nice` values to weights in practice? What happens if a process has nice=+5 vs. nice=0?  
15. In what scenario would you choose lottery over stride scheduling, and vice versa? Justify with system properties.  
16. Why is the *minimum granularity* parameter (`min_granularity`) necessary in CFS? Provide an example where it prevents excessive context switches.  
17. How does ticket transfer improve performance in a client/server architecture? What happens if the server crashes after receiving tickets?  
18. Explain why proportional-share schedulers struggle with I/O-bound processes (e.g., web servers waiting for network packets).  
19. Calculate `vruntime` accumulation for two jobs: A (nice=-5, weight=3121) and B (default, weight=1024), each running 1ms in a CFS system with `sched_latency`=48ms.  
20. Compare the *state overhead* of lottery vs. stride scheduling per process. Which requires more memory? Why?

---

> **Final Insight**: Proportional-share scheduling is not "better" than other schedulersâ€”itâ€™s designed for specific use cases (e.g., cloud resource allocation). The choice depends on whether you prioritize simplicity (`lottery`), exact fairness (`stride`), or scalability/efficiency in modern systems (`CFS`). Mastery requires understanding *when* to apply each approach.