<!-- 
Generated by LectureQ
Date: 2025-08-09 16:16:16
Model: qwen3:30b
-->

<think>
I need to create comprehensive lecture notes for a student who missed class. The instructions are very clear: I must include EVERYTHING from both the slides and the transcript without summarizing. I'll be writing exhaustive notes that preserve every detail, example, and explanation.

Let me analyze what I have:

1. Slide content (64 slides)
2. Transcript of the lecture

I need to combine these into comprehensive notes, making sure to include all concepts, definitions, examples, explanations, analogies, and emphasized points.

I'll organize this with proper markdown formatting, using hierarchical headers, tables, lists, and code blocks where appropriate.

Let me start by creating a title and overview based on the lecture content.

The lecture is about Operating Systems Scheduling for Week 2, Lecture 2.

Now I'll go through each slide and transcript to extract all information, making sure not to miss anything.

I'll organize this into sections that follow the logical flow of the lecture:

1. Introduction to scheduling
2. Key definitions and concepts
3. Scheduling metrics
4. Scheduling algorithms (FCFS, SJF, STCF, RR)
5. I/O blocking considerations
6. Priority-based scheduling
7. Multi-level feedback queue (MLFQ)
8. Other scheduling approaches (Lottery, CFS)
9. Summary

Let me now extract all the information from both sources.

From Slide 3: Last Week - Virtualisation
- Each process thinks it has its own computer
- Direct execution is faster
- Limited execution at key points to ensure OS control
- Hardware provides a lot of OS functionality
- User vs Kernel
- Clock
- Register Saving

From Slide 6: Scheduling vs Dispatching
- Dispatcher: Determines how to switch between processes (User mode/kernel mode, Saving PCBs...)
- Scheduler: Determines which process to dispatch (Conceptual - When)

From Slide 7: Scheduling and States
- Running, Ready, Blocked (I/O: Started I/O: Done Scheduled)

From Slide 8: Definitions
- Workload: The 'jobs' that need to be done
- Job: View as current CPU burst of a process
- Process sometimes alternates between CPU & I/O
- Process moves between ready and blocked queues
- Scheduler: Logic for the job choice
- Metric: Something to determine good from bad

From Slide 9-18: Good Scheduling vs Bad Scheduling (with hospital analogy)
- Turnaround Time: completion_time - arrival_time
- Response Time: start_time - arrival_time
- Wait Time: time waiting when could be treated
- Throughput: how many happy people get through (non-dead patients)
- Resource Utilisation: keep operating room busy
- Overhead (Switches): minimize context switches
- Fairness: even treatment

From Slide 19-22: Scheduling Algorithms and Assumptions
- First Come, First Serve (FCFS)
- Shortest Job First (SJF)
- Shortest Time to Completion First (STCF)
- Round Robin (RR)
- Multilevel Feedback Queue (MLFQ)

Scheduling Assumptions:
1. Jobs run for a fixed time
2. All jobs arrive simultaneously
3. All jobs are CPU-only
4. Run-time of each job is known

From Slide 23-29: FCFS details
- Turnaround Time = completion_time - arrival_time
- Response Time = start_time - arrival_time
- Convoy Effect: big tasks "starving" small tasks

From Slide 30: The Convoy Effect (illustration)

From Slide 31-32: SJF metrics and examples

From Slide 33: Scheduling Assumptions (repeated)

From Slide 34: Pre-emptive vs Non-Pre-emptive scheduling

From Slide 35: STCF metrics

From Slide 36-37: RR metrics

From Slide 38-43: I/O Blocking
- CPU should not be wasted when waiting for I/O
- Example of task with CPU and I/O periods

From Slide 44-52: MLFQ concepts
- Jobs can be varying length, arrive at any time, don't know finish time
- Different jobs have different aims (Interactive vs Batch)
- Priority (Fixed) vs Priority (Dynamic)
- Rules for MLFQ:
  - Run high priority jobs first (round robin for ties)
  - Start high priority
  - If run too long, priority drops
  - Every so often, put jobs back into top priority

From Slide 53: Priority (Evil) - how to be evil in the system

From Slide 54-55: MLFQ rules with "allotment" concept

From Slide 56: Design Decisions for MLFQ
- How many queues?
- How long is an allotment?
- Are allotments the same for each queue level?
- How often to refresh priorities?

From Slide 57: Lottery Scheduling
- Processes get tickets, choose random ticket
- Priorities = More Tickets
- Ticket trading? Ticket inflation? Ticket currencies?

From Slide 58-60: Completely Fair Scheduler (CFS)
- vruntime measured for each task
- Smallest vruntime tasks run with priority
- Each task runs for target latency period
- Shares depend on weight (no starvation)
- Uses Red/Black tree
- Works in Linux since 2007

From Slide 61: nice(1) - "soft" priority, changing nice value changes weighting

From Slide 62: Multi-core CPUs - one red-black tree per core

Now for the transcript content:

The speaker discusses:
- Housekeeping (tutorials due Sunday night, assignment 1 and 2)
- Scheduling concepts
- Scheduling vs Dispatching
- Process states (Running, Ready, Blocked)
- Definitions of workload, job, scheduler, metric
- Hospital analogy to explain scheduling metrics
- Gantt charts
- Scheduling assumptions
- FCFS algorithm with examples
- Convoy effect explanation
- SJF algorithm
- Pre-emptive vs Non-pre-emptive
- STCF (Shortest Time to Completion First)
- RR (Round Robin) algorithm
- I/O blocking considerations
- Priority-based scheduling
- MLFQ details and "evil" strategy
- Lottery scheduling
- CFS (Completely Fair Scheduler) with vruntime
- Red/Black tree explanation
- nice command in Linux

I need to make sure I include all these points, including the speaker's examples, analogies, and explanations.

Let me now create the comprehensive notes following the instructions.
</think>

# Operating Systems: Scheduling (Week 2, Lecture 2)

## Overview
This lecture covers scheduling concepts in operating systems. It explains scheduling vs dispatching, process states, key metrics for evaluating scheduling algorithms, and various scheduling algorithms including FCFS, SJF, STCF, RR, and MLFQ. The lecture also discusses I/O blocking considerations, priority-based scheduling, lottery scheduling, and the Completely Fair Scheduler (CFS) used in Linux.

---

## Scheduling Fundamentals

### Last Week: Virtualisation
- Each process thinks it has its own computer
- Direct execution is faster
- Limited execution at key points to ensure OS control
- Hardware provides a lot of OS functionality
- User vs Kernel mode
- Clock functionality
- Register saving mechanisms

### Scheduling vs Dispatching
**Dispatcher**
- Determines how to switch between processes
- Involves user mode/kernel mode transitions
- Saving Process Control Blocks (PCBs)
- Mechanical aspect (How)

**Scheduler**
- Determines which process to dispatch
- Conceptual aspect (When)

### Scheduling and States
Processes exist in three states:
- **Running**: The operating system thinks the process is doing work
- **Ready**: The process wants to do work but isn't currently running
- **Blocked**: The process can't do anything (e.g., waiting for I/O)

*Visual representation:*
```
Running → Ready → Blocked (I/O: Started) → I/O: Done → Scheduled
```

### Key Definitions
- **Workload**: The 'jobs' that need to be done
- **Job**: View as current CPU burst of a process
  - Processes alternate between CPU & I/O
  - Processes move between ready and blocked queues
- **Scheduler**: Logic for the job choice
- **Metric**: Something to determine good from bad (e.g., what makes scheduling "good" or "bad"?)

---

## Good Scheduling vs Bad Scheduling

### Hospital Analogy Activity
*Activity: Imagine you're running a hospital with an operating room (for surgery). You have a list of patients needing various operations. How do you determine the best way to use the operating room? What things do we want to maximize or minimize?*

#### Key Metrics for Evaluation
1. **Turnaround Time**  
   *Definition*: Completion time - Arrival time  
   *Visual representation*:
   ```
   Arrival Time → Start Treatment → Finish Treatment
   ```

2. **Response Time**  
   *Definition*: Start time - Arrival time  
   *Visual representation*:
   ```
   Arrival Time → Start Treatment → Finish Treatment
   ```

3. **Wait Time**  
   *Definition*: Time waiting when could be treated (not including I/O wait)  
   *Visual representation*:
   ```
   Arrival Time → Start Treatment → Finish Treatment → Pause Treatment → Resume Treatment
   ```

4. **Throughput**  
   *Definition*: How many happy people get through (non-dead patients)  
   *Visual representation*:
   ```
   Arrival Time → Finish Treatment
   ```

5. **Resource Utilisation**  
   *Definition*: Keep operating room busy at all times  
   *Visual representation*:
   ```
   Arrival Time → BAD (empty operating room)
   ```

6. **Overhead (Switches)**  
   *Definition*: Minimize context switches (e.g., switching patients in operating room)  
   *Visual representation*:
   ```
   BAD (frequent switches)
   ```

7. **Fairness**  
   *Definition*: Even treatment of all patients  
   *Visual representation*:
   ```
   GOOD: Even distribution
   BAD: One patient dominating
   ```

---

## Scheduling Algorithms and Assumptions

### Gantt Charts
- Visual representation of task scheduling over time
- Example:
  ```
  Task 1 | Task 2 | Task 3
  ```

### Tables for Scheduling Examples
| Job | Arrival Time | Burst Time |
|-----|--------------|------------|
| A   | 0            | 5          |
| B   | 0            | 5          |
| C   | 0            | 5          |

*Time line:*
```
0    5    10    15
```

### Scheduling Assumptions (Textbook)
1. Jobs run for a fixed time
2. All jobs arrive simultaneously
3. All jobs are CPU-only
4. Run-time of each job is known

*Note: These assumptions are not true in real systems, but they provide a starting point for algorithm development.*

---

## Scheduling Algorithms

### First Come, First Serve (FCFS)
- Simplest scheduling algorithm
- Processes executed in the order they arrive
- **Advantages**: Very simple to implement; has a 'veneer' of fairness
- **Problems**: Dependent on job order; big tasks can 'starve' small tasks (Convoy Effect)

#### FCFS Metrics
*Turnaround Time = Completion time - Arrival time*  
*Response Time = Start time - Arrival time*

**Example 1:**
```
0    5    10    15
Task A Task B Task C
```

| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 5          | 5               |
| B   | 0            | 5          | 10              |
| C   | 0            | 5          | 15              |

*Average Turnaround Time = (5 + 10 + 15) / 3 = 10*

**Example 2:**
```
0    5    10    15    20    25    30
Task A Task B Task C
```

| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 20         | 20              |
| B   | 0            | 4          | 24              |
| C   | 0            | 4          | 28              |

*Average Turnaround Time = (20 + 24 + 28) / 3 = 24*

**Example 3:**
```
0    5    10    15    20    25    30
Task A Task B Task C
```

| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 4          | 4               |
| B   | 0            | 4          | 8               |
| C   | 0            | 20         | 28              |

*Average Turnaround Time = (4 + 8 + 28) / 3 = 16.6*

#### The Convoy Effect
- *Visual representation:*
  ```
  Big Task → Big Task → The Convoy
  ```
- Explanation: A long task "blocks" many short tasks waiting for it to complete, similar to a large truck blocking smaller cars on a highway.

---

### Shortest Job First (SJF)
- Schedule the shortest job first
- Reduces average turnaround time compared to FCFS
- **Problem**: If jobs don't arrive simultaneously, SJF may not be optimal

#### SJF Metrics Example
```
0    5    10    15    20    25    30
Task A Task B Task C
```

| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 20         | 20              |
| B   | 0            | 4          | 24              |
| C   | 0            | 4          | 28              |

*Average Turnaround Time = (20 + 24 + 28) / 3 = 24*

#### SJF with Late Arrivals
```
0    5    10    15    20    25    30
Task A Task B Task C
```

| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 20         | 20              |
| B   | 2            | 4          | 22              |
| C   | 2            | 4          | 26              |

*Average Turnaround Time = (20 + 22 + 26) / 3 = 22.6*

---

### Pre-emptive Scheduling
- **Non-preemptive**: Once a process starts, it runs to completion without interruption
- **Preemptive**: Can interrupt a running process to switch to another

*Visual comparison:*
```
Non-Pre-emptive:
0    20    30
Task A Task B Task C

Pre-emptive:
0    20    30
Task A Task B Task C
```

---

### Shortest Time to Completion First (STCF)
- Preemptive version of SJF
- Always run the job that will finish the soonest
- Also called "Earliest Deadline First" in real-time systems

#### STCF Metrics Example
```
0    10    20    30
Task A Task B Task C
```

| Job | Arrival Time | Burst Time | Turnaround Time | Response Time |
|-----|--------------|------------|-----------------|---------------|
| A   | 0            | 10         | 10              | 0             |
| B   | 2            | 10         | 18              | 8             |
| C   | 4            | 10         | 26              | 16            |

*Average Response Time = (0 + 8 + 16) / 3 = 8*

---

### Round Robin (RR)
- Each process gets a fixed time slice (quantum)
- After the time slice, the process is preempted and moved to the end of the queue
- **Advantage**: Fairness (all processes get a chance)
- **Disadvantage**: High context switching overhead

#### RR Metrics Example
```
0    10    20    30
Task A Task B Task C
```

| Job | Arrival Time | Burst Time | Turnaround Time | Response Time |
|-----|--------------|------------|-----------------|---------------|
| A   | 0            | 10         | 26              | 0             |
| B   | 2            | 10         | 26              | 0             |
| C   | 4            | 10         | 26              | 0             |

*Average Response Time = (0 + 0 + 0) / 3 = 0*

---

## I/O Blocking Considerations

### Input/Output Blocking
- Processes often wait for I/O operations (keyboard, mouse, printer)
- When waiting for I/O, the process is blocked and CPU can be used by other processes
- *Key insight*: Don't waste CPU time when a process is waiting for I/O

#### I/O Blocking Example
```
0    10    20    30
Task A Task B
CPU   I/O
```

*Explanation:* When Task A is doing I/O (from 10-20), the CPU can be used by Task B.

#### Better I/O Blocking Example
```
0    10    20    30
Task B
CPU   I/O
```

*Explanation:* Task B runs on CPU while Task A is waiting for I/O, so CPU is not wasted.

---

## Priority-Based Scheduling

### Priority (Fixed)
- Higher priority jobs run before lower priority jobs
- *Example:*
  ```
  Big Job → Small Job → Small Job → Big Job → Big Job
  ```

*Note:* If a job has higher priority, it can preempt lower priority jobs.

#### Same Priority Handling
- When jobs have the same priority, use Round Robin scheduling
- *Example:*
  ```
  Job → Job → Job → Job → Job → Job → Job → Job
  ```

#### Lower Priority Problem
- *Example:*
  ```
  Big Job → Big Job → Big Job → Big Job → Big Job
  ```
- Explanation: A low priority job (Big Job) will never run if it's always preempted by higher priority jobs.

---

### Priority (Dynamic)
- Adjust priorities based on process behavior
- *Logic:* 
  - If a job takes a lot of CPU (everything you give it), reduce its priority
  - If a job uses only a little CPU, keep its priority high

*Visual representation:*
```
Big Job → Priority → Runs too long? → Drop priority
Tiny I/O Jobs → I/O → I/O → CPU → I/O
```

#### Dynamic Priority Problem
- *Question:* "If a job can only lose priority, won't it eventually get ignored?"
- *Answer:* Yes, this is the problem with fixed priority systems.

---

## Multi-Level Feedback Queue (MLFQ)

### Situation
- Jobs can be of varying length
- Jobs can arrive at any time
- We don't know when they will finish
- Different jobs have different aims:
  - Interactive Jobs: Need good response time
  - Batch Jobs: Need good turnaround time

### MLFQ Rules
1. Run high priority jobs first (round robin for ties)
2. You start high priority
3. If you run for too long, your priority drops
4. Every so often, put jobs back into the top priority

*Visual representation:*
```
Queue 0 → Run this queue first
Queue 1 → Run if queue 2 is empty
Queue 2 → Run if queue 2 and queue 1 are empty
```

### The "Evil" Strategy (How to be malicious)
- *Question:* "Under this system, how can we be evil?"
- *Answer:* Design a process that stays at the top priority by:
  - Running for just under the allotment time before sleeping
  - Example: If allowed 10ms, run for 9.9ms and sleep for 0.1ms

*Visual representation of "evil" strategy:*
```
Big Job → Priority → Runs too long? → Drop priority → Queue 0 → Queue 1 → Queue 2 → Sad Big Job
```

### MLFQ Design Decisions
- How many queues?
- How long is an allotment?
- Are allotments the same for each queue level?
- How often to refresh priorities?

*Note:* These are design decisions with no perfect answers. They're determined through experimentation.

---

## Other Scheduling Approaches

### Lottery Scheduling
- Processes get tickets, and a random ticket is chosen
- Priorities = More Tickets
- *Weird thoughts:*
  - Ticket trading?
  - Ticket inflation?
  - Ticket currencies?

*Example:* A process with 100 tickets has a higher chance of being selected than one with 1 ticket.

---

### Completely Fair Scheduler (CFS)
- **Premise:** All tasks have their vruntime measured
- **Key concepts:**
  - Smallest vruntime tasks are run with priority
  - Each task runs for a bit over target latency period
  - Each task gets a share depending on its weight (no starvation)
  - Works using a Red/Black tree
  - Used in Linux since 2007

#### Why CFS?
- Priority is important to know
- Finding the highest priority needs to be low complexity (O(log(n)))
- *Visual representation:*
  ```
  Small Large
  9   5   2   6   8   10   12
  ```

#### CFS Example
- **Task 1:** Video Rendering
  - Long run-time, CPU intensive
  - Non-interactive
- **Task 2:** Word Processor
  - Intermittent, CPU bursts
  - Interactive

*Result:* Task 2 accumulates little vruntime. When it wakes (user input), it gets run immediately.

#### nice(1) Command
- "nice" can be thought of as a 'soft' priority
- Changing a program's nice value changes the weighting for CFS
- Lower nice = more CPU time

*Example:* `nice -n 5 <program>` gives the process a lower priority (more CPU time).

---

## Multi-core CPUs and Scheduling

### Linux Implementation
- One red-black tree per core
- *Challenge:* How to fairly distribute tasks between cores?
- *Analogy:* Like choosing a queue at an airport or shopping center - you might pick the wrong queue with many people ahead of you.

*Note:* This is not covered in detail in this lecture, but it's an important consideration for multi-core systems.

---

## Summary of Scheduling Algorithms

| Algorithm | Description | Key Characteristics |
|-----------|-------------|---------------------|
| FCFS (First Come First Serve) | Processes executed in order they arrive | Simple, fair appearance, convoy effect |
| SJF (Shortest Job First) | Shortest job runs first | Reduces average turnaround time, requires knowing job length |
| STCF (Shortest Time to Completion First) | Preemptive SJF | Always runs the job that will finish soonest |
| RR (Round Robin) | Each process gets fixed time slice | Fairness, high overhead if quantum too small |
| MLFQ (Multi-level Feedback Queue) | Multiple priority queues with dynamic priority adjustment | Handles interactive and batch jobs well |
| CFS (Completely Fair Scheduler) | Uses vruntime to determine fairness | Used in Linux since 2007, no starvation |

---

## Key Takeaways

1. **Scheduling vs Dispatching**: 
   - Dispatcher: Mechanical (how to switch)
   - Scheduler: Conceptual (when to switch)

2. **Process States**:
   - Running → Ready → Blocked (I/O) → I/O Done → Scheduled

3. **Key Metrics**:
   - Turnaround Time = Completion time - Arrival time
   - Response Time = Start time - Arrival time
   - Wait Time = Time waiting when could be treated
   - Throughput = Number of completed jobs
   - Resource Utilization = Keep CPU busy
   - Fairness = Even treatment

4. **FCFS**:
   - Simple but can lead to convoy effect (long tasks starving short ones)

5. **SJF/STCF**:
   - Shortest job first reduces average turnaround time
   - STCF is preemptive version of SJF

6. **RR**:
   - Fairness at the cost of higher context switching overhead

7. **MLFQ**:
   - Handles interactive and batch jobs well
   - Uses dynamic priority adjustment
   - "Evil" strategy: Run just under allotment time before sleeping

8. **CFS**:
   - Uses vruntime to determine fairness
   - No starvation, works with Red/Black trees
   - Linux uses it since 2007

9. **Multi-core Consideration**:
   - One red-black tree per core in Linux
   - Task distribution between cores is a challenge

---

## Study Questions

1. What is the difference between scheduling and dispatching?
2. Explain the convoy effect with an example.
3. Calculate turnaround time and response time for FCFS with jobs A(0,5), B(0,5), C(0,5).
4. How does STCF differ from SJF?
5. Why might a process want to use the "evil" strategy in MLFQ?
6. What is vruntime in CFS and how does it work?
7. Explain why resource utilization is important in scheduling.
8. Describe the difference between preemptive and non-preemptive scheduling.
9. How does the Completely Fair Scheduler (CFS) prevent starvation?
10. Why might a process with a low nice value get more CPU time?
