<!-- 
Generated by LectureQ
Date: 2025-08-09 19:17:00
Model: qwen3:30b
-->

<think>
I need to create comprehensive lecture notes for a student who missed Week 2, Lecture 2 on Operating Systems Scheduling. I'll follow all the requirements and formatting instructions provided.

Let me break down what I need to include:

1. **Title**: Must include week and lecture information
2. **Overview**: A comprehensive paragraph describing the lecture
3. **Hierarchical headers** organized logically
4. **All content** from both slides and transcript
5. **Professional academic formatting** throughout
6. **Detailed tables, diagrams, and examples**
7. **Summary** with key takeaways
8. **Study questions** (10+)

Let me analyze the content I need to cover:

From the slides:
- Operating Systems Scheduling
- Last week's topic: Virtualisation
- Scheduler Summary: FCFS, SJF, STCF, RR, MLFQ
- Scheduling vs Dispatching
- Scheduling and States (Running, Ready, Blocked)
- Definitions: Workload, Job, Process, Scheduler, Metric
- Good vs Bad Scheduling (with hospital analogy)
- Metrics: Turnaround Time, Response Time, Wait Time, Throughput, Resource Utilisation, Overhead, Fairness
- Gantt Charts and Tables for scheduling examples
- Scheduling Assumptions
- FCFS, SJF, STCF, RR algorithms with examples
- I/O Blocking
- MLFQ (Multi-level Feedback Queue)
- Priority (Fixed vs Dynamic)
- Lottery Scheduling
- Completely Fair Scheduler (CFS)
- Multi-core CPUs

From the transcript:
- Instructor's explanations, analogies, and emphasis points
- Real-world examples (hospital analogy, university assignments)
- Student interactions and questions
- Instructor's clarifications and additional details

Now I'll create the notes following the detailed formatting instructions.

I'll start with the title, then overview, then organize the content into logical sections with appropriate headers.

Let me structure this:

# Operating Systems: Scheduling (Week 2, Lecture 2)

## Overview
[Comprehensive paragraph describing what this lecture covers, main topics, and learning objectives]

---

## Scheduling Fundamentals

### Last Week's Topic: Virtualisation
- Each process thinks it has its own computer
- Direct execution is faster
- Limited execution at key points to ensure OS control
- Hardware provides a lot of OS functionality
- User vs Kernel mode
- Clock functionality
- Register saving

### Scheduling Overview
- **Scheduling**: Determining which process to dispatch (Conceptual "When")
- **Dispatcher**: Determines how to switch between processes (Mechanical "How")
  - User mode/kernel mode transitions
  - Saving PCBs (Process Control Blocks)
- **Scheduling vs Dispatching**:
  - Scheduler: Determines which process to dispatch (Conceptual)
  - Dispatcher: Determines how to switch between processes (Mechanical)

### Scheduling States
Processes exist in three possible states:
- **Running**: The operating system thinks the process is doing work
- **Ready**: The process wants to do work but isn't currently running
- **Blocked**: The process can't do anything (typically waiting for I/O)

*Example*: 
- A process waiting for user input is blocked
- When the input is received, it transitions to ready
- The scheduler may choose to run it or not

### Key Definitions
- **Workload**: The 'jobs' that need to be done
- **Job**: View as current CPU burst of a process
  - Processes alternate between CPU & I/O
  - Processes move between ready and blocked queues
- **Scheduler**: Logic for the job choice
- **Metric**: Something to determine good from bad

*Instructor Insight*: "If you don't know what metric means at this point in your university careers, I feel very bad for you. It means to determine if something is good or bad."

### Good Scheduling vs Bad Scheduling
*Activity*: Imagine running a hospital with an operating room (OR) and patients needing surgery.

**Metrics for Good Scheduling**:
- **Turnaround Time**: Time between arrival and finish
  - *Example*: Patient arrives at 9am, surgery finishes at 12pm → Turnaround time = 3 hours
- **Response Time**: Time between arrival and start of treatment
  - *Example*: Patient arrives at 9am, surgery starts at 9:30am → Response time = 30 minutes
- **Wait Time**: Time waiting when could have been treated
  - *Example*: Patient arrives at 9am, surgery starts at 9:30am, but was waiting for 2 hours → Wait time = 2 hours
- **Throughput**: Number of happy patients (non-dead) processed per unit time
- **Resource Utilisation**: Operating room should be busy as much as possible
- **Overhead (Switches)**: Minimise context switches (e.g., switching patients)
- **Fairness**: Even treatment distribution among patients

*Instructor Insight*: "The good is the left where it's kind of even nominally and the right is bad where green is dominating and blues getting not much treatment."

---

## Scheduling Algorithms

### Gantt Charts
A visual representation of scheduling:
```
Time: 0    5    10    15
Task: Task1 Task2 Task3
```

*Instructor Insight*: "Gantt chart is your life once you have a job, right, or at least that's what your manager will think your life is."

### Scheduling Assumptions
1. Jobs run for a fixed time
2. All jobs arrive simultaneously
3. All jobs are CPU-only
4. Run-time of each job is known

*Instructor Insight*: "These are some, none of these are true, right, like as in like in a real scheduling system, but when we're building algorithms we can start with like an easy example and then work out what's wrong with it and then expand on it."

### First Come, First Serve (FCFS)
- Simplest scheduling algorithm
- Processes run in the order they arrive
- *Advantages*: Very simple to implement; has a 'veneer' of fairness
- *Problems*: Dependent on job order; big tasks can 'starve' small tasks (Convoy Effect)

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 5          | 5               |
| B   | 0            | 5          | 10              |
| C   | 0            | 5          | 15              |

Average Turnaround Time = (5 + 10 + 15) / 3 = 10

*Instructor Insight*: "If you've got a tutorial, I'll do it now, and then I'll wait and do the big job later. This is what most people sort of do."

*Convoy Effect*:
```
Big Task
Big Task
The Convoy
```

*Instructor Insight*: "You have this one task that's gonna take forever to do anything, and all these little tasks that are really quick and speedy, who are just sitting and waiting for the long task to complete."

### Shortest Job First (SJF)
- Schedule the shortest job first
- Minimizes average turnaround time
- *Problem*: If jobs don't arrive simultaneously, it may not be optimal

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 20         | 20              |
| B   | 0            | 4          | 24              |
| C   | 0            | 4          | 28              |

Average Turnaround Time = (20 + 24 + 28) / 3 = 24

*Alternative Example*:
| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 4          | 4               |
| B   | 0            | 4          | 8               |
| C   | 0            | 20         | 28              |

Average Turnaround Time = (4 + 8 + 28) / 3 = 16.6

*Instructor Insight*: "Shortest job first is the solution to all our problems. Nothing will ever go wrong."

### Shortest Time to Completion First (STCF)
- Preemptive version of SJF
- Always run the process with the shortest remaining time
- *Metrics*: Turnaround Time = completion_time - arrival_time; Response Time = start_time - arrival_time

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time | Response Time |
|-----|--------------|------------|-----------------|---------------|
| A   | 0            | 10         | 10              | 0             |
| B   | 2            | 10         | 18              | 8             |
| C   | 4            | 10         | 26              | 16            |

Average Response Time = (0 + 8 + 16) / 3 = 8

*Instructor Insight*: "Shortest time to completion first is, Earliest deadline first, which is what we call it in real-time systems."

### Round Robin (RR)
- Each process gets a fixed time slice (quantum)
- After the quantum expires, the process is preempted
- *Metrics*: Turnaround Time = completion_time - arrival_time; Response Time = start_time - arrival_time

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time | Response Time |
|-----|--------------|------------|-----------------|---------------|
| A   | 0            | 10         | 26              | 0             |
| B   | 2            | 10         | 26              | 0             |
| C   | 4            | 10         | 26              | 0             |

Average Response Time = (0 + 0 + 0) / 3 = 0

*Instructor Insight*: "The main thing with round robin, I think from a conceptual level is like how long, how often do you switch."

### I/O Blocking
- Processes can be interrupted for I/O operations
- *Key Insight*: "Don't waste CPU" - if a process is waiting for I/O, run another process

*Example*:
```
Time: 0    2    4    6    8   10
Task: CPU  I/O  CPU  I/O  CPU  I/O
```

*Instructor Insight*: "If a process is interruptible like this, where it has a lot of little interruptions, it generally means that it doesn't do very much."

---

## Advanced Scheduling

### Multi-Level Feedback Queue (MLFQ)
- **Situation**:
  - Jobs can be of varying length
  - Jobs can arrive at any time
  - We don't know when they will finish
  - Different jobs have different aims:
    - Interactive Jobs: Response Time
    - Batch Jobs: Turnaround Time

### Priority Scheduling
- **Fixed Priority**:
  - Higher priority jobs run first
  - *Problem*: Long jobs can starve short jobs
  - *Example*:
    ```
    Big Job
    Small Job
    Small Job Big Job Big Job
    ```

- **Dynamic Priority**:
  - If a job takes a lot of CPU (runs for too long), reduce its priority
  - If a job uses only a little CPU, keep its priority high
  - *Instructor Insight*: "If a job can only 'lose priority', won't it eventually get ignored?"

### MLFQ Rules
1. Run high priority jobs first (round robin for ties)
2. You start high priority
3. If you run for too long, your priority drops
4. Every so often, put jobs back into the top priority

*Instructor Insight*: "If you're a really big job, right, you, you run and then you're like, oh I've used my time, lower priority, I've used my time, uh lower priority, I've used my time. I want time, I want time, and then eventually it'll just reset."

### MLFQ Design Decisions
- How many queues?
- How long is an allotment?
- Are allotments the same for each queue level?
- How often to refresh priorities?

*Instructor Insight*: "How many cus? Who knows? Who, who knows, it depends on what you're running, right? Like as in like, but we have to make this kind of decision. The way that you make these decisions is you run it and you see, right, and you experiment because these tasks are so like stupidly complicated."

### Lottery Scheduling
- Processes get tickets based on priority
- Random ticket selection determines which process runs
- *Instructor Insight*: "It turns out it's actually not too bad. So basically the idea is you just, you just have a random number generator and you and you have tickets and you give processors tickets depending on how high a priority they need to be, and then you just like roll the dice..."

*Potential Issues*:
- Ticket trading
- Ticket inflation
- Ticket currencies

### Completely Fair Scheduler (CFS)
- **Premise**:
  - All tasks have their vruntime measured
  - Smallest vruntime tasks are run with priority
  - Each task runs for a bit over target latency period
  - Each task gets a share depending on its weight (no starvation)
  - Works using a Red/Black tree (used in Linux since 2007)

*Instructor Insight*: "This is where we have to say if you use a full allotment, not your full allotment, just a full allotment, so we need to start counting allotments..."

*Example*:
- Task 1: Video Rendering (Long run-time, CPU intensive, non-interactive)
- Task 2: Word Processor (Interactive, intermittent CPU bursts)

*How CFS Works*:
- Task 2 accumulates little vruntime
- When it wakes (user input), it gets run immediately

*Instructor Insight*: "The 'nice' can be thought of as a 'soft' priority. Changing a program's nice value changes the weighting for CFS."

### Multi-core CPUs
- Linux: One red-black tree per core
- *Challenge*: Fairly distribute tasks between cores
- *Instructor Insight*: "It's like, oh, I put you, you know, you know, who who's done this at like a shopping centre or like when you're waiting at the airport or something like that, and you're like, there are like 6 queues and you're like, I shall pick the queue. And then there's like someone who has a complaint with the manager in front of you on the line and you're just there going, right, I picked the wrong queue."

---

## Summary / Key Takeaways

1. **Scheduling Fundamentals**: Scheduling determines *when* to run processes (conceptual), while dispatching determines *how* to switch between them (mechanical).
2. **Key Metrics**: Turnaround Time (completion - arrival), Response Time (start - arrival), Wait Time, Throughput, Resource Utilisation, Overhead, Fairness.
3. **FCFS**: Simple but can lead to convoy effect where long jobs starve short jobs.
4. **SJF**: Minimizes average turnaround time but requires knowing job lengths in advance.
5. **STCF**: Preemptive SJF that minimizes response time for interactive processes.
6. **RR**: Fair scheduling with fixed time quantum, but can have high overhead if quantum is too small.
7. **MLFQ**: Advanced scheduling that dynamically adjusts priority based on CPU usage.
8. **CFS**: Completely Fair Scheduler used in Linux since 2007, using vruntime and Red/Black trees.
9. **Priority Scheduling**: Fixed priority can lead to starvation; dynamic priority adjusts based on usage.
10. **I/O Blocking**: Critical for efficient scheduling - don't waste CPU when processes are waiting for I/O.

---

## Study Questions

1. Explain the difference between scheduling and dispatching, including their roles in process management.

2. Describe the convoy effect with an example of how it impacts scheduling performance.

3. Calculate the average turnaround time for a set of processes using FCFS scheduling, given their arrival times and burst times.

4. How does Shortest Time to Completion First (STCF) differ from Shortest Job First (SJF)? Provide an example where STCF outperforms SJF.

5. What is the main disadvantage of Round Robin (RR) scheduling when the time quantum is too small? How does this relate to overhead?

6. Explain how I/O blocking affects process scheduling and why it's important to consider in scheduling algorithms.

7. Describe the rules of Multi-Level Feedback Queue (MLFQ) scheduling, including how priority changes over time.

8. What is the purpose of the "nice" value in Linux scheduling? How does it affect a process's priority?

9. How does the Completely Fair Scheduler (CFS) use vruntime to determine which process should run next?

10. Explain why dynamic priority adjustment is necessary in scheduling systems, and describe how it prevents starvation.

11. Describe the Red-Black tree structure and explain why it's used in the Completely Fair Scheduler.

12. What are the main challenges in scheduling processes on multi-core CPUs, and how might these be addressed?

13. Compare and contrast FCFS, SJF, STCF, and RR scheduling algorithms in terms of their suitability for different types of workloads (interactive vs batch).

14. Explain the concept of "allotment" in MLFQ scheduling and why it's important to track how much of an allotment a process has used.

15. How does the Completely Fair Scheduler ensure that no process starves, even if it's a long-running batch job?

16. Describe the lottery scheduling algorithm and explain how it could be implemented with ticket trading.

17. What is the significance of the "target latency" in the Completely Fair Scheduler?

18. Explain the difference between a preemptive and non-preemptive scheduling algorithm, and provide an example of each.

19. How does the priority of a process change in a dynamic priority scheduling system when it has been running for a long time?

20. Describe the main components of a Process Control Block (PCB) and explain how it's used during context switching.
</think>

# Operating Systems: Scheduling (Week 2, Lecture 2)

## Overview
This lecture covers the fundamental concepts of process scheduling in operating systems, including scheduling algorithms, key metrics for evaluating scheduling performance, and advanced scheduling techniques. The lecture begins with a review of last week's topic on virtualization before diving into scheduling fundamentals. Key topics include the distinction between scheduling and dispatching, process states (running, ready, blocked), scheduling metrics (turnaround time, response time, throughput), and various scheduling algorithms including First Come First Serve (FCFS), Shortest Job First (SJF), Shortest Time to Completion First (STCF), Round Robin (RR), and Multi-Level Feedback Queue (MLFQ). The lecture also explores dynamic priority scheduling, lottery scheduling, and the Completely Fair Scheduler (CFS) used in Linux, with practical examples and real-world analogies to illustrate concepts.

---

## Scheduling Fundamentals

### Scheduling vs Dispatching
- **Scheduler**: Determines *which process to dispatch* (Conceptual "When")
  - *Instructor Insight*: "Scheduler: Determines which process to dispatch. Conceptual (When)"
  
- **Dispatcher**: Determines *how to switch* between processes (Mechanical "How")
  - *Instructor Insight*: "Dispatcher: Determines how to switch between processes. User mode/kernel mode. Saving PCBs... Mechanical (How)"

*Key Distinction*: 
- **Scheduling** is the *conceptual decision* of which process to run next
- **Dispatching** is the *mechanical implementation* of switching to that process

### Process States
Processes exist in three possible states:
- **Running**: The operating system thinks the process is doing work
- **Ready**: The process wants to do work but isn't currently running
- **Blocked**: The process can't do anything (typically waiting for I/O)

*Instructor Insight*: "Locked is pretty easy to understand. It basically means that like you want to use IO in some way, so you're like, I would like to use the printer as a process, and now I can't use the printer, so I'm just standing there waiting, waiting."

*State Transitions*:
```
Running → Blocked (I/O request)
Blocked → Ready (I/O completed)
Ready → Running (Scheduler selects process)
```

### Key Definitions
- **Workload**: The 'jobs' that need to be done
- **Job**: View as current CPU burst of a process
  - *Instructor Insight*: "A job is like I have a job, it's some run processy bit for a bit, and that's kind of what a job is"
  
- **Process**: Alternates between CPU & I/O
  - *Instructor Insight*: "Process sometimes alternates between CPU & I/O. Process moves between ready and blocked queues"

- **Scheduler**: Logic for the job choice
  - *Instructor Insight*: "Scheduler: Logic for the job choice"

- **Metric**: Something to determine good from bad
  - *Instructor Insight*: "If you don't know what metric means at this point in your university careers, I feel very bad for you. It means to determine if something is good or bad."

---

## Scheduling Metrics

### Hospital Analogy Activity
*Instructor Activity*: "Imagine you are running a hospital and you have an operating room (for surgery). You have a list of patients who need various operations... How do we determine the best way to use the operating room? What things do we want to maximise or minimise?"

### Key Metrics for Scheduling
| Metric | Description | Formula |
|--------|-------------|---------|
| **Turnaround Time** | Time between arrival and finish | Completion time - Arrival time |
| **Response Time** | Time between arrival and start of treatment | Start time - Arrival time |
| **Wait Time** | Time waiting when could have been treated | (Start time - Arrival time) - (Time spent processing) |
| **Throughput** | Number of happy patients processed per unit time | Total patients processed / Total time |
| **Resource Utilisation** | Operating room should be busy as much as possible | (Time operating room is busy) / (Total time) |
| **Overhead (Switches)** | Cost of switching between processes | Number of context switches |
| **Fairness** | Even treatment distribution among patients | Equal treatment over time |

*Instructor Insight*: "The good is the left where it's kind of even nominally and the right is bad where green is dominating and blues getting not much treatment."

---

## Scheduling Algorithms

### Gantt Charts
A visual representation of scheduling:
```
Time: 0    5    10    15
Task: Task1 Task2 Task3
```

*Instructor Insight*: "Gantt chart is your life once you have a job, right, or at least that's what your manager will think your life is."

### Scheduling Assumptions
1. Jobs run for a fixed time
2. All jobs arrive simultaneously
3. All jobs are CPU-only
4. Run-time of each job is known

*Instructor Insight*: "These are some, none of these are true, right, like as in like in a real scheduling system, but when we're building algorithms we can start with like an easy example and then work out what's wrong with it and then expand on it."

---

### First Come, First Serve (FCFS)
- Simplest scheduling algorithm
- Processes run in the order they arrive
- *Advantages*: Very simple to implement; has a 'veneer' of fairness
- *Problems*: Dependent on job order; big tasks can 'starve' small tasks (Convoy Effect)

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 5          | 5               |
| B   | 0            | 5          | 10              |
| C   | 0            | 5          | 15              |

Average Turnaround Time = (5 + 10 + 15) / 3 = 10

*Alternative Example*:
| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 20         | 20              |
| B   | 0            | 4          | 24              |
| C   | 0            | 4          | 28              |

Average Turnaround Time = (20 + 24 + 28) / 3 = 24

*Convoy Effect*:
```
Big Task
Big Task
The Convoy
```

*Instructor Insight*: "You have this one task that's gonna take forever to do anything, and all these little tasks that are really quick and speedy, who are just sitting and waiting for the long task to complete."

---

### Shortest Job First (SJF)
- Schedule the shortest job first
- Minimizes average turnaround time
- *Problem*: If jobs don't arrive simultaneously, it may not be optimal

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 20         | 20              |
| B   | 0            | 4          | 24              |
| C   | 0            | 4          | 28              |

Average Turnaround Time = (20 + 24 + 28) / 3 = 24

*Alternative Example*:
| Job | Arrival Time | Burst Time | Turnaround Time |
|-----|--------------|------------|-----------------|
| A   | 0            | 4          | 4               |
| B   | 0            | 4          | 8               |
| C   | 0            | 20         | 28              |

Average Turnaround Time = (4 + 8 + 28) / 3 = 16.6

*Instructor Insight*: "Shortest job first is the solution to all our problems. Nothing will ever go wrong."

---

### Shortest Time to Completion First (STCF)
- Preemptive version of SJF
- Always run the process with the shortest remaining time
- *Metrics*: Turnaround Time = completion_time - arrival_time; Response Time = start_time - arrival_time

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time | Response Time |
|-----|--------------|------------|-----------------|---------------|
| A   | 0            | 10         | 10              | 0             |
| B   | 2            | 10         | 18              | 8             |
| C   | 4            | 10         | 26              | 16            |

Average Response Time = (0 + 8 + 16) / 3 = 8

*Instructor Insight*: "Shortest time to completion first is, Earliest deadline first, which is what we call it in real-time systems."

---

### Round Robin (RR)
- Each process gets a fixed time slice (quantum)
- After the quantum expires, the process is preempted
- *Metrics*: Turnaround Time = completion_time - arrival_time; Response Time = start_time - arrival_time

*Example Calculation*:
| Job | Arrival Time | Burst Time | Turnaround Time | Response Time |
|-----|--------------|------------|-----------------|---------------|
| A   | 0            | 10         | 26              | 0             |
| B   | 2            | 10         | 26              | 0             |
| C   | 4            | 10         | 26              | 0             |

Average Response Time = (0 + 0 + 0) / 3 = 0

*Instructor Insight*: "The main thing with round robin, I think from a conceptual level is like how long, how often do you switch, right? Because if you switch a lot from an operating system point of view, you know, you're gonna grab stuff and get into memory and then run across and be able to put it back in memory, right, you don't want to do that too often."

---

### I/O Blocking
- Processes can be interrupted for I/O operations
- *Key Insight*: "Don't waste CPU" - if a process is waiting for I/O, run another process

*Example*:
```
Time: 0    2    4    6    8   10
Task: CPU  I/O  CPU  I/O  CPU  I/O
```

*Instructor Insight*: "If a process is interruptible like this, where it has a lot of little interruptions, it generally means that it doesn't do very much. So when you press something on the keyboard, it's not a very complicated process, right, you're just getting like a signal."

---

## Advanced Scheduling

### Multi-Level Feedback Queue (MLFQ)
- **Situation**:
  - Jobs can be of varying length
  - Jobs can arrive at any time
  - We don't know when they will finish
  - Different jobs have different aims:
    - Interactive Jobs: Response Time
    - Batch Jobs: Turnaround Time

*Instructor Insight*: "Interactive job, using the keyboard, you want response time. So when, like when you're using a computer, if you click on something and nothing happens for 3 seconds, do you get pissed off? The answer is yes. But if you run like a big long programme and it runs for 10 hours, you don't care."

---

### Priority Scheduling
- **Fixed Priority**:
  - Higher priority jobs run first
  - *Problem*: Long jobs can starve short jobs
  - *Example*:
    ```
    Big Job
    Small Job
    Small Job Big Job Big Job
    ```

- **Dynamic Priority**:
  - If a job takes a lot of CPU (runs for too long), reduce its priority
  - If a job uses only a little CPU, keep its priority high
  - *Instructor Insight*: "If a job can only 'lose priority', won't it eventually get ignored?"

*Malicious Strategy Question*: "Under this system, how can we be evil?"

*Instructor Insight*: "How would you design your system if you were a process to make sure that you're always in the high priority queue? ... The correct answer is: you work out how long you're allowed to run on the operating system before it demotes your priority, and you sleep one microsecond before that happens."

---

### MLFQ Rules
1. Run high priority jobs first (round robin for ties)
2. You start high priority
3. If you run for too long, your priority drops
4. Every so often, put jobs back into the top priority

*Instructor Insight*: "If you're a really big job, right, you, you run and then you're like, oh I've used my time, lower priority, I've used my time, uh lower priority, I've used my time. I want time, I want time, and then eventually it'll just reset."

*Instructor Insight*: "You can't wait forever under this system. It's the glory that is the multi-level feedback queue."

---

### MLFQ Design Decisions
- How many queues?
- How long is an allotment?
- Are allotments the same for each queue level?
- How often to refresh priorities?

*Instructor Insight*: "How many cus? Who knows? Who, who knows, it depends on what you're running, right? Like as in like, but we have to make this kind of decision. The way that you make these decisions is you run it and you see, right, and you experiment because these tasks are so like stupidly complicated."

---

### Lottery Scheduling
- Processes get tickets based on priority
- Random ticket selection determines which process runs
- *Instructor Insight*: "It turns out it's actually not too bad. So basically the idea is you just, you just have a random number generator and you and you have tickets and you give processors tickets depending on how high a priority they need to be, and then you just like roll the dice..."

*Potential Issues*:
- Ticket trading
- Ticket inflation
- Ticket currencies

---

### Completely Fair Scheduler (CFS)
- **Premise**:
  - All tasks have their vruntime measured
  - Smallest vruntime tasks are run with priority
  - Each task runs for a bit over target latency period
  - Each task gets a share depending on its weight (no starvation)
  - Works using a Red/Black tree (used in Linux since 2007)

*Instructor Insight*: "This is where we have to say if you use a full allotment, not your full allotment, just a full allotment, so we need to start counting allotments..."

*Example*:
- Task 1: Video Rendering (Long run-time, CPU intensive, non-interactive)
- Task 2: Word Processor (Interactive, intermittent CPU bursts)

*How CFS Works*:
```
Task 2 accumulates little vruntime. When it wakes (user input) it gets run immediately.
```

*Instructor Insight*: "The 'nice' can be thought of as a 'soft' priority. Changing a program's nice value changes the weighting for CFS."

---

### Multi-core CPUs
- Linux: One red-black tree per core
- *Challenge*: Fairly distribute tasks between cores
- *Instructor Insight*: "It's like, oh, I put you, you know, you know, who who's done this at like a shopping centre or like when you're waiting at the airport or something like that, and you're like, there are like 6 queues and you're like, I shall pick the queue. And then there's like someone who has a complaint with the manager in front of you on the line and you're just there going, right, I picked the wrong queue."

---

## Summary / Key Takeaways

1. **Scheduling Fundamentals**: Scheduling determines *when* to run processes (conceptual), while dispatching determines *how* to switch between them (mechanical).
2. **Key Metrics**: Turnaround Time (completion - arrival), Response Time (start - arrival), Wait Time, Throughput, Resource Utilisation, Overhead, and Fairness are critical for evaluating scheduling performance.
3. **FCFS**: Simple but can lead to convoy effect where long jobs starve short jobs.
4. **SJF**: Minimizes average turnaround time but requires knowing job lengths in advance.
5. **STCF**: Preemptive SJF that minimizes response time for interactive processes.
6. **RR**: Fair scheduling with fixed time quantum, but can have high overhead if quantum is too small.
7. **MLFQ**: Advanced scheduling that dynamically adjusts priority based on CPU usage to balance interactive and batch workloads.
8. **CFS**: Completely Fair Scheduler used in Linux since 2007, using vruntime and Red/Black trees to ensure fair CPU allocation.
9. **Priority Scheduling**: Fixed priority can lead to starvation; dynamic priority adjusts based on usage to prevent starvation.
10. **I/O Blocking**: Critical for efficient scheduling - don't waste CPU when processes are waiting for I/O.

---

## Study Questions

1. Explain the difference between scheduling and dispatching, including their roles in process management.

2. Describe the convoy effect with an example of how it impacts scheduling performance.

3. Calculate the average turnaround time for a set of processes using FCFS scheduling, given their arrival times and burst times.

4. How does Shortest Time to Completion First (STCF) differ from Shortest Job First (SJF)? Provide an example where STCF outperforms SJF.

5. What is the main disadvantage of Round Robin (RR) scheduling when the time quantum is too small? How does this relate to overhead?

6. Explain how I/O blocking affects process scheduling and why it's important to consider in scheduling algorithms.

7. Describe the rules of Multi-Level Feedback Queue (MLFQ) scheduling, including how priority changes over time.

8. What is the purpose of the "nice" value in Linux scheduling? How does it affect a process's priority?

9. How does the Completely Fair Scheduler (CFS) use vruntime to determine which process should run next?

10. Explain why dynamic priority adjustment is necessary in scheduling systems, and describe how it prevents starvation.

11. Describe the Red-Black tree structure and explain why it's used in the Completely Fair Scheduler.

12. What are the main challenges in scheduling processes on multi-core CPUs, and how might these be addressed?

13. Compare and contrast FCFS, SJF, STCF, and RR scheduling algorithms in terms of their suitability for different types of workloads (interactive vs batch).

14. Explain the concept of "allotment" in MLFQ scheduling and why it's important to track how much of an allotment a process has used.

15. How does the Completely Fair Scheduler ensure that no process starves, even if it's a long-running batch job?

16. Describe the lottery scheduling algorithm and explain how it could be implemented with ticket trading.

17. What is the significance of the "target latency" in the Completely Fair Scheduler?

18. Explain the difference between a preemptive and non-preemptive scheduling algorithm, and provide an example of each.

19. How does the priority of a process change in a dynamic priority scheduling system when it has been running for a long time?

20. Describe the main components of a Process Control Block (PCB) and explain how it's used during context switching.