<!-- 
Generated by LectureQ
Date: 2025-08-09 20:09:55
Model: qwen3:30b
-->

<think>
We are creating exhaustive study notes from the provided textbook chapter slides.
 The chapter is titled "The Abstraction: Address Spaces" (Week 2: Textbook Vm Intro).
 We must include EVERY detail without summarizing.

 Steps:
 1. Start with the chapter title and note that it's from Week 2.
 2. Extract all concepts, definitions, examples, explanations, figures, references, homework, etc.
 3. Organize by the slide structure (Slide 1 to Slide 9) but in a logical flow for study notes.
 4. Use markdown with clear headers, bullet points, code blocks, etc.

 Important: Do not skip any detail. The student must be able to learn everything from these notes.

 Let's break down each slide and extract every piece of information.

 Slide 1:
   - Title: "The Abstraction: Address Spaces"
   - Content: 
        * Early days of computer systems: users didn't expect much, so building systems was easy.
        * The text says: "users with their expectations of 'ease of use', 'high performance', 'reliability', etc., that really have led to all these headaches."
        * Then a humorous note: "Next time you meet one of those computer users, thank them for all the problems they have caused."

   - Section 13.1 Early Systems:
        * From memory perspective, early machines didn't provide much abstraction.
        * Physical memory looked like Figure 13.1 (page 2) [but note: we don't have the figure, so we describe as per text].
        * OS was a set of routines (a library) sitting in memory starting at physical address 0.
        * One running program (process) sat in physical memory starting at physical address 64k.
        * The user didn't expect much from the OS.

 Slide 2:
   - Section 13.2 Multiprogramming and Time Sharing:
        * Multiprogramming: multiple processes ready to run at a given time, OS switches between them (e.g., when one does I/O).
        * Increased CPU utilization.
        * Machines were expensive (hundreds of thousands or millions of dollars).
        * Time sharing: era of time sharing (cited: [S59, L60, M62, M83]).
        * Limitations of batch computing: programmers tired of long program-debug cycles.
        * Interactivity became important: many users concurrently using a machine, each waiting for timely response.
        * Crude time sharing approach: run one process for a short while, give it full access to all memory (Figure 13.1), then stop, save state to disk (including entire memory), load another, run, etc.
        * Problem: saving and restoring entire memory to disk is too slow (especially as memory grows).
        * Better approach: leave processes in memory while switching (Figure 13.2, page 3).
        * Figure 13.2: Three processes (A, B, C) sharing 512KB physical memory (each has a small part).
        * OS runs one process (e.g., A) while others (B, C) wait in ready queue.
        * New demand: protection (prevent one process from reading/writing another's memory).

 Slide 3:
   - Section 13.3 The Address Space:
        * Abstraction: address space (the running program's view of memory).
        * Address space contains all memory state of the running program.
        * Components:
            - Code: instructions (static, placed at top of address space).
            - Stack: for local variables, function call chain, parameters, return values (grows upward).
            - Heap: for dynamically allocated memory (e.g., malloc in C, new in Java/C++), grows downward.
        * Figure 13.3 (page 4): tiny address space (16KB) example.
            - Code at top (starting at 0, packed into first 1K).
            - Heap starts just after code (at 1KB) and grows downward.
            - Stack starts at 16KB and grows upward.
        * Note: placement of stack and heap is a convention; could be arranged differently (e.g., multiple threads).
        * The program isn't in memory at physical addresses 0-16KB; it's loaded at arbitrary physical address(es).
        * Example: processes A, B, C in Figure 13.2 are loaded at different physical addresses.

   - The Crux: How to virtualize memory? (Key question)
        * Problem: How can the OS build a private, potentially large address space for multiple running processes (all sharing memory) on top of a single physical memory?
        * Virtualization: the program thinks it's loaded at a particular address (e.g., 0) and has a large address space (e.g., 32-bit or 64-bit), but reality is different.
        * Example: Process A in Figure 13.2 tries to load at virtual address 0 -> must be mapped to physical address 320KB.

 Slide 4:
   - Section 13.4 Goals of Virtual Memory (VM):
        * Goal 1: Transparency - OS implements VM invisibly to the program. Program behaves as if it has private physical memory.
        * Goal 2: Efficiency - VM should be efficient in time (not slow down programs) and space (not use too much memory for support structures). Hardware support (e.g., TLBs) is critical.
        * Goal 3: Protection - Protect processes from each other and the OS from processes. When a process does load/store, it shouldn't access other process's memory or OS memory.

   - Tip: The Principle of Isolation
        * Isolation: key principle for reliable systems. If two entities are isolated, one can fail without affecting the other.
        * OS isolates processes to prevent harm from faulty/malicious processes.
        * Microkernels (e.g., [BH70, R+89, S+03]) take isolation further by walling off pieces of the OS.

 Slide 5:
   - Section 13.5 Summary:
        * VM system provides illusion of large, sparse, private address space to each program.
        * Each virtual address space contains program's instructions and data (referenced via virtual addresses).
        * OS (with hardware help) turns virtual memory references into physical addresses.
        * OS provides service for many processes, protecting programs from each other and the OS.
        * Requires mechanism (low-level machinery) and policies (e.g., managing free space, which pages to evict).

 Slide 6:
   - Aside: Every Address You See Is Virtual
        * When you print a pointer in C, it's a virtual address.
        * Example program (va.c) that prints:
            - location of main() (code)
            - location of heap (malloc)
            - location of stack (integer variable)
        * Output example (on 64-bit Mac):
            location of code: 0x1095afe50
            location of heap: 0x1096008c0
            location of stack: 0x7fff691aea64
        * Explanation: code comes first, then heap, then stack at the other end.

 Slide 7:
   - References (cited in the text):
        [BH70]: Brinch Hansen, "The Nucleus of a Multiprogramming System", 1970.
        [CV65]: Corbato and Vyssotsky, "Introduction and Overview of the Multics System", 1965.
        [DV66]: Dennis and Van Horn, "Programming Semantics for Multiprogrammed Computations", 1966.
        [L60]: Licklider, "Man-Computer Symbiosis", 1960.
        [M62]: McCarthy, "Time-Sharing Computer Systems", 1962.
        [M+63]: McCarthy et al., "A Time-Sharing Debugging System for a Small Computer", 1963.
        [M83]: McCarthy, "Reminiscences on the History of Time Sharing", 1983.
        [NS07]: Nethercote and Seward, "Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation", 2007.
        [R+89]: Rashid et al., "Mach: A System Software kernel", 1989.
        [S59]: Strachey, "Time Sharing in Large Fast Computers", 1959.
        [S+03]: Swift et al., "Improving the Reliability of Commodity Operating Systems", 2003.

 Slide 8:
   - Homework (Code):
        Questions:
        1. Learn about `free` tool: `man free`.
        2. Run `free` (with `-m` for megabytes) and note memory totals and free memory.
        3. Create a program `memory-user.c` that takes a command-line argument (MB to use), allocates an array, and touches each entry indefinitely (or for a time).
        4. While running `memory-user`, run `free` in another terminal. Observe changes in memory usage when the program runs and when killed. Try different memory amounts.
        5. Learn about `pmap`: read `man pmap`.
        6. Use `ps auxw` to find a process (e.g., browser) and then run `pmap` on it (with flags like `-X`).
        7. Observe what `pmap` shows: how many entities make up a modern address space (vs. simple code/stack/heap).
        8. Run `pmap` on `memory-user` with different memory amounts and see if output matches expectations.

 Now, we structure the notes accordingly.

 Important: We are to write exhaustive notes, so we'll include every detail from the slides.

 We'll structure the notes as:

 # Chapter Title
 ## Learning Objectives (if any) - but note: the slides don't have explicit learning objectives, so we skip or note that they are not provided.

 Then, we break down by the sections in the slides.

 Since the slides are numbered, we'll follow the slide order but group by section.

 We'll create headers for each section (13.1, 13.2, etc.) and include all the details.

 Let's write the notes.
</think>

# Week 2: The Abstraction: Address Spaces

## Chapter Overview
This chapter introduces the fundamental concept of **address spaces** as a core abstraction in operating systems. It traces the historical evolution of memory management from early systems to modern virtual memory systems, emphasizing the goals of transparency, efficiency, and protection. The chapter provides exhaustive details on the structure of address spaces, the challenges of memory virtualization, and the principles underlying modern virtual memory systems.

---

## 13.1 Early Systems

### Memory Abstraction in Early Machines
- **Minimal abstraction**: Early machines provided little memory abstraction to users.
- **Physical memory layout** (Figure 13.1):
  - Operating System (OS) resided in memory starting at physical address **0**.
  - A single running program (process) occupied memory starting at physical address **64KB**.
  - The OS was essentially a library of routines (not a full-fledged system).
- **User expectations**: Users had low expectations ("life was easy for OS developers").
- **Humorous note**:  
  > *"Because users didn’t expect much. It is those darned users with their expectations of 'ease of use', 'high performance', 'reliability', etc., that really have led to all these headaches. Next time you meet one of those computer users, thank them for all the problems they have caused."*

---

## 13.2 Multiprogramming and Time Sharing

### Evolution from Batch Processing
- **Multiprogramming** ([DV66]):
  - Multiple processes ready to run simultaneously.
  - OS switched between processes (e.g., when one performed I/O).
  - **Goal**: Increase CPU utilization (critical when machines cost hundreds of thousands/millions of dollars).
- **Time Sharing** ([S59, L60, M62, M83]):
  - Emerged due to limitations of batch computing.
  - **Key motivation**: Programmers tired of long program-debug cycles in batch environments ([CV65]).
  - **Quote from CV65**:  
    > *"The impetus for time-sharing first arose from professional programmers because of their constant frustration in debugging programs at batch processing installations. Thus, the original goal was to time-share computers to allow simultaneous access by several persons while giving to each of them the illusion of having the whole machine at his disposal."*
  - **Interactivity**: Users demanded timely responses from concurrently executing tasks.

### Crude Time-Sharing Implementation (Problematic)
- **Approach**: 
  1. Run one process for a short time (full memory access).
  2. Stop process, save entire state to disk (including all physical memory).
  3. Load another process’s state, run it.
- **Critical flaw**: 
  > *"Saving and restoring register-level state (the PC, general-purpose registers, etc.) is relatively fast, but saving the entire contents of memory to disk is brutally non-performant."*
  - **Consequence**: Slow performance as memory size increased.

### Efficient Time-Sharing Solution (Figure 13.2)
- **Approach**: 
  - Leave processes in physical memory during context switches.
  - OS manages concurrent processes without disk I/O for memory state.
- **Memory layout** (Figure 13.2, page 3):
  - Physical memory: **512KB** total.
  - Three processes (A, B, C) each allocated a segment of memory:
    - Process A: 64KB (physical addresses 0–64KB)
    - Process B: 64KB (physical addresses 64KB–128KB)
    - Process C: 64KB (physical addresses 128KB–192KB)
    - OS: 128KB (physical addresses 384KB–512KB)
  - **OS behavior**: 
    - Runs one process (e.g., A) on CPU.
    - Other processes (B, C) wait in ready queue.

### New Challenge: Protection
- **Requirement**: Prevent processes from accessing each other’s memory.
  > *"Allowing multiple programs to reside concurrently in memory makes protection an important issue; you don’t want a process to be able to read, or worse, write some other process’s memory."*

---

## 13.3 The Address Space

### Definition and Purpose
- **Address space**: The running program’s view of memory (abstraction provided by OS).
- **Contains all memory state** of the running program:
  - Code (instructions)
  - Stack (local variables, function calls, parameters, return values)
  - Heap (dynamically allocated memory via `malloc()`/`new`)
  - Statically-initialized variables (e.g., global variables)

### Address Space Structure (Figure 13.3, page 4)
- **Tiny example**: 16KB address space (simplified for clarity).
- **Layout**:
  | Segment      | Location in Address Space | Growth Direction | Purpose                                                                 |
  |--------------|---------------------------|------------------|-------------------------------------------------------------------------|
  | **Code**     | Top (0–1KB)               | Static (no growth) | Instructions (e.g., `main()`, functions)                                |
  | **Heap**     | After code (1KB–2KB)      | Downward         | Dynamically allocated memory (e.g., `malloc(100e6)` in C)               |
  | **Stack**    | Bottom (15KB–16KB)        | Upward           | Local variables, function call chain, parameters, return values          |

- **Growth convention**:
  - Heap grows **downward** (toward lower addresses) when `malloc()` is called.
  - Stack grows **upward** (toward higher addresses) during function calls.
  - **Reason**: Allows both to grow without overlapping (opposite directions).
- **Note**: This layout is a convention; alternative arrangements exist (e.g., for multi-threaded programs).

### Virtual vs. Physical Memory
- **Program’s illusion**: 
  > *"The program really isn’t in memory at physical addresses 0 through 16KB; rather it is loaded at some arbitrary physical address(es)."*
- **Example** (Figure 13.2):
  - Process A: Loaded at physical address **320KB**.
  - Process B: Loaded at physical address **192KB**.
  - Process C: Loaded at physical address **64KB**.

---

## The Crux: How to Virtualize Memory

### Core Problem Statement
> *"How can the OS build this abstraction of a private, potentially large address space for multiple running processes (all sharing memory) on top of a single, physical memory?"*

### Virtualization Mechanism
- **Virtual address**: Address used by the program (e.g., `0` in Process A).
- **Physical address**: Actual location in hardware memory (e.g., `320KB` for Process A).
- **OS/hardware role**: 
  > *"When process A tries to perform a load at address 0 (virtual address), the OS, in tandem with hardware support, must ensure the load doesn’t go to physical address 0 but rather to physical address 320KB."*
- **Key insight**: Virtual memory is the foundation of all modern computer systems.

---

## 13.4 Goals of Virtual Memory (VM)

### Goal 1: Transparency
- **Definition**: VM implementation must be invisible to the running program.
- **Requirement**: 
  > *"The program shouldn’t be aware that memory is virtualized; rather, the program behaves as if it has its own private physical memory."*
- **OS role**: Multiplex memory among multiple processes without user awareness.

### Goal 2: Efficiency
- **Two dimensions**:
  1. **Time efficiency**: Programs should not run significantly slower due to VM.
  2. **Space efficiency**: Minimal memory overhead for VM structures.
- **Hardware dependency**: 
  > *"The OS will have to rely on hardware support, including hardware features such as TLBs (which we will learn about in due course)."*

### Goal 3: Protection
- **Definition**: Prevent processes from accessing each other’s memory or the OS.
- **Requirement**: 
  > *"When one process performs a load, a store, or an instruction fetch, it should not be able to access or affect in any way the memory contents of any other process or the OS itself."*
- **Consequence**: Enables **isolation** (see Principle of Isolation below).

---

## The Principle of Isolation

### Definition
> *"If two entities are properly isolated from one another, this implies that one can fail without affecting the other."*

### OS Implementation
- **Process isolation**: 
  > *"Operating systems strive to isolate processes from each other and in this way prevent one from harming the other."*
- **Memory isolation**: 
  > *"By using memory isolation, the OS further ensures that running programs cannot affect the operation of the underlying OS."*
- **Advanced isolation**: Microkernels ([BH70, R+89, S+03) wall off OS components:
  > *"Some modern OS’s take isolation even further, by walling off pieces of the OS from other pieces of the OS. Such microkernels thus may provide greater reliability than typical monolithic kernel designs."*

---

## 13.5 Summary

### VM System Responsibilities
- **Primary function**: Provide illusion of a **large, sparse, private address space** to each program.
- **Address space contents**: 
  > *"Each virtual address space contains all of a program’s instructions and data, which can be referenced by the program via virtual addresses."*
- **OS/hardware interaction**: 
  > *"The OS, with some serious hardware help, will take each of these virtual memory references and turn them into physical addresses, which can be presented to the physical memory."*
- **Multi-process handling**: 
  > *"The OS will provide this service for many processes at once, making sure to protect programs from one another, as well as protect the OS."*

### Core Requirements
- **Mechanism**: Low-level machinery (e.g., page tables, TLBs).
- **Policies**: Critical decisions (e.g., managing free space, evicting pages when memory is full).
- **Learning path**: 
  > *"We’ll start from the bottom up, describing the critical mechanisms first."*

---

## Aside: Every Address You See Is Virtual

### Key Insight
> *"Any address you can see as a programmer of a user-level program is a virtual address."*

### Example Program (`va.c`)
```c
#include <stdio.h>
#include <stdlib.h>
int main(int argc, char *argv[]) {
    printf("location of code : %p\n", main);          // Code segment
    printf("location of heap : %p\n", malloc(100e6));  // Heap segment
    int x = 3;
    printf("location of stack: %p\n", &x);             // Stack segment
    return x;
}
```

### Sample Output (64-bit Mac)
```
location of code : 0x1095afe50
location of heap : 0x1096008c0
location of stack: 0x7fff691aea64
```

### Interpretation
- **Code** appears first in the address space (e.g., `0x1095afe50`).
- **Heap** follows code (e.g., `0x1096008c0`).
- **Stack** is at the opposite end of the virtual space (e.g., `0x7fff691aea64`).
- **Critical realization**: 
  > *"All of these addresses are virtual, and will be translated by the OS and hardware in order to fetch values from their true physical locations."*

---

## References

| Citation | Source | Key Contribution |
|----------|--------|------------------|
| [BH70] | Brinch Hansen, *The Nucleus of a Multiprogramming System*, 1970 | First paper proposing minimal kernel for customizable OS |
| [CV65] | Corbato & Vyssotsky, *Introduction to Multics*, 1965 | Early time-sharing motivation: "programmers tired of long program-debug cycles" |
| [DV66] | Dennis & Van Horn, *Programming Semantics for Multiprogrammed Computations*, 1966 | Early paper on multiprogramming |
| [L60] | Licklider, *Man-Computer Symbiosis*, 1960 | Vision of human-computer symbiosis (ahead of its time) |
| [M62] | McCarthy, *Time-Sharing Computer Systems*, 1962 | Earliest recorded paper on time-sharing (McCarthy claims idea since 1957) |
| [M+63] | McCarthy et al., *A Time-Sharing Debugging System*, 1963 | Early system swapping memory to "drum" (disk) |
| [M83] | McCarthy, *Reminiscences on Time Sharing History*, 1983 | Historical note on time-sharing origins |
| [NS07] | Nethercote & Seward, *Valgrind*, 2007 | Dynamic binary instrumentation for memory debugging |
| [R+89] | Rashid et al., *Mach: A System Software Kernel*, 1989 | Influential microkernel project (basis for Mac OS X) |
| [S59] | Strachey, *Time Sharing in Large Fast Computers*, 1959 | One of earliest time-sharing references |
| [S+03] | Swift et al., *Improving OS Reliability*, 2003 | First paper showing microkernel-like thinking improves reliability |

---

## Homework: Virtual Memory Tools (Linux)

### Task 1: `free` Tool
1. **Command**: `man free` (read entire manual page).
2. **Execution**: 
   - Run `free` (e.g., `free -m` to display in megabytes).
   - **Questions**:
     - How much total memory is in your system?
     - How much is free?
     - Do these numbers match your intuition?

### Task 2: Memory-User Program (`memory-user.c`)
```c
// memory-user.c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(int argc, char *argv[]) {
    if (argc < 2) {
        fprintf(stderr, "Usage: %s <MB>\n", argv[0]);
        return 1;
    }
    size_t mb = atoi(argv[1]);
    size_t size = mb * 1024 * 1024;
    char *buf = malloc(size);
    if (!buf) {
        perror("malloc");
        return 1;
    }
    // Touch every byte to prevent optimization
    for (size_t i = 0; i < size; i++) {
        buf[i] = 'a';
    }
    // Run indefinitely (or add time limit)
    while (1) {
        sleep(1);
    }
    return 0;
}
```

### Task 3: Memory Usage Analysis
1. **Run program**: `./memory-user 50` (uses 50MB).
2. **In another terminal**: 
   - Run `free -m` while program is active.
   - **Observe**: 
     - How do memory totals change when the program runs?
     - How do they change when you kill the program (`killall memory-user`)?
     - Do numbers match expectations?
3. **Test different memory amounts** (e.g., 100MB, 500MB).
4. **Extreme test**: Use very large amounts (e.g., 1GB) and observe system behavior.

### Task 4: `pmap` Tool
1. **Command**: `man pmap` (read entire manual page).
2. **Process identification**:
   - Run `ps auxw` to list processes.
   - Pick a process (e.g., browser, or your `memory-user` program).
3. **Run `pmap`**:
   - `pmap -X <PID>` (shows detailed memory mappings).
   - **Questions**:
     - How many different entities make up a modern address space (vs. simple code/stack/heap)?
     - What do you see in the output?
4. **Test with `memory-user`**:
   - Run `./memory-user 10` (10MB).
   - Get PID via `ps auxw` or add `printf("PID: %d\n", getpid());` to program.
   - Run `pmap -X <PID>`.
   - **Observe**: 
     - Does output match expectations?
     - How does output change with different memory allocations?

---

## Key Terms and Definitions

| Term | Definition |
|------|------------|
| **Address Space** | The running program’s view of memory (abstraction provided by OS). Contains all memory state: code, stack, heap. |
| **Virtual Address** | Address used by a program (e.g., `0` in Process A). Translated to physical address by OS/hardware. |
| **Physical Address** | Actual location in hardware memory (e.g., `320KB` for Process A). |
| **Virtualization** | OS technique making programs believe they have private, large memory space, while reality is shared physical memory. |
| **Transparency** | VM implementation invisible to programs (program behaves as if it has private physical memory). |
| **Protection** | Mechanism preventing processes from accessing each other’s memory or the OS. |
| **Isolation** | Principle where one entity failing doesn’t affect others (achieved via memory isolation). |
| **Microkernel** | OS design walling off OS components (e.g., Mach kernel), improving reliability through isolation. |

---

## Review Questions

1. **Why did early systems have minimal memory abstraction?**
   - Users had low expectations; OS was a library at physical address 0, with one process at 64KB.

2. **What was the flaw in the crude time-sharing approach?**
   - Saving/restoring entire memory to disk was too slow (especially as memory grew).

3. **How does the address space layout prevent heap/stack collision?**
   - Heap grows downward from code, stack grows upward from bottom → opposite directions.

4. **Why is transparency a key goal of VM?**
   - Programs must behave as if they have private physical memory without awareness of virtualization.

5. **What does `pmap` reveal about modern address spaces?**
   - It shows multiple memory segments beyond code/stack/heap (e.g., shared libraries, memory-mapped files).

6. **Why is protection critical for time-sharing systems?**
   - To prevent processes from reading/writing each other’s memory (enabling isolation).

7. **What is the "crux" of memory virtualization?**
   - Building a private address space for multiple processes on shared physical memory.

8. **How does the `va.c` example prove all addresses are virtual?**
   - Output shows code, heap, and stack at non-physical locations (e.g., `0x1095afe50`), requiring translation to physical addresses.